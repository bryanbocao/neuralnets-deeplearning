{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "Reference:\n",
    "    http://www.deeplearning.net/tutorial/lstm.html#lstm\n",
    "    https://github.com/llSourcell/LSTM_Networks/blob/master/LSTM%20Demo.ipynb\n",
    "    https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    Recurrent Neural Network.\n",
    "    A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "    This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "    Links:\n",
    "    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n",
    "    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "    Author: Aymeric Damien\n",
    "    Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module\n",
    "\n",
    "H = 5\n",
    "N = 10\n",
    "\n",
    "#Reference: Denis\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    return np.expand_dims(sequences, axis=2), y\n",
    "\n",
    "#Reference: Modified from Denis by Bo Cao\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    \n",
    "    new_y = []\n",
    "    for i in range(len(y)):\n",
    "        new_yy = []\n",
    "        if y[i] == 0:\n",
    "            new_yy.append(0)\n",
    "            new_yy.append(1)\n",
    "        else:\n",
    "            new_yy.append(1)\n",
    "            new_yy.append(0)\n",
    "        new_y.append(new_yy)\n",
    "\n",
    "    return np.expand_dims(sequences, axis=2), new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication: 0: \n",
      "Epoch: 0, Minibatch Loss= 0.6936, Training Accuracy= 0.475\n",
      "Epoch: 10, Minibatch Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 20, Minibatch Loss= 0.6931, Training Accuracy= 0.512\n",
      "Epoch: 30, Minibatch Loss= 0.6931, Training Accuracy= 0.493\n",
      "Epoch: 40, Minibatch Loss= 0.6931, Training Accuracy= 0.500\n",
      "Epoch: 50, Minibatch Loss= 0.6931, Training Accuracy= 0.512\n",
      "Epoch: 60, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 70, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 80, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 90, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 100, Minibatch Loss= 0.6931, Training Accuracy= 0.501\n",
      "Epoch: 110, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 120, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 130, Minibatch Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 140, Minibatch Loss= 0.6930, Training Accuracy= 0.500\n",
      "Epoch: 150, Minibatch Loss= 0.6930, Training Accuracy= 0.495\n",
      "Epoch: 160, Minibatch Loss= 0.6930, Training Accuracy= 0.490\n",
      "Epoch: 170, Minibatch Loss= 0.6930, Training Accuracy= 0.495\n",
      "Epoch: 180, Minibatch Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 190, Minibatch Loss= 0.6930, Training Accuracy= 0.514\n",
      "Epoch: 200, Minibatch Loss= 0.6930, Training Accuracy= 0.514\n",
      "Epoch: 210, Minibatch Loss= 0.6930, Training Accuracy= 0.516\n",
      "Epoch: 220, Minibatch Loss= 0.6930, Training Accuracy= 0.527\n",
      "Epoch: 230, Minibatch Loss= 0.6930, Training Accuracy= 0.523\n",
      "Epoch: 240, Minibatch Loss= 0.6929, Training Accuracy= 0.525\n",
      "Epoch: 250, Minibatch Loss= 0.6929, Training Accuracy= 0.547\n",
      "Epoch: 260, Minibatch Loss= 0.6928, Training Accuracy= 0.540\n",
      "Epoch: 270, Minibatch Loss= 0.6908, Training Accuracy= 0.454\n",
      "Epoch: 280, Minibatch Loss= 0.6468, Training Accuracy= 0.534\n",
      "Epoch: 290, Minibatch Loss= 0.4033, Training Accuracy= 0.740\n",
      "Epoch: 300, Minibatch Loss= 0.2847, Training Accuracy= 0.824\n",
      "Epoch: 310, Minibatch Loss= 0.1319, Training Accuracy= 0.961\n",
      "Epoch: 320, Minibatch Loss= 0.0360, Training Accuracy= 0.993\n",
      "Epoch: 330, Minibatch Loss= 0.0170, Training Accuracy= 0.997\n",
      "Epoch: 340, Minibatch Loss= 0.0112, Training Accuracy= 0.998\n",
      "Epoch: 350, Minibatch Loss= 0.0085, Training Accuracy= 0.998\n",
      "Epoch: 360, Minibatch Loss= 0.0067, Training Accuracy= 0.998\n",
      "Epoch: 370, Minibatch Loss= 0.0054, Training Accuracy= 0.998\n",
      "Epoch: 380, Minibatch Loss= 0.0042, Training Accuracy= 0.998\n",
      "Epoch: 390, Minibatch Loss= 0.0031, Training Accuracy= 1.000\n",
      "Epoch: 400, Minibatch Loss= 0.0024, Training Accuracy= 1.000\n",
      "Epoch: 410, Minibatch Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 420, Minibatch Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 430, Minibatch Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 500, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 510, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 520, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1000, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1010, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1020, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1030, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1040, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1050, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1060, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1070, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1080, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1090, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1100, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1110, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1120, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1130, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1140, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1150, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1160, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1170, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1180, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1190, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1200, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1210, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1220, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1230, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1240, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1250, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1260, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1270, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1280, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1290, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1300, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1310, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1320, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1330, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1340, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1350, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1360, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1370, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1380, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1390, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1400, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1410, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1420, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1430, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1440, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1450, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1460, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1470, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1480, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1490, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1500, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1510, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1520, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1530, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1540, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1550, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1560, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1570, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1580, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1590, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1600, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1610, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1620, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1630, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1640, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1650, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1660, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1670, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1680, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1690, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1700, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1710, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1720, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1730, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1740, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1750, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1760, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1770, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1780, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1790, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1810, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1940, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1950, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1960, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1970, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1980, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1990, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2000, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2010, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2020, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2030, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2040, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2050, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2060, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2070, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2080, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2090, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2100, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2110, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2120, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2130, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2140, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2150, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2160, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2170, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2180, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2190, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2200, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2210, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2220, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2230, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2240, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2250, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2260, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2270, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2280, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2290, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2300, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2310, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2320, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2330, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2340, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2350, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2360, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2370, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2380, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2390, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2400, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2410, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2420, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2430, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2440, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2450, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2460, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2470, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2480, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2490, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2500, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2510, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2520, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2530, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2540, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2550, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2560, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2570, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2580, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2590, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2600, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2610, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2620, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2630, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2640, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2650, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2660, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2670, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2680, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2690, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2700, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2710, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2720, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2730, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2740, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2750, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2760, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2770, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2780, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2790, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2800, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2810, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2820, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2830, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2840, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2850, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2860, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2870, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2880, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2890, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2900, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2910, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2920, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2930, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2940, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2950, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2960, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2970, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2980, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2990, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 1: \n",
      "Epoch: 0, Minibatch Loss= 0.7069, Training Accuracy= 0.496\n",
      "Epoch: 10, Minibatch Loss= 0.6956, Training Accuracy= 0.496\n",
      "Epoch: 20, Minibatch Loss= 0.6948, Training Accuracy= 0.496\n",
      "Epoch: 30, Minibatch Loss= 0.6945, Training Accuracy= 0.496\n",
      "Epoch: 40, Minibatch Loss= 0.6943, Training Accuracy= 0.496\n",
      "Epoch: 50, Minibatch Loss= 0.6941, Training Accuracy= 0.496\n",
      "Epoch: 60, Minibatch Loss= 0.6940, Training Accuracy= 0.496\n",
      "Epoch: 70, Minibatch Loss= 0.6939, Training Accuracy= 0.496\n",
      "Epoch: 80, Minibatch Loss= 0.6939, Training Accuracy= 0.496\n",
      "Epoch: 90, Minibatch Loss= 0.6938, Training Accuracy= 0.496\n",
      "Epoch: 100, Minibatch Loss= 0.6938, Training Accuracy= 0.496\n",
      "Epoch: 110, Minibatch Loss= 0.6938, Training Accuracy= 0.496\n",
      "Epoch: 120, Minibatch Loss= 0.6937, Training Accuracy= 0.495\n",
      "Epoch: 130, Minibatch Loss= 0.6937, Training Accuracy= 0.496\n",
      "Epoch: 140, Minibatch Loss= 0.6937, Training Accuracy= 0.495\n",
      "Epoch: 150, Minibatch Loss= 0.6937, Training Accuracy= 0.493\n",
      "Epoch: 160, Minibatch Loss= 0.6936, Training Accuracy= 0.496\n",
      "Epoch: 170, Minibatch Loss= 0.6936, Training Accuracy= 0.497\n",
      "Epoch: 180, Minibatch Loss= 0.6936, Training Accuracy= 0.505\n",
      "Epoch: 190, Minibatch Loss= 0.6936, Training Accuracy= 0.510\n",
      "Epoch: 200, Minibatch Loss= 0.6936, Training Accuracy= 0.511\n",
      "Epoch: 210, Minibatch Loss= 0.6936, Training Accuracy= 0.505\n",
      "Epoch: 220, Minibatch Loss= 0.6936, Training Accuracy= 0.499\n",
      "Epoch: 230, Minibatch Loss= 0.6936, Training Accuracy= 0.495\n",
      "Epoch: 240, Minibatch Loss= 0.6935, Training Accuracy= 0.498\n",
      "Epoch: 250, Minibatch Loss= 0.6935, Training Accuracy= 0.494\n",
      "Epoch: 260, Minibatch Loss= 0.6935, Training Accuracy= 0.491\n",
      "Epoch: 270, Minibatch Loss= 0.6935, Training Accuracy= 0.491\n",
      "Epoch: 280, Minibatch Loss= 0.6935, Training Accuracy= 0.486\n",
      "Epoch: 290, Minibatch Loss= 0.6935, Training Accuracy= 0.484\n",
      "Epoch: 300, Minibatch Loss= 0.6935, Training Accuracy= 0.481\n",
      "Epoch: 310, Minibatch Loss= 0.6935, Training Accuracy= 0.481\n",
      "Epoch: 320, Minibatch Loss= 0.6935, Training Accuracy= 0.484\n",
      "Epoch: 330, Minibatch Loss= 0.6935, Training Accuracy= 0.485\n",
      "Epoch: 340, Minibatch Loss= 0.6935, Training Accuracy= 0.491\n",
      "Epoch: 350, Minibatch Loss= 0.6935, Training Accuracy= 0.494\n",
      "Epoch: 360, Minibatch Loss= 0.6935, Training Accuracy= 0.498\n",
      "Epoch: 370, Minibatch Loss= 0.6935, Training Accuracy= 0.498\n",
      "Epoch: 380, Minibatch Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 390, Minibatch Loss= 0.6935, Training Accuracy= 0.504\n",
      "Epoch: 400, Minibatch Loss= 0.6935, Training Accuracy= 0.504\n",
      "Epoch: 410, Minibatch Loss= 0.6935, Training Accuracy= 0.506\n",
      "Epoch: 420, Minibatch Loss= 0.6935, Training Accuracy= 0.506\n",
      "Epoch: 430, Minibatch Loss= 0.6935, Training Accuracy= 0.507\n",
      "Epoch: 440, Minibatch Loss= 0.6935, Training Accuracy= 0.509\n",
      "Epoch: 450, Minibatch Loss= 0.6935, Training Accuracy= 0.508\n",
      "Epoch: 460, Minibatch Loss= 0.6935, Training Accuracy= 0.509\n",
      "Epoch: 470, Minibatch Loss= 0.6935, Training Accuracy= 0.507\n",
      "Epoch: 480, Minibatch Loss= 0.6935, Training Accuracy= 0.506\n",
      "Epoch: 490, Minibatch Loss= 0.6935, Training Accuracy= 0.508\n",
      "Epoch: 500, Minibatch Loss= 0.6935, Training Accuracy= 0.507\n",
      "Epoch: 510, Minibatch Loss= 0.6935, Training Accuracy= 0.504\n",
      "Epoch: 520, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 530, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 540, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 550, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 560, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 570, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 580, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 590, Minibatch Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 600, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 610, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 620, Minibatch Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 630, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 640, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 650, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 660, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 670, Minibatch Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 680, Minibatch Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 690, Minibatch Loss= 0.6934, Training Accuracy= 0.499\n",
      "Epoch: 700, Minibatch Loss= 0.6934, Training Accuracy= 0.499\n",
      "Epoch: 710, Minibatch Loss= 0.6934, Training Accuracy= 0.497\n",
      "Epoch: 720, Minibatch Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 730, Minibatch Loss= 0.6934, Training Accuracy= 0.497\n",
      "Epoch: 740, Minibatch Loss= 0.6934, Training Accuracy= 0.497\n",
      "Epoch: 750, Minibatch Loss= 0.6934, Training Accuracy= 0.497\n",
      "Epoch: 760, Minibatch Loss= 0.6934, Training Accuracy= 0.497\n",
      "Epoch: 770, Minibatch Loss= 0.6934, Training Accuracy= 0.497\n",
      "Epoch: 780, Minibatch Loss= 0.6934, Training Accuracy= 0.497\n",
      "Epoch: 790, Minibatch Loss= 0.6934, Training Accuracy= 0.497\n",
      "Epoch: 800, Minibatch Loss= 0.6934, Training Accuracy= 0.496\n",
      "Epoch: 810, Minibatch Loss= 0.6934, Training Accuracy= 0.496\n",
      "Epoch: 820, Minibatch Loss= 0.6934, Training Accuracy= 0.497\n",
      "Epoch: 830, Minibatch Loss= 0.6934, Training Accuracy= 0.495\n",
      "Epoch: 840, Minibatch Loss= 0.6934, Training Accuracy= 0.495\n",
      "Epoch: 850, Minibatch Loss= 0.6934, Training Accuracy= 0.495\n",
      "Epoch: 860, Minibatch Loss= 0.6934, Training Accuracy= 0.495\n",
      "Epoch: 870, Minibatch Loss= 0.6934, Training Accuracy= 0.495\n",
      "Epoch: 880, Minibatch Loss= 0.6934, Training Accuracy= 0.495\n",
      "Epoch: 890, Minibatch Loss= 0.6934, Training Accuracy= 0.495\n",
      "Epoch: 900, Minibatch Loss= 0.6934, Training Accuracy= 0.495\n",
      "Epoch: 910, Minibatch Loss= 0.6934, Training Accuracy= 0.494\n",
      "Epoch: 920, Minibatch Loss= 0.6934, Training Accuracy= 0.494\n",
      "Epoch: 930, Minibatch Loss= 0.6934, Training Accuracy= 0.493\n",
      "Epoch: 940, Minibatch Loss= 0.6934, Training Accuracy= 0.493\n",
      "Epoch: 950, Minibatch Loss= 0.6934, Training Accuracy= 0.493\n",
      "Epoch: 960, Minibatch Loss= 0.6934, Training Accuracy= 0.493\n",
      "Epoch: 970, Minibatch Loss= 0.6934, Training Accuracy= 0.494\n",
      "Epoch: 980, Minibatch Loss= 0.6934, Training Accuracy= 0.495\n",
      "Epoch: 990, Minibatch Loss= 0.6934, Training Accuracy= 0.495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000, Minibatch Loss= 0.6934, Training Accuracy= 0.495\n",
      "Epoch: 1010, Minibatch Loss= 0.6934, Training Accuracy= 0.495\n",
      "Epoch: 1020, Minibatch Loss= 0.6934, Training Accuracy= 0.495\n",
      "Epoch: 1030, Minibatch Loss= 0.6934, Training Accuracy= 0.495\n",
      "Epoch: 1040, Minibatch Loss= 0.6934, Training Accuracy= 0.495\n",
      "Epoch: 1050, Minibatch Loss= 0.6934, Training Accuracy= 0.496\n",
      "Epoch: 1060, Minibatch Loss= 0.6934, Training Accuracy= 0.496\n",
      "Epoch: 1070, Minibatch Loss= 0.6934, Training Accuracy= 0.496\n",
      "Epoch: 1080, Minibatch Loss= 0.6934, Training Accuracy= 0.496\n",
      "Epoch: 1090, Minibatch Loss= 0.6934, Training Accuracy= 0.496\n",
      "Epoch: 1100, Minibatch Loss= 0.6934, Training Accuracy= 0.496\n",
      "Epoch: 1110, Minibatch Loss= 0.6934, Training Accuracy= 0.496\n",
      "Epoch: 1120, Minibatch Loss= 0.6934, Training Accuracy= 0.495\n",
      "Epoch: 1130, Minibatch Loss= 0.6934, Training Accuracy= 0.495\n",
      "Epoch: 1140, Minibatch Loss= 0.6934, Training Accuracy= 0.495\n",
      "Epoch: 1150, Minibatch Loss= 0.6934, Training Accuracy= 0.495\n",
      "Epoch: 1160, Minibatch Loss= 0.6934, Training Accuracy= 0.497\n",
      "Epoch: 1170, Minibatch Loss= 0.6934, Training Accuracy= 0.496\n",
      "Epoch: 1180, Minibatch Loss= 0.6934, Training Accuracy= 0.496\n",
      "Epoch: 1190, Minibatch Loss= 0.6934, Training Accuracy= 0.496\n",
      "Epoch: 1200, Minibatch Loss= 0.6934, Training Accuracy= 0.496\n",
      "Epoch: 1210, Minibatch Loss= 0.6934, Training Accuracy= 0.496\n",
      "Epoch: 1220, Minibatch Loss= 0.6934, Training Accuracy= 0.497\n",
      "Epoch: 1230, Minibatch Loss= 0.6934, Training Accuracy= 0.497\n",
      "Epoch: 1240, Minibatch Loss= 0.6934, Training Accuracy= 0.497\n",
      "Epoch: 1250, Minibatch Loss= 0.6934, Training Accuracy= 0.497\n",
      "Epoch: 1260, Minibatch Loss= 0.6934, Training Accuracy= 0.497\n",
      "Epoch: 1270, Minibatch Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 1280, Minibatch Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 1290, Minibatch Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 1300, Minibatch Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 1310, Minibatch Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 1320, Minibatch Loss= 0.6934, Training Accuracy= 0.497\n",
      "Epoch: 1330, Minibatch Loss= 0.6934, Training Accuracy= 0.497\n",
      "Epoch: 1340, Minibatch Loss= 0.6934, Training Accuracy= 0.496\n",
      "Epoch: 1350, Minibatch Loss= 0.6934, Training Accuracy= 0.496\n",
      "Epoch: 1360, Minibatch Loss= 0.6934, Training Accuracy= 0.496\n",
      "Epoch: 1370, Minibatch Loss= 0.6934, Training Accuracy= 0.497\n",
      "Epoch: 1380, Minibatch Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 1390, Minibatch Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 1400, Minibatch Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 1410, Minibatch Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 1420, Minibatch Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 1430, Minibatch Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 1440, Minibatch Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1450, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 1460, Minibatch Loss= 0.6934, Training Accuracy= 0.504\n",
      "Epoch: 1470, Minibatch Loss= 0.6934, Training Accuracy= 0.506\n",
      "Epoch: 1480, Minibatch Loss= 0.6934, Training Accuracy= 0.505\n",
      "Epoch: 1490, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 1500, Minibatch Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 1510, Minibatch Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 1520, Minibatch Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 1530, Minibatch Loss= 0.6934, Training Accuracy= 0.499\n",
      "Epoch: 1540, Minibatch Loss= 0.6934, Training Accuracy= 0.499\n",
      "Epoch: 1550, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 1560, Minibatch Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 1570, Minibatch Loss= 0.6934, Training Accuracy= 0.499\n",
      "Epoch: 1580, Minibatch Loss= 0.6933, Training Accuracy= 0.501\n",
      "Epoch: 1590, Minibatch Loss= 0.6933, Training Accuracy= 0.501\n",
      "Epoch: 1600, Minibatch Loss= 0.6933, Training Accuracy= 0.501\n",
      "Epoch: 1610, Minibatch Loss= 0.6933, Training Accuracy= 0.504\n",
      "Epoch: 1620, Minibatch Loss= 0.6933, Training Accuracy= 0.500\n",
      "Epoch: 1630, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 1640, Minibatch Loss= 0.6933, Training Accuracy= 0.513\n",
      "Epoch: 1650, Minibatch Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 1660, Minibatch Loss= 0.6933, Training Accuracy= 0.508\n",
      "Epoch: 1670, Minibatch Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 1680, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 1690, Minibatch Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 1700, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 1710, Minibatch Loss= 0.6931, Training Accuracy= 0.497\n",
      "Epoch: 1720, Minibatch Loss= 0.6922, Training Accuracy= 0.524\n",
      "Epoch: 1730, Minibatch Loss= 0.6523, Training Accuracy= 0.668\n",
      "Epoch: 1740, Minibatch Loss= 0.4601, Training Accuracy= 0.783\n",
      "Epoch: 1750, Minibatch Loss= 0.3536, Training Accuracy= 0.815\n",
      "Epoch: 1760, Minibatch Loss= 0.2389, Training Accuracy= 0.881\n",
      "Epoch: 1770, Minibatch Loss= 0.1819, Training Accuracy= 0.909\n",
      "Epoch: 1780, Minibatch Loss= 0.5225, Training Accuracy= 0.696\n",
      "Epoch: 1790, Minibatch Loss= 0.4157, Training Accuracy= 0.760\n",
      "Epoch: 1800, Minibatch Loss= 0.3076, Training Accuracy= 0.849\n",
      "Epoch: 1810, Minibatch Loss= 0.7445, Training Accuracy= 0.783\n",
      "Epoch: 1820, Minibatch Loss= 0.0483, Training Accuracy= 0.992\n",
      "Epoch: 1830, Minibatch Loss= 0.0334, Training Accuracy= 0.992\n",
      "Epoch: 1840, Minibatch Loss= 0.0292, Training Accuracy= 0.992\n",
      "Epoch: 1850, Minibatch Loss= 0.0272, Training Accuracy= 0.992\n",
      "Epoch: 1860, Minibatch Loss= 0.0261, Training Accuracy= 0.992\n",
      "Epoch: 1870, Minibatch Loss= 0.0253, Training Accuracy= 0.992\n",
      "Epoch: 1880, Minibatch Loss= 0.0248, Training Accuracy= 0.992\n",
      "Epoch: 1890, Minibatch Loss= 0.0243, Training Accuracy= 0.992\n",
      "Epoch: 1900, Minibatch Loss= 0.0239, Training Accuracy= 0.992\n",
      "Epoch: 1910, Minibatch Loss= 0.0236, Training Accuracy= 0.992\n",
      "Epoch: 1920, Minibatch Loss= 0.0232, Training Accuracy= 0.992\n",
      "Epoch: 1930, Minibatch Loss= 0.0230, Training Accuracy= 0.992\n",
      "Epoch: 1940, Minibatch Loss= 0.0228, Training Accuracy= 0.992\n",
      "Epoch: 1950, Minibatch Loss= 0.0229, Training Accuracy= 0.992\n",
      "Epoch: 1960, Minibatch Loss= 0.0234, Training Accuracy= 0.992\n",
      "Epoch: 1970, Minibatch Loss= 0.0218, Training Accuracy= 0.992\n",
      "Epoch: 1980, Minibatch Loss= 0.0176, Training Accuracy= 0.993\n",
      "Epoch: 1990, Minibatch Loss= 0.0151, Training Accuracy= 0.996\n",
      "Epoch: 2000, Minibatch Loss= 0.0136, Training Accuracy= 0.997\n",
      "Epoch: 2010, Minibatch Loss= 0.0124, Training Accuracy= 0.997\n",
      "Epoch: 2020, Minibatch Loss= 0.0110, Training Accuracy= 0.998\n",
      "Epoch: 2030, Minibatch Loss= 0.0095, Training Accuracy= 0.998\n",
      "Epoch: 2040, Minibatch Loss= 0.0082, Training Accuracy= 0.998\n",
      "Epoch: 2050, Minibatch Loss= 0.0077, Training Accuracy= 0.998\n",
      "Epoch: 2060, Minibatch Loss= 0.0073, Training Accuracy= 0.998\n",
      "Epoch: 2070, Minibatch Loss= 0.0071, Training Accuracy= 0.998\n",
      "Epoch: 2080, Minibatch Loss= 0.0069, Training Accuracy= 0.998\n",
      "Epoch: 2090, Minibatch Loss= 0.0067, Training Accuracy= 0.998\n",
      "Epoch: 2100, Minibatch Loss= 0.0066, Training Accuracy= 0.998\n",
      "Epoch: 2110, Minibatch Loss= 0.0065, Training Accuracy= 0.998\n",
      "Epoch: 2120, Minibatch Loss= 0.0064, Training Accuracy= 0.998\n",
      "Epoch: 2130, Minibatch Loss= 0.0063, Training Accuracy= 0.998\n",
      "Epoch: 2140, Minibatch Loss= 0.0062, Training Accuracy= 0.998\n",
      "Epoch: 2150, Minibatch Loss= 0.0062, Training Accuracy= 0.998\n",
      "Epoch: 2160, Minibatch Loss= 0.0061, Training Accuracy= 0.998\n",
      "Epoch: 2170, Minibatch Loss= 0.0061, Training Accuracy= 0.998\n",
      "Epoch: 2180, Minibatch Loss= 0.0060, Training Accuracy= 0.998\n",
      "Epoch: 2190, Minibatch Loss= 0.0060, Training Accuracy= 0.998\n",
      "Epoch: 2200, Minibatch Loss= 0.0059, Training Accuracy= 0.998\n",
      "Epoch: 2210, Minibatch Loss= 0.0059, Training Accuracy= 0.998\n",
      "Epoch: 2220, Minibatch Loss= 0.0059, Training Accuracy= 0.998\n",
      "Epoch: 2230, Minibatch Loss= 0.0058, Training Accuracy= 0.998\n",
      "Epoch: 2240, Minibatch Loss= 0.0058, Training Accuracy= 0.998\n",
      "Epoch: 2250, Minibatch Loss= 0.0058, Training Accuracy= 0.998\n",
      "Epoch: 2260, Minibatch Loss= 0.0057, Training Accuracy= 0.998\n",
      "Epoch: 2270, Minibatch Loss= 0.0057, Training Accuracy= 0.998\n",
      "Epoch: 2280, Minibatch Loss= 0.0057, Training Accuracy= 0.998\n",
      "Epoch: 2290, Minibatch Loss= 0.0057, Training Accuracy= 0.998\n",
      "Epoch: 2300, Minibatch Loss= 0.0056, Training Accuracy= 0.998\n",
      "Epoch: 2310, Minibatch Loss= 0.0056, Training Accuracy= 0.998\n",
      "Epoch: 2320, Minibatch Loss= 0.0056, Training Accuracy= 0.998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2330, Minibatch Loss= 0.0056, Training Accuracy= 0.998\n",
      "Epoch: 2340, Minibatch Loss= 0.0055, Training Accuracy= 0.998\n",
      "Epoch: 2350, Minibatch Loss= 0.0055, Training Accuracy= 0.998\n",
      "Epoch: 2360, Minibatch Loss= 0.0055, Training Accuracy= 0.998\n",
      "Epoch: 2370, Minibatch Loss= 0.0055, Training Accuracy= 0.998\n",
      "Epoch: 2380, Minibatch Loss= 0.0054, Training Accuracy= 0.998\n",
      "Epoch: 2390, Minibatch Loss= 0.0054, Training Accuracy= 0.998\n",
      "Epoch: 2400, Minibatch Loss= 0.0054, Training Accuracy= 0.998\n",
      "Epoch: 2410, Minibatch Loss= 0.0054, Training Accuracy= 0.998\n",
      "Epoch: 2420, Minibatch Loss= 0.0053, Training Accuracy= 0.998\n",
      "Epoch: 2430, Minibatch Loss= 0.0053, Training Accuracy= 0.998\n",
      "Epoch: 2440, Minibatch Loss= 0.0053, Training Accuracy= 0.998\n",
      "Epoch: 2450, Minibatch Loss= 0.0171, Training Accuracy= 0.998\n",
      "Epoch: 2460, Minibatch Loss= 0.0091, Training Accuracy= 0.998\n",
      "Epoch: 2470, Minibatch Loss= 0.0067, Training Accuracy= 0.998\n",
      "Epoch: 2480, Minibatch Loss= 0.0062, Training Accuracy= 0.998\n",
      "Epoch: 2490, Minibatch Loss= 0.0060, Training Accuracy= 0.998\n",
      "Epoch: 2500, Minibatch Loss= 0.0058, Training Accuracy= 0.998\n",
      "Epoch: 2510, Minibatch Loss= 0.0057, Training Accuracy= 0.998\n",
      "Epoch: 2520, Minibatch Loss= 0.0056, Training Accuracy= 0.998\n",
      "Epoch: 2530, Minibatch Loss= 0.0055, Training Accuracy= 0.998\n",
      "Epoch: 2540, Minibatch Loss= 0.0053, Training Accuracy= 0.998\n",
      "Epoch: 2550, Minibatch Loss= 0.0052, Training Accuracy= 0.998\n",
      "Epoch: 2560, Minibatch Loss= 0.0051, Training Accuracy= 0.998\n",
      "Epoch: 2570, Minibatch Loss= 0.0050, Training Accuracy= 0.998\n",
      "Epoch: 2580, Minibatch Loss= 0.0050, Training Accuracy= 0.998\n",
      "Epoch: 2590, Minibatch Loss= 0.0049, Training Accuracy= 0.998\n",
      "Epoch: 2600, Minibatch Loss= 0.0048, Training Accuracy= 0.998\n",
      "Epoch: 2610, Minibatch Loss= 0.0047, Training Accuracy= 0.998\n",
      "Epoch: 2620, Minibatch Loss= 0.0046, Training Accuracy= 0.998\n",
      "Epoch: 2630, Minibatch Loss= 0.0045, Training Accuracy= 0.998\n",
      "Epoch: 2640, Minibatch Loss= 0.0043, Training Accuracy= 0.998\n",
      "Epoch: 2650, Minibatch Loss= 0.0042, Training Accuracy= 0.998\n",
      "Epoch: 2660, Minibatch Loss= 0.0041, Training Accuracy= 0.998\n",
      "Epoch: 2670, Minibatch Loss= 0.0040, Training Accuracy= 0.998\n",
      "Epoch: 2680, Minibatch Loss= 0.0038, Training Accuracy= 0.998\n",
      "Epoch: 2690, Minibatch Loss= 0.0037, Training Accuracy= 0.998\n",
      "Epoch: 2700, Minibatch Loss= 0.0036, Training Accuracy= 0.998\n",
      "Epoch: 2710, Minibatch Loss= 0.0035, Training Accuracy= 0.998\n",
      "Epoch: 2720, Minibatch Loss= 0.0034, Training Accuracy= 0.998\n",
      "Epoch: 2730, Minibatch Loss= 0.0033, Training Accuracy= 0.998\n",
      "Epoch: 2740, Minibatch Loss= 0.0032, Training Accuracy= 0.998\n",
      "Epoch: 2750, Minibatch Loss= 0.0031, Training Accuracy= 0.998\n",
      "Epoch: 2760, Minibatch Loss= 0.0030, Training Accuracy= 1.000\n",
      "Epoch: 2770, Minibatch Loss= 0.7812, Training Accuracy= 0.496\n",
      "Epoch: 2780, Minibatch Loss= 0.7426, Training Accuracy= 0.496\n",
      "Epoch: 2790, Minibatch Loss= 0.7347, Training Accuracy= 0.496\n",
      "Epoch: 2800, Minibatch Loss= 0.7279, Training Accuracy= 0.496\n",
      "Epoch: 2810, Minibatch Loss= 0.7254, Training Accuracy= 0.496\n",
      "Epoch: 2820, Minibatch Loss= 0.7232, Training Accuracy= 0.496\n",
      "Epoch: 2830, Minibatch Loss= 0.7214, Training Accuracy= 0.496\n",
      "Epoch: 2840, Minibatch Loss= 0.7199, Training Accuracy= 0.496\n",
      "Epoch: 2850, Minibatch Loss= 0.7188, Training Accuracy= 0.496\n",
      "Epoch: 2860, Minibatch Loss= 0.7180, Training Accuracy= 0.496\n",
      "Epoch: 2870, Minibatch Loss= 0.7173, Training Accuracy= 0.496\n",
      "Epoch: 2880, Minibatch Loss= 0.7168, Training Accuracy= 0.496\n",
      "Epoch: 2890, Minibatch Loss= 0.7164, Training Accuracy= 0.496\n",
      "Epoch: 2900, Minibatch Loss= 0.7161, Training Accuracy= 0.496\n",
      "Epoch: 2910, Minibatch Loss= 0.7158, Training Accuracy= 0.496\n",
      "Epoch: 2920, Minibatch Loss= 0.7155, Training Accuracy= 0.496\n",
      "Epoch: 2930, Minibatch Loss= 0.7153, Training Accuracy= 0.496\n",
      "Epoch: 2940, Minibatch Loss= 0.7152, Training Accuracy= 0.496\n",
      "Epoch: 2950, Minibatch Loss= 0.7150, Training Accuracy= 0.496\n",
      "Epoch: 2960, Minibatch Loss= 0.7149, Training Accuracy= 0.496\n",
      "Epoch: 2970, Minibatch Loss= 0.7147, Training Accuracy= 0.496\n",
      "Epoch: 2980, Minibatch Loss= 0.7146, Training Accuracy= 0.496\n",
      "Epoch: 2990, Minibatch Loss= 0.7145, Training Accuracy= 0.496\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5064\n",
      "Replication: 2: \n",
      "Epoch: 0, Minibatch Loss= 0.7037, Training Accuracy= 0.498\n",
      "Epoch: 10, Minibatch Loss= 0.6995, Training Accuracy= 0.498\n",
      "Epoch: 20, Minibatch Loss= 0.6985, Training Accuracy= 0.498\n",
      "Epoch: 30, Minibatch Loss= 0.6978, Training Accuracy= 0.498\n",
      "Epoch: 40, Minibatch Loss= 0.6974, Training Accuracy= 0.498\n",
      "Epoch: 50, Minibatch Loss= 0.6970, Training Accuracy= 0.498\n",
      "Epoch: 60, Minibatch Loss= 0.6967, Training Accuracy= 0.498\n",
      "Epoch: 70, Minibatch Loss= 0.6965, Training Accuracy= 0.498\n",
      "Epoch: 80, Minibatch Loss= 0.6963, Training Accuracy= 0.498\n",
      "Epoch: 90, Minibatch Loss= 0.6962, Training Accuracy= 0.498\n",
      "Epoch: 100, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 110, Minibatch Loss= 0.6960, Training Accuracy= 0.498\n",
      "Epoch: 120, Minibatch Loss= 0.6959, Training Accuracy= 0.498\n",
      "Epoch: 130, Minibatch Loss= 0.6958, Training Accuracy= 0.498\n",
      "Epoch: 140, Minibatch Loss= 0.6957, Training Accuracy= 0.498\n",
      "Epoch: 150, Minibatch Loss= 0.6956, Training Accuracy= 0.498\n",
      "Epoch: 160, Minibatch Loss= 0.6956, Training Accuracy= 0.498\n",
      "Epoch: 170, Minibatch Loss= 0.6955, Training Accuracy= 0.498\n",
      "Epoch: 180, Minibatch Loss= 0.6955, Training Accuracy= 0.498\n",
      "Epoch: 190, Minibatch Loss= 0.6954, Training Accuracy= 0.498\n",
      "Epoch: 200, Minibatch Loss= 0.6954, Training Accuracy= 0.498\n",
      "Epoch: 210, Minibatch Loss= 0.6953, Training Accuracy= 0.498\n",
      "Epoch: 220, Minibatch Loss= 0.6953, Training Accuracy= 0.498\n",
      "Epoch: 230, Minibatch Loss= 0.6953, Training Accuracy= 0.498\n",
      "Epoch: 240, Minibatch Loss= 0.6952, Training Accuracy= 0.498\n",
      "Epoch: 250, Minibatch Loss= 0.6952, Training Accuracy= 0.498\n",
      "Epoch: 260, Minibatch Loss= 0.6952, Training Accuracy= 0.498\n",
      "Epoch: 270, Minibatch Loss= 0.6951, Training Accuracy= 0.498\n",
      "Epoch: 280, Minibatch Loss= 0.6951, Training Accuracy= 0.498\n",
      "Epoch: 290, Minibatch Loss= 0.6951, Training Accuracy= 0.498\n",
      "Epoch: 300, Minibatch Loss= 0.6951, Training Accuracy= 0.498\n",
      "Epoch: 310, Minibatch Loss= 0.6950, Training Accuracy= 0.498\n",
      "Epoch: 320, Minibatch Loss= 0.6950, Training Accuracy= 0.498\n",
      "Epoch: 330, Minibatch Loss= 0.6950, Training Accuracy= 0.498\n",
      "Epoch: 340, Minibatch Loss= 0.6950, Training Accuracy= 0.498\n",
      "Epoch: 350, Minibatch Loss= 0.6950, Training Accuracy= 0.498\n",
      "Epoch: 360, Minibatch Loss= 0.6950, Training Accuracy= 0.498\n",
      "Epoch: 370, Minibatch Loss= 0.6949, Training Accuracy= 0.498\n",
      "Epoch: 380, Minibatch Loss= 0.6949, Training Accuracy= 0.498\n",
      "Epoch: 390, Minibatch Loss= 0.6949, Training Accuracy= 0.498\n",
      "Epoch: 400, Minibatch Loss= 0.6949, Training Accuracy= 0.498\n",
      "Epoch: 410, Minibatch Loss= 0.6949, Training Accuracy= 0.498\n",
      "Epoch: 420, Minibatch Loss= 0.6949, Training Accuracy= 0.498\n",
      "Epoch: 430, Minibatch Loss= 0.6949, Training Accuracy= 0.498\n",
      "Epoch: 440, Minibatch Loss= 0.6948, Training Accuracy= 0.498\n",
      "Epoch: 450, Minibatch Loss= 0.6948, Training Accuracy= 0.498\n",
      "Epoch: 460, Minibatch Loss= 0.6948, Training Accuracy= 0.498\n",
      "Epoch: 470, Minibatch Loss= 0.6948, Training Accuracy= 0.498\n",
      "Epoch: 480, Minibatch Loss= 0.6948, Training Accuracy= 0.498\n",
      "Epoch: 490, Minibatch Loss= 0.6948, Training Accuracy= 0.498\n",
      "Epoch: 500, Minibatch Loss= 0.6948, Training Accuracy= 0.498\n",
      "Epoch: 510, Minibatch Loss= 0.6948, Training Accuracy= 0.498\n",
      "Epoch: 520, Minibatch Loss= 0.6948, Training Accuracy= 0.498\n",
      "Epoch: 530, Minibatch Loss= 0.6948, Training Accuracy= 0.498\n",
      "Epoch: 540, Minibatch Loss= 0.6948, Training Accuracy= 0.498\n",
      "Epoch: 550, Minibatch Loss= 0.6947, Training Accuracy= 0.498\n",
      "Epoch: 560, Minibatch Loss= 0.6947, Training Accuracy= 0.498\n",
      "Epoch: 570, Minibatch Loss= 0.6947, Training Accuracy= 0.498\n",
      "Epoch: 580, Minibatch Loss= 0.6947, Training Accuracy= 0.498\n",
      "Epoch: 590, Minibatch Loss= 0.6947, Training Accuracy= 0.498\n",
      "Epoch: 600, Minibatch Loss= 0.6947, Training Accuracy= 0.498\n",
      "Epoch: 610, Minibatch Loss= 0.6947, Training Accuracy= 0.498\n",
      "Epoch: 620, Minibatch Loss= 0.6947, Training Accuracy= 0.498\n",
      "Epoch: 630, Minibatch Loss= 0.6947, Training Accuracy= 0.498\n",
      "Epoch: 640, Minibatch Loss= 0.6947, Training Accuracy= 0.498\n",
      "Epoch: 650, Minibatch Loss= 0.6947, Training Accuracy= 0.498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 660, Minibatch Loss= 0.6947, Training Accuracy= 0.498\n",
      "Epoch: 670, Minibatch Loss= 0.6947, Training Accuracy= 0.498\n",
      "Epoch: 680, Minibatch Loss= 0.6947, Training Accuracy= 0.498\n",
      "Epoch: 690, Minibatch Loss= 0.6947, Training Accuracy= 0.498\n",
      "Epoch: 700, Minibatch Loss= 0.6947, Training Accuracy= 0.498\n",
      "Epoch: 710, Minibatch Loss= 0.6947, Training Accuracy= 0.498\n",
      "Epoch: 720, Minibatch Loss= 0.6947, Training Accuracy= 0.498\n",
      "Epoch: 730, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 740, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 750, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 760, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 770, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 780, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 790, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 800, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 810, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 820, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 830, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 840, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 850, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 860, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 870, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 880, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 890, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 900, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 910, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 920, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 930, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 940, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 950, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 960, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 970, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 980, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 990, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 1000, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 1010, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 1020, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 1030, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 1040, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 1050, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 1060, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1070, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1080, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1090, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1100, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1110, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1120, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1130, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1140, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1150, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1160, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1170, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1180, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1190, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1200, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1210, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1220, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1230, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1240, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1250, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1260, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1270, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1280, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1290, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1300, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1310, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1320, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1330, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1340, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1350, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1360, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1370, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1380, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1390, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1400, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1410, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1420, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1430, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1440, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1450, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1460, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1470, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1480, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1490, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1500, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1510, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1520, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1530, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1540, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1550, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1560, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1570, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1580, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1590, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1600, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1610, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1620, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1630, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1640, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1650, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1660, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1670, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1680, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1690, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1700, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1710, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1720, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1730, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1740, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1750, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1760, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1770, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1780, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1790, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1800, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1810, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1820, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1830, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 1840, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 1850, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 1860, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 1870, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 1880, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 1890, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 1900, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 1910, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 1920, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 1930, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 1940, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 1950, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 1960, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 1970, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 1980, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1990, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2000, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2010, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2020, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2030, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2040, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2050, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2060, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2070, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2080, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2090, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2100, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2110, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2120, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2130, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2140, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2150, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2160, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2170, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2180, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2190, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2200, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2210, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2220, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2230, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2240, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2250, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2260, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2270, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2280, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2290, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2300, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2310, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2320, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2330, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2340, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2350, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2360, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2370, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2380, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2390, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2400, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2410, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2420, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2430, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2440, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2450, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2460, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2470, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2480, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2490, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2500, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2510, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2520, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2530, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2540, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2550, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2560, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2570, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2580, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2590, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2600, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 2610, Minibatch Loss= 0.6944, Training Accuracy= 0.497\n",
      "Epoch: 2620, Minibatch Loss= 0.6944, Training Accuracy= 0.497\n",
      "Epoch: 2630, Minibatch Loss= 0.6944, Training Accuracy= 0.497\n",
      "Epoch: 2640, Minibatch Loss= 0.6944, Training Accuracy= 0.497\n",
      "Epoch: 2650, Minibatch Loss= 0.6944, Training Accuracy= 0.496\n",
      "Epoch: 2660, Minibatch Loss= 0.6944, Training Accuracy= 0.496\n",
      "Epoch: 2670, Minibatch Loss= 0.6944, Training Accuracy= 0.495\n",
      "Epoch: 2680, Minibatch Loss= 0.6943, Training Accuracy= 0.495\n",
      "Epoch: 2690, Minibatch Loss= 0.6943, Training Accuracy= 0.501\n",
      "Epoch: 2700, Minibatch Loss= 0.6943, Training Accuracy= 0.501\n",
      "Epoch: 2710, Minibatch Loss= 0.6943, Training Accuracy= 0.501\n",
      "Epoch: 2720, Minibatch Loss= 0.6942, Training Accuracy= 0.495\n",
      "Epoch: 2730, Minibatch Loss= 0.6938, Training Accuracy= 0.500\n",
      "Epoch: 2740, Minibatch Loss= 0.6872, Training Accuracy= 0.562\n",
      "Epoch: 2750, Minibatch Loss= 0.6304, Training Accuracy= 0.648\n",
      "Epoch: 2760, Minibatch Loss= 0.3566, Training Accuracy= 0.831\n",
      "Epoch: 2770, Minibatch Loss= 0.2823, Training Accuracy= 0.867\n",
      "Epoch: 2780, Minibatch Loss= 0.2394, Training Accuracy= 0.878\n",
      "Epoch: 2790, Minibatch Loss= 0.1690, Training Accuracy= 0.933\n",
      "Epoch: 2800, Minibatch Loss= 0.1324, Training Accuracy= 0.944\n",
      "Epoch: 2810, Minibatch Loss= 0.1155, Training Accuracy= 0.943\n",
      "Epoch: 2820, Minibatch Loss= 0.1028, Training Accuracy= 0.949\n",
      "Epoch: 2830, Minibatch Loss= 0.0930, Training Accuracy= 0.951\n",
      "Epoch: 2840, Minibatch Loss= 0.0725, Training Accuracy= 0.962\n",
      "Epoch: 2850, Minibatch Loss= 0.7704, Training Accuracy= 0.498\n",
      "Epoch: 2860, Minibatch Loss= 0.7511, Training Accuracy= 0.498\n",
      "Epoch: 2870, Minibatch Loss= 0.7478, Training Accuracy= 0.498\n",
      "Epoch: 2880, Minibatch Loss= 0.7465, Training Accuracy= 0.498\n",
      "Epoch: 2890, Minibatch Loss= 0.7457, Training Accuracy= 0.498\n",
      "Epoch: 2900, Minibatch Loss= 0.7452, Training Accuracy= 0.498\n",
      "Epoch: 2910, Minibatch Loss= 0.7449, Training Accuracy= 0.498\n",
      "Epoch: 2920, Minibatch Loss= 0.7447, Training Accuracy= 0.498\n",
      "Epoch: 2930, Minibatch Loss= 0.7445, Training Accuracy= 0.498\n",
      "Epoch: 2940, Minibatch Loss= 0.7444, Training Accuracy= 0.498\n",
      "Epoch: 2950, Minibatch Loss= 0.7443, Training Accuracy= 0.498\n",
      "Epoch: 2960, Minibatch Loss= 0.7442, Training Accuracy= 0.498\n",
      "Epoch: 2970, Minibatch Loss= 0.7442, Training Accuracy= 0.498\n",
      "Epoch: 2980, Minibatch Loss= 0.7441, Training Accuracy= 0.498\n",
      "Epoch: 2990, Minibatch Loss= 0.7441, Training Accuracy= 0.498\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4975\n",
      "Replication: 3: \n",
      "Epoch: 0, Minibatch Loss= 0.6932, Training Accuracy= 0.516\n",
      "Epoch: 10, Minibatch Loss= 0.6928, Training Accuracy= 0.512\n",
      "Epoch: 20, Minibatch Loss= 0.6927, Training Accuracy= 0.512\n",
      "Epoch: 30, Minibatch Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 40, Minibatch Loss= 0.6925, Training Accuracy= 0.526\n",
      "Epoch: 50, Minibatch Loss= 0.6925, Training Accuracy= 0.524\n",
      "Epoch: 60, Minibatch Loss= 0.6925, Training Accuracy= 0.517\n",
      "Epoch: 70, Minibatch Loss= 0.6925, Training Accuracy= 0.503\n",
      "Epoch: 80, Minibatch Loss= 0.6924, Training Accuracy= 0.496\n",
      "Epoch: 90, Minibatch Loss= 0.6924, Training Accuracy= 0.488\n",
      "Epoch: 100, Minibatch Loss= 0.6924, Training Accuracy= 0.481\n",
      "Epoch: 110, Minibatch Loss= 0.6924, Training Accuracy= 0.480\n",
      "Epoch: 120, Minibatch Loss= 0.6924, Training Accuracy= 0.478\n",
      "Epoch: 130, Minibatch Loss= 0.6923, Training Accuracy= 0.502\n",
      "Epoch: 140, Minibatch Loss= 0.6892, Training Accuracy= 0.610\n",
      "Epoch: 150, Minibatch Loss= 0.5706, Training Accuracy= 0.703\n",
      "Epoch: 160, Minibatch Loss= 0.3239, Training Accuracy= 0.819\n",
      "Epoch: 170, Minibatch Loss= 0.1701, Training Accuracy= 0.927\n",
      "Epoch: 180, Minibatch Loss= 0.0962, Training Accuracy= 0.981\n",
      "Epoch: 190, Minibatch Loss= 0.0759, Training Accuracy= 0.987\n",
      "Epoch: 200, Minibatch Loss= 0.0649, Training Accuracy= 0.987\n",
      "Epoch: 210, Minibatch Loss= 0.0575, Training Accuracy= 0.987\n",
      "Epoch: 220, Minibatch Loss= 0.0578, Training Accuracy= 0.987\n",
      "Epoch: 230, Minibatch Loss= 0.0482, Training Accuracy= 0.987\n",
      "Epoch: 240, Minibatch Loss= 0.0474, Training Accuracy= 0.985\n",
      "Epoch: 250, Minibatch Loss= 0.0425, Training Accuracy= 0.987\n",
      "Epoch: 260, Minibatch Loss= 0.0384, Training Accuracy= 0.988\n",
      "Epoch: 270, Minibatch Loss= 0.0360, Training Accuracy= 0.988\n",
      "Epoch: 280, Minibatch Loss= 0.0344, Training Accuracy= 0.988\n",
      "Epoch: 290, Minibatch Loss= 0.0336, Training Accuracy= 0.988\n",
      "Epoch: 300, Minibatch Loss= 0.0346, Training Accuracy= 0.986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 310, Minibatch Loss= 0.0391, Training Accuracy= 0.986\n",
      "Epoch: 320, Minibatch Loss= 0.0450, Training Accuracy= 0.985\n",
      "Epoch: 330, Minibatch Loss= 0.7581, Training Accuracy= 0.552\n",
      "Epoch: 340, Minibatch Loss= 0.6324, Training Accuracy= 0.630\n",
      "Epoch: 350, Minibatch Loss= 0.6977, Training Accuracy= 0.519\n",
      "Epoch: 360, Minibatch Loss= 0.6955, Training Accuracy= 0.521\n",
      "Epoch: 370, Minibatch Loss= 0.7016, Training Accuracy= 0.501\n",
      "Epoch: 380, Minibatch Loss= 0.6950, Training Accuracy= 0.536\n",
      "Epoch: 390, Minibatch Loss= 0.6956, Training Accuracy= 0.517\n",
      "Epoch: 400, Minibatch Loss= 0.6701, Training Accuracy= 0.554\n",
      "Epoch: 410, Minibatch Loss= 0.5857, Training Accuracy= 0.660\n",
      "Epoch: 420, Minibatch Loss= 0.3707, Training Accuracy= 0.761\n",
      "Epoch: 430, Minibatch Loss= 0.0072, Training Accuracy= 1.000\n",
      "Epoch: 440, Minibatch Loss= 0.0035, Training Accuracy= 1.000\n",
      "Epoch: 450, Minibatch Loss= 0.0024, Training Accuracy= 1.000\n",
      "Epoch: 460, Minibatch Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 470, Minibatch Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 480, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 490, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 500, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 510, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 520, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 530, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 540, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 550, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 560, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 570, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 580, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 590, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 600, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 610, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 620, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 630, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1000, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1010, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1020, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1030, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1040, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1050, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1060, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1070, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1080, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1090, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1100, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1110, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1120, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1130, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1140, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1150, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1160, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1170, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1180, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1190, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1200, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1210, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1220, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1230, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1240, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1250, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1260, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1270, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1280, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1290, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1300, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1310, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1320, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1330, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1340, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1350, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1360, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1370, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1380, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1390, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1400, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1410, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1420, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1430, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1440, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1450, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1460, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1470, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1480, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1490, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1500, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1510, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1520, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1530, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1540, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1550, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1560, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1570, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1580, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1590, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1600, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1610, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1620, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1630, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1640, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1650, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1660, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1670, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1680, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1690, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1700, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1710, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1720, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1730, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1740, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1750, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1760, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1770, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1780, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1790, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1800, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1810, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1820, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1830, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1840, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1850, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1860, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1870, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1880, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1890, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1900, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1910, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1920, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1930, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1940, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1950, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1960, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1970, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1980, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1990, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2000, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2010, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2020, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2030, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2040, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2050, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2060, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2070, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2080, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2090, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2100, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2110, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2120, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2130, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2140, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2150, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2160, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2170, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2180, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2190, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2200, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2210, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2220, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2230, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2240, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2250, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2260, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2270, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2280, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2290, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2300, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2310, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2320, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2330, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2340, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2350, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2360, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2370, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2380, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2390, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2400, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2410, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2420, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2430, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2440, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2450, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2460, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2470, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2480, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2490, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2500, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2510, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2520, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2530, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2540, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2550, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2560, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2570, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2580, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2590, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2600, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2610, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2620, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2630, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2640, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2650, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2660, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2670, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2680, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2690, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2700, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2710, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2720, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2730, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2740, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2750, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2760, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2770, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2780, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2790, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2800, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2810, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2820, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2830, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2840, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2850, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2860, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2870, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2880, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2890, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2900, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2910, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2920, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2930, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2940, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2950, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2960, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2970, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2980, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2990, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 4: \n",
      "Epoch: 0, Minibatch Loss= 0.6946, Training Accuracy= 0.506\n",
      "Epoch: 10, Minibatch Loss= 0.6943, Training Accuracy= 0.504\n",
      "Epoch: 20, Minibatch Loss= 0.6943, Training Accuracy= 0.502\n",
      "Epoch: 30, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 40, Minibatch Loss= 0.6944, Training Accuracy= 0.503\n",
      "Epoch: 50, Minibatch Loss= 0.6944, Training Accuracy= 0.503\n",
      "Epoch: 60, Minibatch Loss= 0.6944, Training Accuracy= 0.503\n",
      "Epoch: 70, Minibatch Loss= 0.6944, Training Accuracy= 0.503\n",
      "Epoch: 80, Minibatch Loss= 0.6944, Training Accuracy= 0.503\n",
      "Epoch: 90, Minibatch Loss= 0.6944, Training Accuracy= 0.503\n",
      "Epoch: 100, Minibatch Loss= 0.6944, Training Accuracy= 0.503\n",
      "Epoch: 110, Minibatch Loss= 0.6944, Training Accuracy= 0.503\n",
      "Epoch: 120, Minibatch Loss= 0.6944, Training Accuracy= 0.503\n",
      "Epoch: 130, Minibatch Loss= 0.6944, Training Accuracy= 0.503\n",
      "Epoch: 140, Minibatch Loss= 0.6944, Training Accuracy= 0.503\n",
      "Epoch: 150, Minibatch Loss= 0.6944, Training Accuracy= 0.503\n",
      "Epoch: 160, Minibatch Loss= 0.6944, Training Accuracy= 0.503\n",
      "Epoch: 170, Minibatch Loss= 0.6944, Training Accuracy= 0.503\n",
      "Epoch: 180, Minibatch Loss= 0.6944, Training Accuracy= 0.503\n",
      "Epoch: 190, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 200, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 210, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 220, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 230, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 240, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 250, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 260, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 270, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 280, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 290, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 300, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 310, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 320, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 330, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 340, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 350, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 360, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 370, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 380, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 390, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 400, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 410, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 420, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 430, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 440, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 450, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 460, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 470, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 480, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 490, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 500, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 510, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 520, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 530, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 540, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 550, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 560, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 570, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 580, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 590, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 600, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 610, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 620, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 630, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 640, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 650, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 660, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 670, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 680, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 690, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 700, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 710, Minibatch Loss= 0.6941, Training Accuracy= 0.503\n",
      "Epoch: 720, Minibatch Loss= 0.6941, Training Accuracy= 0.503\n",
      "Epoch: 730, Minibatch Loss= 0.6941, Training Accuracy= 0.505\n",
      "Epoch: 740, Minibatch Loss= 0.6941, Training Accuracy= 0.505\n",
      "Epoch: 750, Minibatch Loss= 0.6941, Training Accuracy= 0.505\n",
      "Epoch: 760, Minibatch Loss= 0.6941, Training Accuracy= 0.505\n",
      "Epoch: 770, Minibatch Loss= 0.6941, Training Accuracy= 0.506\n",
      "Epoch: 780, Minibatch Loss= 0.6941, Training Accuracy= 0.505\n",
      "Epoch: 790, Minibatch Loss= 0.6941, Training Accuracy= 0.505\n",
      "Epoch: 800, Minibatch Loss= 0.6941, Training Accuracy= 0.505\n",
      "Epoch: 810, Minibatch Loss= 0.6941, Training Accuracy= 0.505\n",
      "Epoch: 820, Minibatch Loss= 0.6941, Training Accuracy= 0.507\n",
      "Epoch: 830, Minibatch Loss= 0.6941, Training Accuracy= 0.508\n",
      "Epoch: 840, Minibatch Loss= 0.6941, Training Accuracy= 0.508\n",
      "Epoch: 850, Minibatch Loss= 0.6941, Training Accuracy= 0.508\n",
      "Epoch: 860, Minibatch Loss= 0.6941, Training Accuracy= 0.508\n",
      "Epoch: 870, Minibatch Loss= 0.6941, Training Accuracy= 0.506\n",
      "Epoch: 880, Minibatch Loss= 0.6941, Training Accuracy= 0.504\n",
      "Epoch: 890, Minibatch Loss= 0.6941, Training Accuracy= 0.504\n",
      "Epoch: 900, Minibatch Loss= 0.6941, Training Accuracy= 0.502\n",
      "Epoch: 910, Minibatch Loss= 0.6941, Training Accuracy= 0.499\n",
      "Epoch: 920, Minibatch Loss= 0.6941, Training Accuracy= 0.498\n",
      "Epoch: 930, Minibatch Loss= 0.6941, Training Accuracy= 0.496\n",
      "Epoch: 940, Minibatch Loss= 0.6941, Training Accuracy= 0.492\n",
      "Epoch: 950, Minibatch Loss= 0.6941, Training Accuracy= 0.488\n",
      "Epoch: 960, Minibatch Loss= 0.6940, Training Accuracy= 0.483\n",
      "Epoch: 970, Minibatch Loss= 0.6940, Training Accuracy= 0.486\n",
      "Epoch: 980, Minibatch Loss= 0.6940, Training Accuracy= 0.486\n",
      "Epoch: 990, Minibatch Loss= 0.6939, Training Accuracy= 0.508\n",
      "Epoch: 1000, Minibatch Loss= 0.6936, Training Accuracy= 0.538\n",
      "Epoch: 1010, Minibatch Loss= 0.6888, Training Accuracy= 0.557\n",
      "Epoch: 1020, Minibatch Loss= 0.7570, Training Accuracy= 0.483\n",
      "Epoch: 1030, Minibatch Loss= 0.5856, Training Accuracy= 0.624\n",
      "Epoch: 1040, Minibatch Loss= 0.0117, Training Accuracy= 1.000\n",
      "Epoch: 1050, Minibatch Loss= 0.0037, Training Accuracy= 1.000\n",
      "Epoch: 1060, Minibatch Loss= 0.0023, Training Accuracy= 1.000\n",
      "Epoch: 1070, Minibatch Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 1080, Minibatch Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 1090, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1100, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1110, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1120, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1130, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1140, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1150, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1160, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1170, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1180, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1190, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1200, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1210, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1220, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1230, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1240, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1250, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1260, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1270, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1280, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1290, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1300, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1310, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1320, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1330, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1340, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1350, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1360, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1370, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1380, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1390, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1400, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1410, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1420, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1430, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1440, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1450, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1460, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1470, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1480, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1490, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1500, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1510, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1520, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1530, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1540, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1550, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1560, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1570, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1580, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1590, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1600, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1610, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1620, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1630, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1640, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1650, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1660, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1670, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1680, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1690, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1700, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1710, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1720, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1730, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1740, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1750, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1760, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1770, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1780, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1790, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1810, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1940, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1950, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1960, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1970, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1980, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 1990, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2000, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2010, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2020, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2030, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2040, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2050, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2060, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2070, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2080, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2090, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2100, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2110, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2120, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2130, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2140, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2150, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2160, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2170, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2180, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2190, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2200, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2210, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2220, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2230, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2240, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2250, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2260, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2270, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2280, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2290, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2300, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2310, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2320, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2330, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2340, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2350, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2360, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2370, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2380, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2390, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2400, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2410, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2420, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2430, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2440, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2450, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2460, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2470, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2480, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2490, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2500, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2510, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2520, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2530, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2540, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2550, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2560, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2570, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2580, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2590, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2600, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2610, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2620, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2630, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2640, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2650, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2660, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2670, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2680, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2690, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2700, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2710, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2720, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2730, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2740, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2750, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2760, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2770, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2780, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2790, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2800, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2810, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2820, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2830, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2840, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2850, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2860, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2870, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2880, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2890, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2900, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2910, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2920, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2930, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2940, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2950, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2960, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2970, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2980, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Epoch: 2990, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 5: \n",
      "Epoch: 0, Minibatch Loss= 0.6949, Training Accuracy= 0.498\n",
      "Epoch: 10, Minibatch Loss= 0.6940, Training Accuracy= 0.498\n",
      "Epoch: 20, Minibatch Loss= 0.6937, Training Accuracy= 0.498\n",
      "Epoch: 30, Minibatch Loss= 0.6936, Training Accuracy= 0.498\n",
      "Epoch: 40, Minibatch Loss= 0.6935, Training Accuracy= 0.498\n",
      "Epoch: 50, Minibatch Loss= 0.6935, Training Accuracy= 0.498\n",
      "Epoch: 60, Minibatch Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 70, Minibatch Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 80, Minibatch Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 90, Minibatch Loss= 0.6933, Training Accuracy= 0.498\n",
      "Epoch: 100, Minibatch Loss= 0.6933, Training Accuracy= 0.498\n",
      "Epoch: 110, Minibatch Loss= 0.6933, Training Accuracy= 0.498\n",
      "Epoch: 120, Minibatch Loss= 0.6933, Training Accuracy= 0.498\n",
      "Epoch: 130, Minibatch Loss= 0.6933, Training Accuracy= 0.498\n",
      "Epoch: 140, Minibatch Loss= 0.6933, Training Accuracy= 0.499\n",
      "Epoch: 150, Minibatch Loss= 0.6933, Training Accuracy= 0.498\n",
      "Epoch: 160, Minibatch Loss= 0.6933, Training Accuracy= 0.497\n",
      "Epoch: 170, Minibatch Loss= 0.6933, Training Accuracy= 0.498\n",
      "Epoch: 180, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 190, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 200, Minibatch Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 210, Minibatch Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 220, Minibatch Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 230, Minibatch Loss= 0.6932, Training Accuracy= 0.500\n",
      "Epoch: 240, Minibatch Loss= 0.6932, Training Accuracy= 0.491\n",
      "Epoch: 250, Minibatch Loss= 0.6932, Training Accuracy= 0.485\n",
      "Epoch: 260, Minibatch Loss= 0.6932, Training Accuracy= 0.486\n",
      "Epoch: 270, Minibatch Loss= 0.6932, Training Accuracy= 0.490\n",
      "Epoch: 280, Minibatch Loss= 0.6932, Training Accuracy= 0.495\n",
      "Epoch: 290, Minibatch Loss= 0.6932, Training Accuracy= 0.497\n",
      "Epoch: 300, Minibatch Loss= 0.6932, Training Accuracy= 0.498\n",
      "Epoch: 310, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 320, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 330, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 340, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 350, Minibatch Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 360, Minibatch Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 370, Minibatch Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 380, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 390, Minibatch Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 400, Minibatch Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 410, Minibatch Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 420, Minibatch Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 430, Minibatch Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 440, Minibatch Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 450, Minibatch Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 460, Minibatch Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 470, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 480, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 490, Minibatch Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 500, Minibatch Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 510, Minibatch Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 520, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 530, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 540, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 550, Minibatch Loss= 0.6931, Training Accuracy= 0.501\n",
      "Epoch: 560, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 570, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 580, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 590, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 600, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 610, Minibatch Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 620, Minibatch Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 630, Minibatch Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 640, Minibatch Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 650, Minibatch Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 660, Minibatch Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 670, Minibatch Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 680, Minibatch Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 690, Minibatch Loss= 0.6931, Training Accuracy= 0.513\n",
      "Epoch: 700, Minibatch Loss= 0.6931, Training Accuracy= 0.513\n",
      "Epoch: 710, Minibatch Loss= 0.6931, Training Accuracy= 0.510\n",
      "Epoch: 720, Minibatch Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 730, Minibatch Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 740, Minibatch Loss= 0.6931, Training Accuracy= 0.510\n",
      "Epoch: 750, Minibatch Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 760, Minibatch Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 770, Minibatch Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 780, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 790, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 800, Minibatch Loss= 0.6931, Training Accuracy= 0.501\n",
      "Epoch: 810, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 820, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 830, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 840, Minibatch Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 850, Minibatch Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 860, Minibatch Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 870, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 880, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 890, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 900, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 910, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 920, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 930, Minibatch Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 940, Minibatch Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 950, Minibatch Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 960, Minibatch Loss= 0.6931, Training Accuracy= 0.510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 970, Minibatch Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 980, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 990, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1000, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1010, Minibatch Loss= 0.6931, Training Accuracy= 0.499\n",
      "Epoch: 1020, Minibatch Loss= 0.6931, Training Accuracy= 0.492\n",
      "Epoch: 1030, Minibatch Loss= 0.6931, Training Accuracy= 0.494\n",
      "Epoch: 1040, Minibatch Loss= 0.6931, Training Accuracy= 0.494\n",
      "Epoch: 1050, Minibatch Loss= 0.6931, Training Accuracy= 0.496\n",
      "Epoch: 1060, Minibatch Loss= 0.6931, Training Accuracy= 0.493\n",
      "Epoch: 1070, Minibatch Loss= 0.6931, Training Accuracy= 0.491\n",
      "Epoch: 1080, Minibatch Loss= 0.6931, Training Accuracy= 0.484\n",
      "Epoch: 1090, Minibatch Loss= 0.6930, Training Accuracy= 0.484\n",
      "Epoch: 1100, Minibatch Loss= 0.6930, Training Accuracy= 0.489\n",
      "Epoch: 1110, Minibatch Loss= 0.6930, Training Accuracy= 0.499\n",
      "Epoch: 1120, Minibatch Loss= 0.6928, Training Accuracy= 0.508\n",
      "Epoch: 1130, Minibatch Loss= 0.6913, Training Accuracy= 0.489\n",
      "Epoch: 1140, Minibatch Loss= 0.6890, Training Accuracy= 0.555\n",
      "Epoch: 1150, Minibatch Loss= 0.5778, Training Accuracy= 0.571\n",
      "Epoch: 1160, Minibatch Loss= 0.3667, Training Accuracy= 0.813\n",
      "Epoch: 1170, Minibatch Loss= 0.2540, Training Accuracy= 0.857\n",
      "Epoch: 1180, Minibatch Loss= 0.1754, Training Accuracy= 0.929\n",
      "Epoch: 1190, Minibatch Loss= 0.1486, Training Accuracy= 0.931\n",
      "Epoch: 1200, Minibatch Loss= 0.1348, Training Accuracy= 0.931\n",
      "Epoch: 1210, Minibatch Loss= 0.1274, Training Accuracy= 0.942\n",
      "Epoch: 1220, Minibatch Loss= 0.1219, Training Accuracy= 0.950\n",
      "Epoch: 1230, Minibatch Loss= 0.1121, Training Accuracy= 0.951\n",
      "Epoch: 1240, Minibatch Loss= 0.0919, Training Accuracy= 0.930\n",
      "Epoch: 1250, Minibatch Loss= 0.0696, Training Accuracy= 0.981\n",
      "Epoch: 1260, Minibatch Loss= 0.0595, Training Accuracy= 0.983\n",
      "Epoch: 1270, Minibatch Loss= 0.0546, Training Accuracy= 0.984\n",
      "Epoch: 1280, Minibatch Loss= 0.0518, Training Accuracy= 0.987\n",
      "Epoch: 1290, Minibatch Loss= 0.0492, Training Accuracy= 0.988\n",
      "Epoch: 1300, Minibatch Loss= 0.0482, Training Accuracy= 0.988\n",
      "Epoch: 1310, Minibatch Loss= 0.6978, Training Accuracy= 0.498\n",
      "Epoch: 1320, Minibatch Loss= 0.6970, Training Accuracy= 0.498\n",
      "Epoch: 1330, Minibatch Loss= 0.6967, Training Accuracy= 0.498\n",
      "Epoch: 1340, Minibatch Loss= 0.6965, Training Accuracy= 0.498\n",
      "Epoch: 1350, Minibatch Loss= 0.6964, Training Accuracy= 0.498\n",
      "Epoch: 1360, Minibatch Loss= 0.6964, Training Accuracy= 0.498\n",
      "Epoch: 1370, Minibatch Loss= 0.6963, Training Accuracy= 0.498\n",
      "Epoch: 1380, Minibatch Loss= 0.6963, Training Accuracy= 0.498\n",
      "Epoch: 1390, Minibatch Loss= 0.6963, Training Accuracy= 0.498\n",
      "Epoch: 1400, Minibatch Loss= 0.6962, Training Accuracy= 0.498\n",
      "Epoch: 1410, Minibatch Loss= 0.6962, Training Accuracy= 0.498\n",
      "Epoch: 1420, Minibatch Loss= 0.6962, Training Accuracy= 0.498\n",
      "Epoch: 1430, Minibatch Loss= 0.6962, Training Accuracy= 0.498\n",
      "Epoch: 1440, Minibatch Loss= 0.6962, Training Accuracy= 0.498\n",
      "Epoch: 1450, Minibatch Loss= 0.6962, Training Accuracy= 0.498\n",
      "Epoch: 1460, Minibatch Loss= 0.6962, Training Accuracy= 0.498\n",
      "Epoch: 1470, Minibatch Loss= 0.6962, Training Accuracy= 0.498\n",
      "Epoch: 1480, Minibatch Loss= 0.6962, Training Accuracy= 0.498\n",
      "Epoch: 1490, Minibatch Loss= 0.6962, Training Accuracy= 0.498\n",
      "Epoch: 1500, Minibatch Loss= 0.6962, Training Accuracy= 0.498\n",
      "Epoch: 1510, Minibatch Loss= 0.6962, Training Accuracy= 0.498\n",
      "Epoch: 1520, Minibatch Loss= 0.6962, Training Accuracy= 0.498\n",
      "Epoch: 1530, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1540, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1550, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1560, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1570, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1580, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1590, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1600, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1610, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1620, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1630, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1640, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1650, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1660, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1670, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1680, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1690, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1700, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1710, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1720, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1730, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1740, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1750, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1760, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1770, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1780, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1790, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1800, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1810, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1820, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1830, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1840, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1850, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1860, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1870, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1880, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1890, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1900, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1910, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1920, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1930, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1940, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1950, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1960, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1970, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1980, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 1990, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2000, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2010, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2020, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2030, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2040, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2050, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2060, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2070, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2080, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2090, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2100, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2110, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2120, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2130, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2140, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2150, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2160, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2170, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2180, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2190, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2200, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2210, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2220, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2230, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2240, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2250, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2260, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2270, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2280, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2290, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2300, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2310, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2320, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2330, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2340, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2350, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2360, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2370, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2380, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2390, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2400, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2410, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2420, Minibatch Loss= 0.6961, Training Accuracy= 0.498\n",
      "Epoch: 2430, Minibatch Loss= 0.6960, Training Accuracy= 0.498\n",
      "Epoch: 2440, Minibatch Loss= 0.6960, Training Accuracy= 0.498\n",
      "Epoch: 2450, Minibatch Loss= 0.6960, Training Accuracy= 0.498\n",
      "Epoch: 2460, Minibatch Loss= 0.6960, Training Accuracy= 0.498\n",
      "Epoch: 2470, Minibatch Loss= 0.6960, Training Accuracy= 0.498\n",
      "Epoch: 2480, Minibatch Loss= 0.6960, Training Accuracy= 0.498\n",
      "Epoch: 2490, Minibatch Loss= 0.6960, Training Accuracy= 0.498\n",
      "Epoch: 2500, Minibatch Loss= 0.6960, Training Accuracy= 0.498\n",
      "Epoch: 2510, Minibatch Loss= 0.6960, Training Accuracy= 0.498\n",
      "Epoch: 2520, Minibatch Loss= 0.6960, Training Accuracy= 0.498\n",
      "Epoch: 2530, Minibatch Loss= 0.6960, Training Accuracy= 0.498\n",
      "Epoch: 2540, Minibatch Loss= 0.6960, Training Accuracy= 0.498\n",
      "Epoch: 2550, Minibatch Loss= 0.6960, Training Accuracy= 0.498\n",
      "Epoch: 2560, Minibatch Loss= 0.6960, Training Accuracy= 0.497\n",
      "Epoch: 2570, Minibatch Loss= 0.6960, Training Accuracy= 0.497\n",
      "Epoch: 2580, Minibatch Loss= 0.6960, Training Accuracy= 0.497\n",
      "Epoch: 2590, Minibatch Loss= 0.6960, Training Accuracy= 0.497\n",
      "Epoch: 2600, Minibatch Loss= 0.6960, Training Accuracy= 0.497\n",
      "Epoch: 2610, Minibatch Loss= 0.6960, Training Accuracy= 0.498\n",
      "Epoch: 2620, Minibatch Loss= 0.6960, Training Accuracy= 0.498\n",
      "Epoch: 2630, Minibatch Loss= 0.6960, Training Accuracy= 0.498\n",
      "Epoch: 2640, Minibatch Loss= 0.6960, Training Accuracy= 0.497\n",
      "Epoch: 2650, Minibatch Loss= 0.6960, Training Accuracy= 0.497\n",
      "Epoch: 2660, Minibatch Loss= 0.6960, Training Accuracy= 0.500\n",
      "Epoch: 2670, Minibatch Loss= 0.6960, Training Accuracy= 0.500\n",
      "Epoch: 2680, Minibatch Loss= 0.6960, Training Accuracy= 0.500\n",
      "Epoch: 2690, Minibatch Loss= 0.6960, Training Accuracy= 0.500\n",
      "Epoch: 2700, Minibatch Loss= 0.6960, Training Accuracy= 0.499\n",
      "Epoch: 2710, Minibatch Loss= 0.6960, Training Accuracy= 0.500\n",
      "Epoch: 2720, Minibatch Loss= 0.6959, Training Accuracy= 0.500\n",
      "Epoch: 2730, Minibatch Loss= 0.6959, Training Accuracy= 0.499\n",
      "Epoch: 2740, Minibatch Loss= 0.6959, Training Accuracy= 0.499\n",
      "Epoch: 2750, Minibatch Loss= 0.6959, Training Accuracy= 0.500\n",
      "Epoch: 2760, Minibatch Loss= 0.6959, Training Accuracy= 0.500\n",
      "Epoch: 2770, Minibatch Loss= 0.6959, Training Accuracy= 0.500\n",
      "Epoch: 2780, Minibatch Loss= 0.6959, Training Accuracy= 0.500\n",
      "Epoch: 2790, Minibatch Loss= 0.6958, Training Accuracy= 0.500\n",
      "Epoch: 2800, Minibatch Loss= 0.6958, Training Accuracy= 0.499\n",
      "Epoch: 2810, Minibatch Loss= 0.6958, Training Accuracy= 0.500\n",
      "Epoch: 2820, Minibatch Loss= 0.6958, Training Accuracy= 0.499\n",
      "Epoch: 2830, Minibatch Loss= 0.6958, Training Accuracy= 0.499\n",
      "Epoch: 2840, Minibatch Loss= 0.6958, Training Accuracy= 0.499\n",
      "Epoch: 2850, Minibatch Loss= 0.6958, Training Accuracy= 0.499\n",
      "Epoch: 2860, Minibatch Loss= 0.6958, Training Accuracy= 0.499\n",
      "Epoch: 2870, Minibatch Loss= 0.6957, Training Accuracy= 0.499\n",
      "Epoch: 2880, Minibatch Loss= 0.6957, Training Accuracy= 0.500\n",
      "Epoch: 2890, Minibatch Loss= 0.6957, Training Accuracy= 0.498\n",
      "Epoch: 2900, Minibatch Loss= 0.6957, Training Accuracy= 0.498\n",
      "Epoch: 2910, Minibatch Loss= 0.6957, Training Accuracy= 0.498\n",
      "Epoch: 2920, Minibatch Loss= 0.6957, Training Accuracy= 0.498\n",
      "Epoch: 2930, Minibatch Loss= 0.6957, Training Accuracy= 0.498\n",
      "Epoch: 2940, Minibatch Loss= 0.6957, Training Accuracy= 0.498\n",
      "Epoch: 2950, Minibatch Loss= 0.6957, Training Accuracy= 0.498\n",
      "Epoch: 2960, Minibatch Loss= 0.6957, Training Accuracy= 0.498\n",
      "Epoch: 2970, Minibatch Loss= 0.6957, Training Accuracy= 0.497\n",
      "Epoch: 2980, Minibatch Loss= 0.6956, Training Accuracy= 0.497\n",
      "Epoch: 2990, Minibatch Loss= 0.6955, Training Accuracy= 0.498\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5027\n",
      "Replication: 6: \n",
      "Epoch: 0, Minibatch Loss= 0.6945, Training Accuracy= 0.500\n",
      "Epoch: 10, Minibatch Loss= 0.6939, Training Accuracy= 0.500\n",
      "Epoch: 20, Minibatch Loss= 0.6938, Training Accuracy= 0.500\n",
      "Epoch: 30, Minibatch Loss= 0.6937, Training Accuracy= 0.500\n",
      "Epoch: 40, Minibatch Loss= 0.6937, Training Accuracy= 0.500\n",
      "Epoch: 50, Minibatch Loss= 0.6936, Training Accuracy= 0.500\n",
      "Epoch: 60, Minibatch Loss= 0.6936, Training Accuracy= 0.500\n",
      "Epoch: 70, Minibatch Loss= 0.6936, Training Accuracy= 0.500\n",
      "Epoch: 80, Minibatch Loss= 0.6936, Training Accuracy= 0.500\n",
      "Epoch: 90, Minibatch Loss= 0.6935, Training Accuracy= 0.499\n",
      "Epoch: 100, Minibatch Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 110, Minibatch Loss= 0.6935, Training Accuracy= 0.502\n",
      "Epoch: 120, Minibatch Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 130, Minibatch Loss= 0.6935, Training Accuracy= 0.501\n",
      "Epoch: 140, Minibatch Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 150, Minibatch Loss= 0.6934, Training Accuracy= 0.504\n",
      "Epoch: 160, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 170, Minibatch Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 180, Minibatch Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 190, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 200, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 210, Minibatch Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 220, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 230, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 240, Minibatch Loss= 0.6934, Training Accuracy= 0.504\n",
      "Epoch: 250, Minibatch Loss= 0.6934, Training Accuracy= 0.507\n",
      "Epoch: 260, Minibatch Loss= 0.6933, Training Accuracy= 0.507\n",
      "Epoch: 270, Minibatch Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 280, Minibatch Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 290, Minibatch Loss= 0.6933, Training Accuracy= 0.511\n",
      "Epoch: 300, Minibatch Loss= 0.6933, Training Accuracy= 0.513\n",
      "Epoch: 310, Minibatch Loss= 0.6933, Training Accuracy= 0.514\n",
      "Epoch: 320, Minibatch Loss= 0.6933, Training Accuracy= 0.518\n",
      "Epoch: 330, Minibatch Loss= 0.6933, Training Accuracy= 0.518\n",
      "Epoch: 340, Minibatch Loss= 0.6933, Training Accuracy= 0.518\n",
      "Epoch: 350, Minibatch Loss= 0.6933, Training Accuracy= 0.522\n",
      "Epoch: 360, Minibatch Loss= 0.6933, Training Accuracy= 0.522\n",
      "Epoch: 370, Minibatch Loss= 0.6933, Training Accuracy= 0.521\n",
      "Epoch: 380, Minibatch Loss= 0.6933, Training Accuracy= 0.523\n",
      "Epoch: 390, Minibatch Loss= 0.6933, Training Accuracy= 0.524\n",
      "Epoch: 400, Minibatch Loss= 0.6933, Training Accuracy= 0.525\n",
      "Epoch: 410, Minibatch Loss= 0.6933, Training Accuracy= 0.526\n",
      "Epoch: 420, Minibatch Loss= 0.6933, Training Accuracy= 0.529\n",
      "Epoch: 430, Minibatch Loss= 0.6933, Training Accuracy= 0.534\n",
      "Epoch: 440, Minibatch Loss= 0.6927, Training Accuracy= 0.543\n",
      "Epoch: 450, Minibatch Loss= 0.6785, Training Accuracy= 0.562\n",
      "Epoch: 460, Minibatch Loss= 0.6456, Training Accuracy= 0.591\n",
      "Epoch: 470, Minibatch Loss= 0.6050, Training Accuracy= 0.587\n",
      "Epoch: 480, Minibatch Loss= 0.6975, Training Accuracy= 0.507\n",
      "Epoch: 490, Minibatch Loss= 0.6956, Training Accuracy= 0.515\n",
      "Epoch: 500, Minibatch Loss= 0.6945, Training Accuracy= 0.523\n",
      "Epoch: 510, Minibatch Loss= 0.6929, Training Accuracy= 0.530\n",
      "Epoch: 520, Minibatch Loss= 0.6844, Training Accuracy= 0.528\n",
      "Epoch: 530, Minibatch Loss= 0.6972, Training Accuracy= 0.502\n",
      "Epoch: 540, Minibatch Loss= 0.6975, Training Accuracy= 0.510\n",
      "Epoch: 550, Minibatch Loss= 0.6547, Training Accuracy= 0.600\n",
      "Epoch: 560, Minibatch Loss= 0.6997, Training Accuracy= 0.502\n",
      "Epoch: 570, Minibatch Loss= 0.6720, Training Accuracy= 0.574\n",
      "Epoch: 580, Minibatch Loss= 0.0967, Training Accuracy= 0.990\n",
      "Epoch: 590, Minibatch Loss= 0.0346, Training Accuracy= 0.993\n",
      "Epoch: 600, Minibatch Loss= 0.0205, Training Accuracy= 0.996\n",
      "Epoch: 610, Minibatch Loss= 0.0134, Training Accuracy= 0.998\n",
      "Epoch: 620, Minibatch Loss= 0.0090, Training Accuracy= 0.999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 630, Minibatch Loss= 0.0063, Training Accuracy= 1.000\n",
      "Epoch: 640, Minibatch Loss= 0.0047, Training Accuracy= 1.000\n",
      "Epoch: 650, Minibatch Loss= 0.0037, Training Accuracy= 1.000\n",
      "Epoch: 660, Minibatch Loss= 0.0031, Training Accuracy= 1.000\n",
      "Epoch: 670, Minibatch Loss= 0.0026, Training Accuracy= 1.000\n",
      "Epoch: 680, Minibatch Loss= 0.0023, Training Accuracy= 1.000\n",
      "Epoch: 690, Minibatch Loss= 0.0020, Training Accuracy= 1.000\n",
      "Epoch: 700, Minibatch Loss= 0.0018, Training Accuracy= 1.000\n",
      "Epoch: 710, Minibatch Loss= 0.0016, Training Accuracy= 1.000\n",
      "Epoch: 720, Minibatch Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 730, Minibatch Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 740, Minibatch Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 750, Minibatch Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 760, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 770, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 780, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 790, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 800, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 810, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 820, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 830, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 840, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 850, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 860, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 870, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 880, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 890, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 900, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 910, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 920, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 930, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 940, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 950, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 960, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 970, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 980, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 990, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1000, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1010, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1020, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1030, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1040, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1050, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1060, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1070, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1080, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1090, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1100, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1110, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1120, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1130, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1140, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1150, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1160, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1170, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1180, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1190, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1200, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1210, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1220, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1230, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1240, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 1250, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1260, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1270, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1280, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1290, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1300, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1310, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1320, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1330, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1340, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1350, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1360, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1370, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1380, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1390, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1400, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1410, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1420, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1430, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1440, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1450, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1460, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1470, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1480, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1490, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1500, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1510, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1520, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1530, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1540, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1550, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1560, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1570, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1580, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1590, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1600, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1610, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1620, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1630, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1640, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1650, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 1660, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1670, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1680, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1690, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1700, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1710, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1720, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1730, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1740, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1750, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1760, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1770, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1780, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1790, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1810, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1940, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1950, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1960, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1970, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1980, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 1990, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2000, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2010, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2020, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2030, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2040, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2050, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2060, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2070, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2080, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2090, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2100, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2110, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2120, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2130, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2140, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2150, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2160, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2170, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2180, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2190, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2200, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2210, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2220, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2230, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2240, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2250, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2260, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2270, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2280, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2290, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2300, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2310, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2320, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2330, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2340, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2350, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2360, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2370, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2380, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2390, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2400, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2410, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2420, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2430, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2440, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2450, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2460, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2470, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2480, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2490, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2500, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2510, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2520, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2530, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2540, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2550, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2560, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2570, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2580, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2590, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2600, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2610, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2620, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2630, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2640, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2650, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2660, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2670, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2680, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2690, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2700, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2710, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2720, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2730, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2740, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2750, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2760, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2770, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2780, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2790, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2810, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2940, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2950, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2960, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2970, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2980, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2990, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n",
      "Replication: 7: \n",
      "Epoch: 0, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 10, Minibatch Loss= 0.6938, Training Accuracy= 0.497\n",
      "Epoch: 20, Minibatch Loss= 0.6938, Training Accuracy= 0.497\n",
      "Epoch: 30, Minibatch Loss= 0.6937, Training Accuracy= 0.497\n",
      "Epoch: 40, Minibatch Loss= 0.6937, Training Accuracy= 0.497\n",
      "Epoch: 50, Minibatch Loss= 0.6936, Training Accuracy= 0.497\n",
      "Epoch: 60, Minibatch Loss= 0.6936, Training Accuracy= 0.497\n",
      "Epoch: 70, Minibatch Loss= 0.6936, Training Accuracy= 0.497\n",
      "Epoch: 80, Minibatch Loss= 0.6936, Training Accuracy= 0.497\n",
      "Epoch: 90, Minibatch Loss= 0.6935, Training Accuracy= 0.497\n",
      "Epoch: 100, Minibatch Loss= 0.6935, Training Accuracy= 0.497\n",
      "Epoch: 110, Minibatch Loss= 0.6935, Training Accuracy= 0.497\n",
      "Epoch: 120, Minibatch Loss= 0.6935, Training Accuracy= 0.497\n",
      "Epoch: 130, Minibatch Loss= 0.6935, Training Accuracy= 0.497\n",
      "Epoch: 140, Minibatch Loss= 0.6935, Training Accuracy= 0.497\n",
      "Epoch: 150, Minibatch Loss= 0.6935, Training Accuracy= 0.497\n",
      "Epoch: 160, Minibatch Loss= 0.6935, Training Accuracy= 0.496\n",
      "Epoch: 170, Minibatch Loss= 0.6934, Training Accuracy= 0.496\n",
      "Epoch: 180, Minibatch Loss= 0.6934, Training Accuracy= 0.497\n",
      "Epoch: 190, Minibatch Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 200, Minibatch Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 210, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 220, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 230, Minibatch Loss= 0.6934, Training Accuracy= 0.508\n",
      "Epoch: 240, Minibatch Loss= 0.6934, Training Accuracy= 0.511\n",
      "Epoch: 250, Minibatch Loss= 0.6934, Training Accuracy= 0.509\n",
      "Epoch: 260, Minibatch Loss= 0.6934, Training Accuracy= 0.509\n",
      "Epoch: 270, Minibatch Loss= 0.6934, Training Accuracy= 0.508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 280, Minibatch Loss= 0.6934, Training Accuracy= 0.507\n",
      "Epoch: 290, Minibatch Loss= 0.6934, Training Accuracy= 0.505\n",
      "Epoch: 300, Minibatch Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 310, Minibatch Loss= 0.6934, Training Accuracy= 0.499\n",
      "Epoch: 320, Minibatch Loss= 0.6933, Training Accuracy= 0.499\n",
      "Epoch: 330, Minibatch Loss= 0.6933, Training Accuracy= 0.497\n",
      "Epoch: 340, Minibatch Loss= 0.6933, Training Accuracy= 0.493\n",
      "Epoch: 350, Minibatch Loss= 0.6933, Training Accuracy= 0.493\n",
      "Epoch: 360, Minibatch Loss= 0.6933, Training Accuracy= 0.490\n",
      "Epoch: 370, Minibatch Loss= 0.6933, Training Accuracy= 0.488\n",
      "Epoch: 380, Minibatch Loss= 0.6933, Training Accuracy= 0.488\n",
      "Epoch: 390, Minibatch Loss= 0.6933, Training Accuracy= 0.485\n",
      "Epoch: 400, Minibatch Loss= 0.6933, Training Accuracy= 0.482\n",
      "Epoch: 410, Minibatch Loss= 0.6933, Training Accuracy= 0.481\n",
      "Epoch: 420, Minibatch Loss= 0.6933, Training Accuracy= 0.481\n",
      "Epoch: 430, Minibatch Loss= 0.6933, Training Accuracy= 0.482\n",
      "Epoch: 440, Minibatch Loss= 0.6933, Training Accuracy= 0.481\n",
      "Epoch: 450, Minibatch Loss= 0.6933, Training Accuracy= 0.486\n",
      "Epoch: 460, Minibatch Loss= 0.6933, Training Accuracy= 0.486\n",
      "Epoch: 470, Minibatch Loss= 0.6933, Training Accuracy= 0.488\n",
      "Epoch: 480, Minibatch Loss= 0.6933, Training Accuracy= 0.490\n",
      "Epoch: 490, Minibatch Loss= 0.6933, Training Accuracy= 0.490\n",
      "Epoch: 500, Minibatch Loss= 0.6933, Training Accuracy= 0.489\n",
      "Epoch: 510, Minibatch Loss= 0.6933, Training Accuracy= 0.490\n",
      "Epoch: 520, Minibatch Loss= 0.6933, Training Accuracy= 0.490\n",
      "Epoch: 530, Minibatch Loss= 0.6933, Training Accuracy= 0.491\n",
      "Epoch: 540, Minibatch Loss= 0.6933, Training Accuracy= 0.490\n",
      "Epoch: 550, Minibatch Loss= 0.6933, Training Accuracy= 0.491\n",
      "Epoch: 560, Minibatch Loss= 0.6933, Training Accuracy= 0.488\n",
      "Epoch: 570, Minibatch Loss= 0.6933, Training Accuracy= 0.488\n",
      "Epoch: 580, Minibatch Loss= 0.6933, Training Accuracy= 0.490\n",
      "Epoch: 590, Minibatch Loss= 0.6932, Training Accuracy= 0.491\n",
      "Epoch: 600, Minibatch Loss= 0.6932, Training Accuracy= 0.495\n",
      "Epoch: 610, Minibatch Loss= 0.6932, Training Accuracy= 0.496\n",
      "Epoch: 620, Minibatch Loss= 0.6932, Training Accuracy= 0.497\n",
      "Epoch: 630, Minibatch Loss= 0.6932, Training Accuracy= 0.500\n",
      "Epoch: 640, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 650, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 660, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 670, Minibatch Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 680, Minibatch Loss= 0.6932, Training Accuracy= 0.499\n",
      "Epoch: 690, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 700, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 710, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 720, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 730, Minibatch Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 740, Minibatch Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 750, Minibatch Loss= 0.6931, Training Accuracy= 0.547\n",
      "Epoch: 760, Minibatch Loss= 0.6919, Training Accuracy= 0.493\n",
      "Epoch: 770, Minibatch Loss= 0.6010, Training Accuracy= 0.665\n",
      "Epoch: 780, Minibatch Loss= 0.7241, Training Accuracy= 0.507\n",
      "Epoch: 790, Minibatch Loss= 0.7062, Training Accuracy= 0.503\n",
      "Epoch: 800, Minibatch Loss= 0.6998, Training Accuracy= 0.503\n",
      "Epoch: 810, Minibatch Loss= 0.6979, Training Accuracy= 0.503\n",
      "Epoch: 820, Minibatch Loss= 0.6970, Training Accuracy= 0.503\n",
      "Epoch: 830, Minibatch Loss= 0.6964, Training Accuracy= 0.503\n",
      "Epoch: 840, Minibatch Loss= 0.6959, Training Accuracy= 0.503\n",
      "Epoch: 850, Minibatch Loss= 0.6956, Training Accuracy= 0.503\n",
      "Epoch: 860, Minibatch Loss= 0.6953, Training Accuracy= 0.503\n",
      "Epoch: 870, Minibatch Loss= 0.6950, Training Accuracy= 0.503\n",
      "Epoch: 880, Minibatch Loss= 0.6948, Training Accuracy= 0.503\n",
      "Epoch: 890, Minibatch Loss= 0.6947, Training Accuracy= 0.503\n",
      "Epoch: 900, Minibatch Loss= 0.6946, Training Accuracy= 0.503\n",
      "Epoch: 910, Minibatch Loss= 0.6945, Training Accuracy= 0.503\n",
      "Epoch: 920, Minibatch Loss= 0.6944, Training Accuracy= 0.503\n",
      "Epoch: 930, Minibatch Loss= 0.6944, Training Accuracy= 0.503\n",
      "Epoch: 940, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 950, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 960, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 970, Minibatch Loss= 0.6942, Training Accuracy= 0.503\n",
      "Epoch: 980, Minibatch Loss= 0.6941, Training Accuracy= 0.503\n",
      "Epoch: 990, Minibatch Loss= 0.6941, Training Accuracy= 0.503\n",
      "Epoch: 1000, Minibatch Loss= 0.6941, Training Accuracy= 0.503\n",
      "Epoch: 1010, Minibatch Loss= 0.6941, Training Accuracy= 0.503\n",
      "Epoch: 1020, Minibatch Loss= 0.6940, Training Accuracy= 0.503\n",
      "Epoch: 1030, Minibatch Loss= 0.6940, Training Accuracy= 0.503\n",
      "Epoch: 1040, Minibatch Loss= 0.6940, Training Accuracy= 0.503\n",
      "Epoch: 1050, Minibatch Loss= 0.6940, Training Accuracy= 0.503\n",
      "Epoch: 1060, Minibatch Loss= 0.6940, Training Accuracy= 0.503\n",
      "Epoch: 1070, Minibatch Loss= 0.6939, Training Accuracy= 0.503\n",
      "Epoch: 1080, Minibatch Loss= 0.6939, Training Accuracy= 0.503\n",
      "Epoch: 1090, Minibatch Loss= 0.6939, Training Accuracy= 0.503\n",
      "Epoch: 1100, Minibatch Loss= 0.6939, Training Accuracy= 0.503\n",
      "Epoch: 1110, Minibatch Loss= 0.6939, Training Accuracy= 0.503\n",
      "Epoch: 1120, Minibatch Loss= 0.6938, Training Accuracy= 0.503\n",
      "Epoch: 1130, Minibatch Loss= 0.6938, Training Accuracy= 0.503\n",
      "Epoch: 1140, Minibatch Loss= 0.6938, Training Accuracy= 0.503\n",
      "Epoch: 1150, Minibatch Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1160, Minibatch Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1170, Minibatch Loss= 0.6937, Training Accuracy= 0.503\n",
      "Epoch: 1180, Minibatch Loss= 0.6936, Training Accuracy= 0.503\n",
      "Epoch: 1190, Minibatch Loss= 0.6936, Training Accuracy= 0.503\n",
      "Epoch: 1200, Minibatch Loss= 0.6935, Training Accuracy= 0.503\n",
      "Epoch: 1210, Minibatch Loss= 0.6934, Training Accuracy= 0.503\n",
      "Epoch: 1220, Minibatch Loss= 0.6934, Training Accuracy= 0.502\n",
      "Epoch: 1230, Minibatch Loss= 0.6933, Training Accuracy= 0.508\n",
      "Epoch: 1240, Minibatch Loss= 0.6932, Training Accuracy= 0.495\n",
      "Epoch: 1250, Minibatch Loss= 0.6931, Training Accuracy= 0.510\n",
      "Epoch: 1260, Minibatch Loss= 0.6931, Training Accuracy= 0.488\n",
      "Epoch: 1270, Minibatch Loss= 0.6931, Training Accuracy= 0.500\n",
      "Epoch: 1280, Minibatch Loss= 0.6930, Training Accuracy= 0.517\n",
      "Epoch: 1290, Minibatch Loss= 0.6930, Training Accuracy= 0.525\n",
      "Epoch: 1300, Minibatch Loss= 0.6930, Training Accuracy= 0.515\n",
      "Epoch: 1310, Minibatch Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 1320, Minibatch Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 1330, Minibatch Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 1340, Minibatch Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 1350, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 1360, Minibatch Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 1370, Minibatch Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 1380, Minibatch Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 1390, Minibatch Loss= 0.6930, Training Accuracy= 0.499\n",
      "Epoch: 1400, Minibatch Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 1410, Minibatch Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 1420, Minibatch Loss= 0.6930, Training Accuracy= 0.519\n",
      "Epoch: 1430, Minibatch Loss= 0.6930, Training Accuracy= 0.523\n",
      "Epoch: 1440, Minibatch Loss= 0.6930, Training Accuracy= 0.528\n",
      "Epoch: 1450, Minibatch Loss= 0.6930, Training Accuracy= 0.533\n",
      "Epoch: 1460, Minibatch Loss= 0.6930, Training Accuracy= 0.533\n",
      "Epoch: 1470, Minibatch Loss= 0.6930, Training Accuracy= 0.533\n",
      "Epoch: 1480, Minibatch Loss= 0.6930, Training Accuracy= 0.529\n",
      "Epoch: 1490, Minibatch Loss= 0.6930, Training Accuracy= 0.523\n",
      "Epoch: 1500, Minibatch Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 1510, Minibatch Loss= 0.6930, Training Accuracy= 0.503\n",
      "Epoch: 1520, Minibatch Loss= 0.6930, Training Accuracy= 0.500\n",
      "Epoch: 1530, Minibatch Loss= 0.6930, Training Accuracy= 0.498\n",
      "Epoch: 1540, Minibatch Loss= 0.6930, Training Accuracy= 0.498\n",
      "Epoch: 1550, Minibatch Loss= 0.6930, Training Accuracy= 0.498\n",
      "Epoch: 1560, Minibatch Loss= 0.6930, Training Accuracy= 0.501\n",
      "Epoch: 1570, Minibatch Loss= 0.6930, Training Accuracy= 0.501\n",
      "Epoch: 1580, Minibatch Loss= 0.6930, Training Accuracy= 0.501\n",
      "Epoch: 1590, Minibatch Loss= 0.6930, Training Accuracy= 0.499\n",
      "Epoch: 1600, Minibatch Loss= 0.6930, Training Accuracy= 0.501\n",
      "Epoch: 1610, Minibatch Loss= 0.6930, Training Accuracy= 0.504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1620, Minibatch Loss= 0.6930, Training Accuracy= 0.512\n",
      "Epoch: 1630, Minibatch Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 1640, Minibatch Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 1650, Minibatch Loss= 0.6930, Training Accuracy= 0.498\n",
      "Epoch: 1660, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 1670, Minibatch Loss= 0.6930, Training Accuracy= 0.523\n",
      "Epoch: 1680, Minibatch Loss= 0.6930, Training Accuracy= 0.533\n",
      "Epoch: 1690, Minibatch Loss= 0.6931, Training Accuracy= 0.516\n",
      "Epoch: 1700, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1710, Minibatch Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 1720, Minibatch Loss= 0.6931, Training Accuracy= 0.518\n",
      "Epoch: 1730, Minibatch Loss= 0.6931, Training Accuracy= 0.521\n",
      "Epoch: 1740, Minibatch Loss= 0.6931, Training Accuracy= 0.520\n",
      "Epoch: 1750, Minibatch Loss= 0.6932, Training Accuracy= 0.518\n",
      "Epoch: 1760, Minibatch Loss= 0.6932, Training Accuracy= 0.515\n",
      "Epoch: 1770, Minibatch Loss= 0.6932, Training Accuracy= 0.516\n",
      "Epoch: 1780, Minibatch Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 1790, Minibatch Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 1800, Minibatch Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 1810, Minibatch Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 1820, Minibatch Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 1830, Minibatch Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 1840, Minibatch Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 1850, Minibatch Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 1860, Minibatch Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 1870, Minibatch Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 1880, Minibatch Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 1890, Minibatch Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 1900, Minibatch Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 1910, Minibatch Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 1920, Minibatch Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 1930, Minibatch Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 1940, Minibatch Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 1950, Minibatch Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 1960, Minibatch Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 1970, Minibatch Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 1980, Minibatch Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 1990, Minibatch Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 2000, Minibatch Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 2010, Minibatch Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 2020, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 2030, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 2040, Minibatch Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 2050, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 2060, Minibatch Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 2070, Minibatch Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 2080, Minibatch Loss= 0.6932, Training Accuracy= 0.500\n",
      "Epoch: 2090, Minibatch Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 2100, Minibatch Loss= 0.6932, Training Accuracy= 0.500\n",
      "Epoch: 2110, Minibatch Loss= 0.6932, Training Accuracy= 0.500\n",
      "Epoch: 2120, Minibatch Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 2130, Minibatch Loss= 0.6932, Training Accuracy= 0.500\n",
      "Epoch: 2140, Minibatch Loss= 0.6932, Training Accuracy= 0.499\n",
      "Epoch: 2150, Minibatch Loss= 0.6932, Training Accuracy= 0.498\n",
      "Epoch: 2160, Minibatch Loss= 0.6932, Training Accuracy= 0.497\n",
      "Epoch: 2170, Minibatch Loss= 0.6932, Training Accuracy= 0.497\n",
      "Epoch: 2180, Minibatch Loss= 0.6932, Training Accuracy= 0.498\n",
      "Epoch: 2190, Minibatch Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 2200, Minibatch Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 2210, Minibatch Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 2220, Minibatch Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 2230, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 2240, Minibatch Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 2250, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 2260, Minibatch Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 2270, Minibatch Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 2280, Minibatch Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 2290, Minibatch Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 2300, Minibatch Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 2310, Minibatch Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 2320, Minibatch Loss= 0.6932, Training Accuracy= 0.512\n",
      "Epoch: 2330, Minibatch Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 2340, Minibatch Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 2350, Minibatch Loss= 0.6932, Training Accuracy= 0.512\n",
      "Epoch: 2360, Minibatch Loss= 0.6932, Training Accuracy= 0.512\n",
      "Epoch: 2370, Minibatch Loss= 0.6932, Training Accuracy= 0.513\n",
      "Epoch: 2380, Minibatch Loss= 0.6932, Training Accuracy= 0.512\n",
      "Epoch: 2390, Minibatch Loss= 0.6932, Training Accuracy= 0.513\n",
      "Epoch: 2400, Minibatch Loss= 0.6932, Training Accuracy= 0.514\n",
      "Epoch: 2410, Minibatch Loss= 0.6932, Training Accuracy= 0.513\n",
      "Epoch: 2420, Minibatch Loss= 0.6932, Training Accuracy= 0.512\n",
      "Epoch: 2430, Minibatch Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 2440, Minibatch Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 2450, Minibatch Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 2460, Minibatch Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 2470, Minibatch Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 2480, Minibatch Loss= 0.6932, Training Accuracy= 0.512\n",
      "Epoch: 2490, Minibatch Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 2500, Minibatch Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 2510, Minibatch Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 2520, Minibatch Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 2530, Minibatch Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 2540, Minibatch Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 2550, Minibatch Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 2560, Minibatch Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 2570, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 2580, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 2590, Minibatch Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 2600, Minibatch Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 2610, Minibatch Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 2620, Minibatch Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 2630, Minibatch Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 2640, Minibatch Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 2650, Minibatch Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 2660, Minibatch Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 2670, Minibatch Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 2680, Minibatch Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 2690, Minibatch Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 2700, Minibatch Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 2710, Minibatch Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 2720, Minibatch Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 2730, Minibatch Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 2740, Minibatch Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 2750, Minibatch Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 2760, Minibatch Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 2770, Minibatch Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 2780, Minibatch Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 2790, Minibatch Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 2800, Minibatch Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 2810, Minibatch Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 2820, Minibatch Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 2830, Minibatch Loss= 0.6932, Training Accuracy= 0.508\n",
      "Epoch: 2840, Minibatch Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 2850, Minibatch Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 2860, Minibatch Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 2870, Minibatch Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 2880, Minibatch Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 2890, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 2900, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 2910, Minibatch Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 2920, Minibatch Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 2930, Minibatch Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 2940, Minibatch Loss= 0.6931, Training Accuracy= 0.510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2950, Minibatch Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 2960, Minibatch Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 2970, Minibatch Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 2980, Minibatch Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 2990, Minibatch Loss= 0.6931, Training Accuracy= 0.507\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4956\n",
      "Replication: 8: \n",
      "Epoch: 0, Minibatch Loss= 0.6936, Training Accuracy= 0.498\n",
      "Epoch: 10, Minibatch Loss= 0.6939, Training Accuracy= 0.498\n",
      "Epoch: 20, Minibatch Loss= 0.6938, Training Accuracy= 0.498\n",
      "Epoch: 30, Minibatch Loss= 0.6937, Training Accuracy= 0.498\n",
      "Epoch: 40, Minibatch Loss= 0.6937, Training Accuracy= 0.498\n",
      "Epoch: 50, Minibatch Loss= 0.6936, Training Accuracy= 0.498\n",
      "Epoch: 60, Minibatch Loss= 0.6936, Training Accuracy= 0.498\n",
      "Epoch: 70, Minibatch Loss= 0.6935, Training Accuracy= 0.498\n",
      "Epoch: 80, Minibatch Loss= 0.6935, Training Accuracy= 0.498\n",
      "Epoch: 90, Minibatch Loss= 0.6935, Training Accuracy= 0.498\n",
      "Epoch: 100, Minibatch Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 110, Minibatch Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 120, Minibatch Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 130, Minibatch Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 140, Minibatch Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 150, Minibatch Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 160, Minibatch Loss= 0.6934, Training Accuracy= 0.498\n",
      "Epoch: 170, Minibatch Loss= 0.6933, Training Accuracy= 0.500\n",
      "Epoch: 180, Minibatch Loss= 0.6933, Training Accuracy= 0.499\n",
      "Epoch: 190, Minibatch Loss= 0.6933, Training Accuracy= 0.499\n",
      "Epoch: 200, Minibatch Loss= 0.6933, Training Accuracy= 0.499\n",
      "Epoch: 210, Minibatch Loss= 0.6933, Training Accuracy= 0.498\n",
      "Epoch: 220, Minibatch Loss= 0.6933, Training Accuracy= 0.497\n",
      "Epoch: 230, Minibatch Loss= 0.6933, Training Accuracy= 0.497\n",
      "Epoch: 240, Minibatch Loss= 0.6933, Training Accuracy= 0.498\n",
      "Epoch: 250, Minibatch Loss= 0.6933, Training Accuracy= 0.500\n",
      "Epoch: 260, Minibatch Loss= 0.6933, Training Accuracy= 0.500\n",
      "Epoch: 270, Minibatch Loss= 0.6933, Training Accuracy= 0.500\n",
      "Epoch: 280, Minibatch Loss= 0.6933, Training Accuracy= 0.501\n",
      "Epoch: 290, Minibatch Loss= 0.6933, Training Accuracy= 0.501\n",
      "Epoch: 300, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 310, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 320, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 330, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 340, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 350, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 360, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 370, Minibatch Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 380, Minibatch Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 390, Minibatch Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 400, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 410, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 420, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 430, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 440, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 450, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 460, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 470, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 480, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 490, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 500, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 510, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 520, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 530, Minibatch Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 540, Minibatch Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 550, Minibatch Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 560, Minibatch Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 570, Minibatch Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 580, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 590, Minibatch Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 600, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 610, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 620, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 630, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 640, Minibatch Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 650, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 660, Minibatch Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 670, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 680, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 690, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 700, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 710, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 720, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 730, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 740, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 750, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 760, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 770, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 780, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 790, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 800, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 810, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 820, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 830, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 840, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 850, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 860, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 870, Minibatch Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 880, Minibatch Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 890, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 900, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 910, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 920, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 930, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 940, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 950, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 960, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 970, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 980, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 990, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1000, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1010, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1020, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1030, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1040, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1050, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1060, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1070, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1080, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 1090, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 1100, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 1110, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1120, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1130, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1140, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1150, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1160, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1170, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1180, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1190, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1200, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1210, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1220, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1230, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1240, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1250, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1260, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1270, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1280, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1290, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 1300, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1310, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1320, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1330, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1340, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1350, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 1360, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1370, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1380, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1390, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1400, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1410, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1420, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1430, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1440, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1450, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1460, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1470, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1480, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1490, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1500, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1510, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1520, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1530, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1540, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1550, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1560, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1570, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1580, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1590, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1600, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1610, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1620, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1630, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1640, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 1650, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1660, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1670, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 1680, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 1690, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 1700, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 1710, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 1720, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 1730, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 1740, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 1750, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 1760, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 1770, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 1780, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 1790, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 1800, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 1810, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 1820, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 1830, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 1840, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 1850, Minibatch Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 1860, Minibatch Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 1870, Minibatch Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 1880, Minibatch Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 1890, Minibatch Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 1900, Minibatch Loss= 0.6930, Training Accuracy= 0.502\n",
      "Epoch: 1910, Minibatch Loss= 0.6930, Training Accuracy= 0.501\n",
      "Epoch: 1920, Minibatch Loss= 0.6930, Training Accuracy= 0.501\n",
      "Epoch: 1930, Minibatch Loss= 0.6930, Training Accuracy= 0.499\n",
      "Epoch: 1940, Minibatch Loss= 0.6930, Training Accuracy= 0.499\n",
      "Epoch: 1950, Minibatch Loss= 0.6930, Training Accuracy= 0.499\n",
      "Epoch: 1960, Minibatch Loss= 0.6930, Training Accuracy= 0.498\n",
      "Epoch: 1970, Minibatch Loss= 0.6930, Training Accuracy= 0.498\n",
      "Epoch: 1980, Minibatch Loss= 0.6930, Training Accuracy= 0.498\n",
      "Epoch: 1990, Minibatch Loss= 0.6930, Training Accuracy= 0.496\n",
      "Epoch: 2000, Minibatch Loss= 0.6930, Training Accuracy= 0.494\n",
      "Epoch: 2010, Minibatch Loss= 0.6930, Training Accuracy= 0.494\n",
      "Epoch: 2020, Minibatch Loss= 0.6930, Training Accuracy= 0.494\n",
      "Epoch: 2030, Minibatch Loss= 0.6930, Training Accuracy= 0.493\n",
      "Epoch: 2040, Minibatch Loss= 0.6930, Training Accuracy= 0.493\n",
      "Epoch: 2050, Minibatch Loss= 0.6930, Training Accuracy= 0.493\n",
      "Epoch: 2060, Minibatch Loss= 0.6930, Training Accuracy= 0.490\n",
      "Epoch: 2070, Minibatch Loss= 0.6930, Training Accuracy= 0.488\n",
      "Epoch: 2080, Minibatch Loss= 0.6930, Training Accuracy= 0.489\n",
      "Epoch: 2090, Minibatch Loss= 0.6930, Training Accuracy= 0.489\n",
      "Epoch: 2100, Minibatch Loss= 0.6930, Training Accuracy= 0.491\n",
      "Epoch: 2110, Minibatch Loss= 0.6930, Training Accuracy= 0.491\n",
      "Epoch: 2120, Minibatch Loss= 0.6930, Training Accuracy= 0.489\n",
      "Epoch: 2130, Minibatch Loss= 0.6930, Training Accuracy= 0.491\n",
      "Epoch: 2140, Minibatch Loss= 0.6930, Training Accuracy= 0.493\n",
      "Epoch: 2150, Minibatch Loss= 0.6930, Training Accuracy= 0.494\n",
      "Epoch: 2160, Minibatch Loss= 0.6930, Training Accuracy= 0.495\n",
      "Epoch: 2170, Minibatch Loss= 0.6930, Training Accuracy= 0.496\n",
      "Epoch: 2180, Minibatch Loss= 0.6930, Training Accuracy= 0.497\n",
      "Epoch: 2190, Minibatch Loss= 0.6929, Training Accuracy= 0.496\n",
      "Epoch: 2200, Minibatch Loss= 0.6929, Training Accuracy= 0.498\n",
      "Epoch: 2210, Minibatch Loss= 0.6929, Training Accuracy= 0.498\n",
      "Epoch: 2220, Minibatch Loss= 0.6929, Training Accuracy= 0.498\n",
      "Epoch: 2230, Minibatch Loss= 0.6929, Training Accuracy= 0.499\n",
      "Epoch: 2240, Minibatch Loss= 0.6929, Training Accuracy= 0.501\n",
      "Epoch: 2250, Minibatch Loss= 0.6929, Training Accuracy= 0.503\n",
      "Epoch: 2260, Minibatch Loss= 0.6929, Training Accuracy= 0.502\n",
      "Epoch: 2270, Minibatch Loss= 0.6929, Training Accuracy= 0.505\n",
      "Epoch: 2280, Minibatch Loss= 0.6929, Training Accuracy= 0.502\n",
      "Epoch: 2290, Minibatch Loss= 0.6928, Training Accuracy= 0.504\n",
      "Epoch: 2300, Minibatch Loss= 0.6928, Training Accuracy= 0.503\n",
      "Epoch: 2310, Minibatch Loss= 0.6926, Training Accuracy= 0.506\n",
      "Epoch: 2320, Minibatch Loss= 0.6921, Training Accuracy= 0.525\n",
      "Epoch: 2330, Minibatch Loss= 0.6873, Training Accuracy= 0.521\n",
      "Epoch: 2340, Minibatch Loss= 0.6121, Training Accuracy= 0.532\n",
      "Epoch: 2350, Minibatch Loss= 0.6400, Training Accuracy= 0.683\n",
      "Epoch: 2360, Minibatch Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 2370, Minibatch Loss= 0.6935, Training Accuracy= 0.498\n",
      "Epoch: 2380, Minibatch Loss= 0.6965, Training Accuracy= 0.498\n",
      "Epoch: 2390, Minibatch Loss= 0.6977, Training Accuracy= 0.500\n",
      "Epoch: 2400, Minibatch Loss= 0.6930, Training Accuracy= 0.498\n",
      "Epoch: 2410, Minibatch Loss= 0.6932, Training Accuracy= 0.498\n",
      "Epoch: 2420, Minibatch Loss= 0.6932, Training Accuracy= 0.499\n",
      "Epoch: 2430, Minibatch Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 2440, Minibatch Loss= 0.6932, Training Accuracy= 0.500\n",
      "Epoch: 2450, Minibatch Loss= 0.6932, Training Accuracy= 0.497\n",
      "Epoch: 2460, Minibatch Loss= 0.6932, Training Accuracy= 0.498\n",
      "Epoch: 2470, Minibatch Loss= 0.6932, Training Accuracy= 0.500\n",
      "Epoch: 2480, Minibatch Loss= 0.6932, Training Accuracy= 0.500\n",
      "Epoch: 2490, Minibatch Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 2500, Minibatch Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 2510, Minibatch Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 2520, Minibatch Loss= 0.6932, Training Accuracy= 0.496\n",
      "Epoch: 2530, Minibatch Loss= 0.6932, Training Accuracy= 0.499\n",
      "Epoch: 2540, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 2550, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 2560, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 2570, Minibatch Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 2580, Minibatch Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 2590, Minibatch Loss= 0.6932, Training Accuracy= 0.506\n",
      "Epoch: 2600, Minibatch Loss= 0.6932, Training Accuracy= 0.505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2610, Minibatch Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 2620, Minibatch Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 2630, Minibatch Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 2640, Minibatch Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 2650, Minibatch Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 2660, Minibatch Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 2670, Minibatch Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 2680, Minibatch Loss= 0.6932, Training Accuracy= 0.505\n",
      "Epoch: 2690, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 2700, Minibatch Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 2710, Minibatch Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 2720, Minibatch Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 2730, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 2740, Minibatch Loss= 0.6933, Training Accuracy= 0.502\n",
      "Epoch: 2750, Minibatch Loss= 0.6933, Training Accuracy= 0.503\n",
      "Epoch: 2760, Minibatch Loss= 0.6933, Training Accuracy= 0.505\n",
      "Epoch: 2770, Minibatch Loss= 0.6933, Training Accuracy= 0.508\n",
      "Epoch: 2780, Minibatch Loss= 0.6933, Training Accuracy= 0.507\n",
      "Epoch: 2790, Minibatch Loss= 0.6933, Training Accuracy= 0.511\n",
      "Epoch: 2800, Minibatch Loss= 0.6933, Training Accuracy= 0.511\n",
      "Epoch: 2810, Minibatch Loss= 0.6933, Training Accuracy= 0.511\n",
      "Epoch: 2820, Minibatch Loss= 0.6933, Training Accuracy= 0.512\n",
      "Epoch: 2830, Minibatch Loss= 0.6933, Training Accuracy= 0.511\n",
      "Epoch: 2840, Minibatch Loss= 0.6933, Training Accuracy= 0.508\n",
      "Epoch: 2850, Minibatch Loss= 0.6933, Training Accuracy= 0.507\n",
      "Epoch: 2860, Minibatch Loss= 0.6933, Training Accuracy= 0.508\n",
      "Epoch: 2870, Minibatch Loss= 0.6933, Training Accuracy= 0.508\n",
      "Epoch: 2880, Minibatch Loss= 0.6933, Training Accuracy= 0.511\n",
      "Epoch: 2890, Minibatch Loss= 0.6933, Training Accuracy= 0.512\n",
      "Epoch: 2900, Minibatch Loss= 0.6933, Training Accuracy= 0.515\n",
      "Epoch: 2910, Minibatch Loss= 0.6933, Training Accuracy= 0.515\n",
      "Epoch: 2920, Minibatch Loss= 0.6933, Training Accuracy= 0.514\n",
      "Epoch: 2930, Minibatch Loss= 0.6933, Training Accuracy= 0.513\n",
      "Epoch: 2940, Minibatch Loss= 0.6933, Training Accuracy= 0.512\n",
      "Epoch: 2950, Minibatch Loss= 0.6933, Training Accuracy= 0.513\n",
      "Epoch: 2960, Minibatch Loss= 0.6933, Training Accuracy= 0.512\n",
      "Epoch: 2970, Minibatch Loss= 0.6933, Training Accuracy= 0.513\n",
      "Epoch: 2980, Minibatch Loss= 0.6933, Training Accuracy= 0.512\n",
      "Epoch: 2990, Minibatch Loss= 0.6933, Training Accuracy= 0.510\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4976\n",
      "Replication: 9: \n",
      "Epoch: 0, Minibatch Loss= 0.7329, Training Accuracy= 0.497\n",
      "Epoch: 10, Minibatch Loss= 0.7125, Training Accuracy= 0.497\n",
      "Epoch: 20, Minibatch Loss= 0.7092, Training Accuracy= 0.497\n",
      "Epoch: 30, Minibatch Loss= 0.7075, Training Accuracy= 0.497\n",
      "Epoch: 40, Minibatch Loss= 0.7064, Training Accuracy= 0.497\n",
      "Epoch: 50, Minibatch Loss= 0.7056, Training Accuracy= 0.497\n",
      "Epoch: 60, Minibatch Loss= 0.7049, Training Accuracy= 0.497\n",
      "Epoch: 70, Minibatch Loss= 0.7043, Training Accuracy= 0.497\n",
      "Epoch: 80, Minibatch Loss= 0.7038, Training Accuracy= 0.497\n",
      "Epoch: 90, Minibatch Loss= 0.7034, Training Accuracy= 0.497\n",
      "Epoch: 100, Minibatch Loss= 0.7030, Training Accuracy= 0.497\n",
      "Epoch: 110, Minibatch Loss= 0.7027, Training Accuracy= 0.497\n",
      "Epoch: 120, Minibatch Loss= 0.7024, Training Accuracy= 0.497\n",
      "Epoch: 130, Minibatch Loss= 0.7022, Training Accuracy= 0.497\n",
      "Epoch: 140, Minibatch Loss= 0.7020, Training Accuracy= 0.497\n",
      "Epoch: 150, Minibatch Loss= 0.7018, Training Accuracy= 0.497\n",
      "Epoch: 160, Minibatch Loss= 0.7016, Training Accuracy= 0.497\n",
      "Epoch: 170, Minibatch Loss= 0.7014, Training Accuracy= 0.497\n",
      "Epoch: 180, Minibatch Loss= 0.7013, Training Accuracy= 0.497\n",
      "Epoch: 190, Minibatch Loss= 0.7011, Training Accuracy= 0.497\n",
      "Epoch: 200, Minibatch Loss= 0.7010, Training Accuracy= 0.497\n",
      "Epoch: 210, Minibatch Loss= 0.7009, Training Accuracy= 0.497\n",
      "Epoch: 220, Minibatch Loss= 0.7008, Training Accuracy= 0.497\n",
      "Epoch: 230, Minibatch Loss= 0.7007, Training Accuracy= 0.497\n",
      "Epoch: 240, Minibatch Loss= 0.7006, Training Accuracy= 0.497\n",
      "Epoch: 250, Minibatch Loss= 0.7005, Training Accuracy= 0.497\n",
      "Epoch: 260, Minibatch Loss= 0.7004, Training Accuracy= 0.497\n",
      "Epoch: 270, Minibatch Loss= 0.7004, Training Accuracy= 0.497\n",
      "Epoch: 280, Minibatch Loss= 0.7003, Training Accuracy= 0.497\n",
      "Epoch: 290, Minibatch Loss= 0.7003, Training Accuracy= 0.497\n",
      "Epoch: 300, Minibatch Loss= 0.7002, Training Accuracy= 0.497\n",
      "Epoch: 310, Minibatch Loss= 0.7001, Training Accuracy= 0.497\n",
      "Epoch: 320, Minibatch Loss= 0.7001, Training Accuracy= 0.497\n",
      "Epoch: 330, Minibatch Loss= 0.7001, Training Accuracy= 0.497\n",
      "Epoch: 340, Minibatch Loss= 0.7000, Training Accuracy= 0.497\n",
      "Epoch: 350, Minibatch Loss= 0.7000, Training Accuracy= 0.497\n",
      "Epoch: 360, Minibatch Loss= 0.6999, Training Accuracy= 0.497\n",
      "Epoch: 370, Minibatch Loss= 0.6999, Training Accuracy= 0.497\n",
      "Epoch: 380, Minibatch Loss= 0.6999, Training Accuracy= 0.497\n",
      "Epoch: 390, Minibatch Loss= 0.6998, Training Accuracy= 0.497\n",
      "Epoch: 400, Minibatch Loss= 0.6998, Training Accuracy= 0.497\n",
      "Epoch: 410, Minibatch Loss= 0.6998, Training Accuracy= 0.497\n",
      "Epoch: 420, Minibatch Loss= 0.6998, Training Accuracy= 0.497\n",
      "Epoch: 430, Minibatch Loss= 0.6997, Training Accuracy= 0.497\n",
      "Epoch: 440, Minibatch Loss= 0.6997, Training Accuracy= 0.497\n",
      "Epoch: 450, Minibatch Loss= 0.6997, Training Accuracy= 0.497\n",
      "Epoch: 460, Minibatch Loss= 0.6997, Training Accuracy= 0.497\n",
      "Epoch: 470, Minibatch Loss= 0.6997, Training Accuracy= 0.497\n",
      "Epoch: 480, Minibatch Loss= 0.6996, Training Accuracy= 0.497\n",
      "Epoch: 490, Minibatch Loss= 0.6996, Training Accuracy= 0.497\n",
      "Epoch: 500, Minibatch Loss= 0.6996, Training Accuracy= 0.497\n",
      "Epoch: 510, Minibatch Loss= 0.6996, Training Accuracy= 0.497\n",
      "Epoch: 520, Minibatch Loss= 0.6996, Training Accuracy= 0.497\n",
      "Epoch: 530, Minibatch Loss= 0.6996, Training Accuracy= 0.497\n",
      "Epoch: 540, Minibatch Loss= 0.6995, Training Accuracy= 0.497\n",
      "Epoch: 550, Minibatch Loss= 0.6995, Training Accuracy= 0.497\n",
      "Epoch: 560, Minibatch Loss= 0.6995, Training Accuracy= 0.497\n",
      "Epoch: 570, Minibatch Loss= 0.6995, Training Accuracy= 0.497\n",
      "Epoch: 580, Minibatch Loss= 0.6995, Training Accuracy= 0.497\n",
      "Epoch: 590, Minibatch Loss= 0.6995, Training Accuracy= 0.497\n",
      "Epoch: 600, Minibatch Loss= 0.6995, Training Accuracy= 0.497\n",
      "Epoch: 610, Minibatch Loss= 0.6995, Training Accuracy= 0.497\n",
      "Epoch: 620, Minibatch Loss= 0.6995, Training Accuracy= 0.497\n",
      "Epoch: 630, Minibatch Loss= 0.6994, Training Accuracy= 0.497\n",
      "Epoch: 640, Minibatch Loss= 0.6994, Training Accuracy= 0.497\n",
      "Epoch: 650, Minibatch Loss= 0.6994, Training Accuracy= 0.497\n",
      "Epoch: 660, Minibatch Loss= 0.6994, Training Accuracy= 0.497\n",
      "Epoch: 670, Minibatch Loss= 0.6994, Training Accuracy= 0.497\n",
      "Epoch: 680, Minibatch Loss= 0.6994, Training Accuracy= 0.497\n",
      "Epoch: 690, Minibatch Loss= 0.6994, Training Accuracy= 0.497\n",
      "Epoch: 700, Minibatch Loss= 0.6994, Training Accuracy= 0.497\n",
      "Epoch: 710, Minibatch Loss= 0.6994, Training Accuracy= 0.497\n",
      "Epoch: 720, Minibatch Loss= 0.6994, Training Accuracy= 0.497\n",
      "Epoch: 730, Minibatch Loss= 0.6994, Training Accuracy= 0.497\n",
      "Epoch: 740, Minibatch Loss= 0.6994, Training Accuracy= 0.497\n",
      "Epoch: 750, Minibatch Loss= 0.6994, Training Accuracy= 0.497\n",
      "Epoch: 760, Minibatch Loss= 0.6994, Training Accuracy= 0.497\n",
      "Epoch: 770, Minibatch Loss= 0.6994, Training Accuracy= 0.497\n",
      "Epoch: 780, Minibatch Loss= 0.6994, Training Accuracy= 0.497\n",
      "Epoch: 790, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 800, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 810, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 820, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 830, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 840, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 850, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 860, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 870, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 880, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 890, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 900, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 910, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 920, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 930, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 940, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 950, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 960, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 970, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 980, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 990, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 1000, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 1010, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 1020, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 1030, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 1040, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 1050, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 1060, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 1070, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 1080, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 1090, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 1100, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 1110, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 1120, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 1130, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 1140, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 1150, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 1160, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 1170, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 1180, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 1190, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 1200, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 1210, Minibatch Loss= 0.6993, Training Accuracy= 0.497\n",
      "Epoch: 1220, Minibatch Loss= 0.6992, Training Accuracy= 0.497\n",
      "Epoch: 1230, Minibatch Loss= 0.6992, Training Accuracy= 0.497\n",
      "Epoch: 1240, Minibatch Loss= 0.6992, Training Accuracy= 0.497\n",
      "Epoch: 1250, Minibatch Loss= 0.6992, Training Accuracy= 0.497\n",
      "Epoch: 1260, Minibatch Loss= 0.6992, Training Accuracy= 0.497\n",
      "Epoch: 1270, Minibatch Loss= 0.6992, Training Accuracy= 0.497\n",
      "Epoch: 1280, Minibatch Loss= 0.6992, Training Accuracy= 0.497\n",
      "Epoch: 1290, Minibatch Loss= 0.6992, Training Accuracy= 0.497\n",
      "Epoch: 1300, Minibatch Loss= 0.6992, Training Accuracy= 0.497\n",
      "Epoch: 1310, Minibatch Loss= 0.6992, Training Accuracy= 0.497\n",
      "Epoch: 1320, Minibatch Loss= 0.6992, Training Accuracy= 0.497\n",
      "Epoch: 1330, Minibatch Loss= 0.6991, Training Accuracy= 0.497\n",
      "Epoch: 1340, Minibatch Loss= 0.6991, Training Accuracy= 0.497\n",
      "Epoch: 1350, Minibatch Loss= 0.6990, Training Accuracy= 0.497\n",
      "Epoch: 1360, Minibatch Loss= 0.6986, Training Accuracy= 0.495\n",
      "Epoch: 1370, Minibatch Loss= 0.6937, Training Accuracy= 0.550\n",
      "Epoch: 1380, Minibatch Loss= 0.5472, Training Accuracy= 0.565\n",
      "Epoch: 1390, Minibatch Loss= 0.4390, Training Accuracy= 0.702\n",
      "Epoch: 1400, Minibatch Loss= 0.3917, Training Accuracy= 0.795\n",
      "Epoch: 1410, Minibatch Loss= 0.3281, Training Accuracy= 0.862\n",
      "Epoch: 1420, Minibatch Loss= 0.1935, Training Accuracy= 0.909\n",
      "Epoch: 1430, Minibatch Loss= 0.1502, Training Accuracy= 0.937\n",
      "Epoch: 1440, Minibatch Loss= 0.0820, Training Accuracy= 0.967\n",
      "Epoch: 1450, Minibatch Loss= 0.0564, Training Accuracy= 0.970\n",
      "Epoch: 1460, Minibatch Loss= 0.0237, Training Accuracy= 0.996\n",
      "Epoch: 1470, Minibatch Loss= 0.0146, Training Accuracy= 0.998\n",
      "Epoch: 1480, Minibatch Loss= 0.0108, Training Accuracy= 0.998\n",
      "Epoch: 1490, Minibatch Loss= 0.0073, Training Accuracy= 0.999\n",
      "Epoch: 1500, Minibatch Loss= 0.0060, Training Accuracy= 0.999\n",
      "Epoch: 1510, Minibatch Loss= 0.0052, Training Accuracy= 0.999\n",
      "Epoch: 1520, Minibatch Loss= 0.0048, Training Accuracy= 0.999\n",
      "Epoch: 1530, Minibatch Loss= 0.0039, Training Accuracy= 0.999\n",
      "Epoch: 1540, Minibatch Loss= 0.0038, Training Accuracy= 0.999\n",
      "Epoch: 1550, Minibatch Loss= 0.0034, Training Accuracy= 0.999\n",
      "Epoch: 1560, Minibatch Loss= 0.0026, Training Accuracy= 1.000\n",
      "Epoch: 1570, Minibatch Loss= 0.0024, Training Accuracy= 1.000\n",
      "Epoch: 1580, Minibatch Loss= 0.0021, Training Accuracy= 1.000\n",
      "Epoch: 1590, Minibatch Loss= 0.0019, Training Accuracy= 1.000\n",
      "Epoch: 1600, Minibatch Loss= 0.0017, Training Accuracy= 1.000\n",
      "Epoch: 1610, Minibatch Loss= 0.0015, Training Accuracy= 1.000\n",
      "Epoch: 1620, Minibatch Loss= 0.0014, Training Accuracy= 1.000\n",
      "Epoch: 1630, Minibatch Loss= 0.0013, Training Accuracy= 1.000\n",
      "Epoch: 1640, Minibatch Loss= 0.0012, Training Accuracy= 1.000\n",
      "Epoch: 1650, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1660, Minibatch Loss= 0.0011, Training Accuracy= 1.000\n",
      "Epoch: 1670, Minibatch Loss= 0.0010, Training Accuracy= 1.000\n",
      "Epoch: 1680, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1690, Minibatch Loss= 0.0009, Training Accuracy= 1.000\n",
      "Epoch: 1700, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1710, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1720, Minibatch Loss= 0.0008, Training Accuracy= 1.000\n",
      "Epoch: 1730, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1740, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1750, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1760, Minibatch Loss= 0.0007, Training Accuracy= 1.000\n",
      "Epoch: 1770, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1780, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1790, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1800, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1810, Minibatch Loss= 0.0006, Training Accuracy= 1.000\n",
      "Epoch: 1820, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1830, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1840, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1850, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1860, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1870, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1880, Minibatch Loss= 0.0005, Training Accuracy= 1.000\n",
      "Epoch: 1890, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1900, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1910, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1920, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1930, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1940, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1950, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1960, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1970, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1980, Minibatch Loss= 0.0004, Training Accuracy= 1.000\n",
      "Epoch: 1990, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2000, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2010, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2020, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2030, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2040, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2050, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2060, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2070, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2080, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2090, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2100, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2110, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2120, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2130, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2140, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2150, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2160, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2170, Minibatch Loss= 0.0003, Training Accuracy= 1.000\n",
      "Epoch: 2180, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2190, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2200, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2210, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2220, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2230, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2240, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2250, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2260, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2270, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2280, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2290, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2300, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2310, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2320, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2330, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2340, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2350, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2360, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2370, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2380, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2390, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2400, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2410, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2420, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2430, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2440, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2450, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2460, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2470, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2480, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2490, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2500, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2510, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2520, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2530, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2540, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2550, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2560, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2570, Minibatch Loss= 0.0002, Training Accuracy= 1.000\n",
      "Epoch: 2580, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2590, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2600, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2610, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2620, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2630, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2640, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2650, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2660, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2670, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2680, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2690, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2700, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2710, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2720, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2730, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2740, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2750, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2760, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2770, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2780, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2790, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2800, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2810, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2820, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2830, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2840, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2850, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2860, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2870, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2880, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2890, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2900, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2910, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2920, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2930, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2940, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2950, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2960, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2970, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2980, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Epoch: 2990, Minibatch Loss= 0.0001, Training Accuracy= 1.000\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.35\n",
    "batch_size = 128\n",
    "display_step = batch_size * 100\n",
    "\n",
    "#batch_steps = 10000 / batch_size\n",
    "epochs = 3000\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1 # \n",
    "timesteps = N # timesteps\n",
    "num_hidden = H # hidden layer num of features\n",
    "num_classes = 2 # 0 or 1\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "#prediction = tf.nn.softmax(logits)\n",
    "prediction = tf.tanh(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "test_accuracies_10replications = []\n",
    "losses_1st_replication = [] #epoch as unit\n",
    "test_accuracies_1st_replication = [] #epoch as unit\n",
    "train_accuracies_1st_replication = [] #epoch as unit\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run 10 replications\n",
    "    for replication in range(10):\n",
    "        \n",
    "        print(\"Replication: %d: \" % replication)\n",
    "        \n",
    "        # Initialize random weights\n",
    "        train_data = generate_parity_sequences(N, 10000)\n",
    "        train_data_x = train_data[0]\n",
    "        train_data_y = train_data[1]\n",
    "        test_data = generate_parity_sequences(N, 10000)\n",
    "        test_data_x = test_data[0]\n",
    "        test_data_y = test_data[1]\n",
    "        \n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            batch_index = 0\n",
    "            while batch_index < 10000:\n",
    "\n",
    "                train_data_batch_x = []\n",
    "                train_data_batch_y = []\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_x[batch_index : batch_index + batch_size]\n",
    "                    train_data_batch_y = train_data_y[batch_index : batch_index + batch_size]\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_x[batch_index : ]\n",
    "                    train_data_batch_y = train_data_y[batch_index : ]\n",
    "\n",
    "                #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                # Reshape data to get 28 seq of 28 elements\n",
    "                #batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                #train_data_x = train_data_x.reshape((10000, timesteps, num_input))\n",
    "                #print(\"train_data_batch_x.shape:  \" , train_data_batch_x.shape)\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_batch_x.reshape((10000 % batch_size, timesteps, num_input))\n",
    "                # Run optimization op (backprop)\n",
    "                #sess.run(train_op, feed_dict={X: train_data_x, \n",
    "                 #                             Y: train_data_y})\n",
    "                sess.run(train_op, feed_dict={X: train_data_batch_x, \n",
    "                                              Y: train_data_batch_y})\n",
    "\n",
    "                batch_index += batch_size\n",
    "\n",
    "            if replication == 0:\n",
    "                loss, train_accuracy = sess.run([loss_op, accuracy], feed_dict={X: train_data_x, Y: train_data_y})\n",
    "                test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "                minibatch_losses_1st_replication.append(loss)\n",
    "                train_accuracies_1st_replication.append(train_accuracy)\n",
    "                test_accuracies_1st_replication.append(test_accuracy)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: train_data_x,\n",
    "                                                                         Y: train_data_y})\n",
    "                print(\"Epoch: \" + str(epoch) + \\\n",
    "                          \", Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        test_data_x = test_data_x.reshape((-1, timesteps, num_input))\n",
    "        test_data_y = test_data_y\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "        test_accuracies_10replications.append(test_accuracy)\n",
    "        print(\"Testing Accuracy:\", test_accuracy)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracies_10replications:  [1.0, 0.50639999, 0.4975, 1.0, 1.0, 0.50269997, 1.0, 0.49559999, 0.49759999, 1.0]\n",
      "mean of test_accuracies_10replications:  0.74998\n",
      "standard deviation of test_accuracies_10replications_std_mean:  0.00250035911798\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "test_accuracies_10replications_std = np.std(test_accuracies_10replications, axis=0)\n",
    "test_accuracies_10replications_std_mean = test_accuracies_10replications_std / np.square(10)\n",
    "print(\"test_accuracies_10replications: \", test_accuracies_10replications)\n",
    "print(\"mean of test_accuracies_10replications: \", np.mean(test_accuracies_10replications))\n",
    "print(\"standard deviation of test_accuracies_10replications_std_mean: \", test_accuracies_10replications_std_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEoCAYAAABPQRaPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff05ddd47d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses_1st_replication\n",
    "plt.plot(losses_1st_replication, color='green', linewidth=5)\n",
    "plt.plot(trdd3c867662ecc159febcca779dd76481d891859bain_accuracies_1st_replication, color='blue', linewidth=7)\n",
    "plt.plot(test_accuracies_1st_replication, color='red', linewidth=3)\n",
    "plt.xlim(0, epochs)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.ylabel(\"train acc in blue, test acc in red, loss in green\")\n",
    "plt.title(\"1st replication\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
