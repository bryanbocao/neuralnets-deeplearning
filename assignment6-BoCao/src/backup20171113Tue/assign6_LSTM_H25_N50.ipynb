{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "Reference:\n",
    "    http://www.deeplearning.net/tutorial/lstm.html#lstm\n",
    "    https://github.com/llSourcell/LSTM_Networks/blob/master/LSTM%20Demo.ipynb\n",
    "    https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/recurrent_network.py\n",
    "    Recurrent Neural Network.\n",
    "    A Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\n",
    "    This example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\n",
    "    Links:\n",
    "    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\n",
    "    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\n",
    "    Author: Aymeric Damien\n",
    "    Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module\n",
    "\n",
    "H = 25\n",
    "N = 50\n",
    "\n",
    "#Reference: Denis\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    return np.expand_dims(sequences, axis=2), y\n",
    "\n",
    "#Reference: Modified from Denis by Bo Cao\n",
    "def generate_parity_sequences(N, count):\n",
    "    \"\"\"\n",
    "    Generate :count: sequences of length :N:.\n",
    "    If odd # of 1's -> output 1\n",
    "    else -> output 0\n",
    "    \"\"\"\n",
    "    xor = lambda x: 1 if (x % 2 == 1) else 0\n",
    "    sequences = np.random.choice([0, 1], size=[count, N], replace=True)\n",
    "    counts = np.count_nonzero(sequences == 1, axis=1)\n",
    "    # xor each sequence, expand dimensions by 1 to match sequences shape\n",
    "    y = np.expand_dims(np.array([xor(x) for x in counts]), axis=1)\n",
    "\n",
    "    # In case if you wanted to have the answer just appended at the end of the sequence:\n",
    "    #     # append the answer at the end of each sequence\n",
    "    #     seq_plus_y = np.concatenate([sequences, y], axis=1)\n",
    "    #     print(sequences.shape, y.shape, seq_plus_y.shape)\n",
    "    #     return seq_plus_y\n",
    "    \n",
    "    new_y = []\n",
    "    for i in range(len(y)):\n",
    "        new_yy = []\n",
    "        if y[i] == 0:\n",
    "            new_yy.append(0)\n",
    "            new_yy.append(1)\n",
    "        else:\n",
    "            new_yy.append(1)\n",
    "            new_yy.append(0)\n",
    "        new_y.append(new_yy)\n",
    "\n",
    "    return np.expand_dims(sequences, axis=2), new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication: 0: \n",
      "Epoch: 0, Minibatch Loss= 0.8090, Training Accuracy= 0.499\n",
      "Epoch: 10, Minibatch Loss= 0.7167, Training Accuracy= 0.499\n",
      "Epoch: 20, Minibatch Loss= 0.7074, Training Accuracy= 0.499\n",
      "Epoch: 30, Minibatch Loss= 0.7035, Training Accuracy= 0.499\n",
      "Epoch: 40, Minibatch Loss= 0.7013, Training Accuracy= 0.499\n",
      "Epoch: 50, Minibatch Loss= 0.6998, Training Accuracy= 0.499\n",
      "Epoch: 60, Minibatch Loss= 0.6988, Training Accuracy= 0.499\n",
      "Epoch: 70, Minibatch Loss= 0.6981, Training Accuracy= 0.499\n",
      "Epoch: 80, Minibatch Loss= 0.6975, Training Accuracy= 0.499\n",
      "Epoch: 90, Minibatch Loss= 0.6971, Training Accuracy= 0.499\n",
      "Epoch: 100, Minibatch Loss= 0.6967, Training Accuracy= 0.499\n",
      "Epoch: 110, Minibatch Loss= 0.6964, Training Accuracy= 0.499\n",
      "Epoch: 120, Minibatch Loss= 0.6962, Training Accuracy= 0.499\n",
      "Epoch: 130, Minibatch Loss= 0.6959, Training Accuracy= 0.499\n",
      "Epoch: 140, Minibatch Loss= 0.6958, Training Accuracy= 0.499\n",
      "Epoch: 150, Minibatch Loss= 0.6956, Training Accuracy= 0.499\n",
      "Epoch: 160, Minibatch Loss= 0.6954, Training Accuracy= 0.499\n",
      "Epoch: 170, Minibatch Loss= 0.6953, Training Accuracy= 0.499\n",
      "Epoch: 180, Minibatch Loss= 0.6952, Training Accuracy= 0.499\n",
      "Epoch: 190, Minibatch Loss= 0.6951, Training Accuracy= 0.499\n",
      "Epoch: 200, Minibatch Loss= 0.6950, Training Accuracy= 0.499\n",
      "Epoch: 210, Minibatch Loss= 0.6949, Training Accuracy= 0.499\n",
      "Epoch: 220, Minibatch Loss= 0.6948, Training Accuracy= 0.499\n",
      "Epoch: 230, Minibatch Loss= 0.6948, Training Accuracy= 0.499\n",
      "Epoch: 240, Minibatch Loss= 0.6947, Training Accuracy= 0.499\n",
      "Epoch: 250, Minibatch Loss= 0.6946, Training Accuracy= 0.499\n",
      "Epoch: 260, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 270, Minibatch Loss= 0.6945, Training Accuracy= 0.499\n",
      "Epoch: 280, Minibatch Loss= 0.6944, Training Accuracy= 0.499\n",
      "Epoch: 290, Minibatch Loss= 0.6944, Training Accuracy= 0.499\n",
      "Epoch: 300, Minibatch Loss= 0.6943, Training Accuracy= 0.500\n",
      "Epoch: 310, Minibatch Loss= 0.6943, Training Accuracy= 0.501\n",
      "Epoch: 320, Minibatch Loss= 0.6942, Training Accuracy= 0.501\n",
      "Epoch: 330, Minibatch Loss= 0.6942, Training Accuracy= 0.501\n",
      "Epoch: 340, Minibatch Loss= 0.6941, Training Accuracy= 0.501\n",
      "Epoch: 350, Minibatch Loss= 0.6940, Training Accuracy= 0.500\n",
      "Epoch: 360, Minibatch Loss= 0.6940, Training Accuracy= 0.499\n",
      "Epoch: 370, Minibatch Loss= 0.6939, Training Accuracy= 0.501\n",
      "Epoch: 380, Minibatch Loss= 0.6938, Training Accuracy= 0.501\n",
      "Epoch: 390, Minibatch Loss= 0.6937, Training Accuracy= 0.500\n",
      "Epoch: 400, Minibatch Loss= 0.6936, Training Accuracy= 0.505\n",
      "Epoch: 410, Minibatch Loss= 0.6935, Training Accuracy= 0.508\n",
      "Epoch: 420, Minibatch Loss= 0.6934, Training Accuracy= 0.509\n",
      "Epoch: 430, Minibatch Loss= 0.6933, Training Accuracy= 0.507\n",
      "Epoch: 440, Minibatch Loss= 0.6932, Training Accuracy= 0.507\n",
      "Epoch: 450, Minibatch Loss= 0.6932, Training Accuracy= 0.509\n",
      "Epoch: 460, Minibatch Loss= 0.6931, Training Accuracy= 0.511\n",
      "Epoch: 470, Minibatch Loss= 0.6929, Training Accuracy= 0.511\n",
      "Epoch: 480, Minibatch Loss= 0.6927, Training Accuracy= 0.516\n",
      "Epoch: 490, Minibatch Loss= 0.6924, Training Accuracy= 0.521\n",
      "Epoch: 500, Minibatch Loss= 0.6922, Training Accuracy= 0.525\n",
      "Epoch: 510, Minibatch Loss= 0.6919, Training Accuracy= 0.518\n",
      "Epoch: 520, Minibatch Loss= 0.6923, Training Accuracy= 0.520\n",
      "Epoch: 530, Minibatch Loss= 0.6921, Training Accuracy= 0.526\n",
      "Epoch: 540, Minibatch Loss= 0.6929, Training Accuracy= 0.525\n",
      "Epoch: 550, Minibatch Loss= 0.6915, Training Accuracy= 0.531\n",
      "Epoch: 560, Minibatch Loss= 0.6941, Training Accuracy= 0.530\n",
      "Epoch: 570, Minibatch Loss= 0.6945, Training Accuracy= 0.523\n",
      "Epoch: 580, Minibatch Loss= 0.6954, Training Accuracy= 0.525\n",
      "Epoch: 590, Minibatch Loss= 0.6928, Training Accuracy= 0.534\n",
      "Epoch: 600, Minibatch Loss= 0.6888, Training Accuracy= 0.542\n",
      "Epoch: 610, Minibatch Loss= 0.6889, Training Accuracy= 0.544\n",
      "Epoch: 620, Minibatch Loss= 0.6895, Training Accuracy= 0.547\n",
      "Epoch: 630, Minibatch Loss= 0.6891, Training Accuracy= 0.546\n",
      "Epoch: 640, Minibatch Loss= 0.6948, Training Accuracy= 0.537\n",
      "Epoch: 650, Minibatch Loss= 0.6891, Training Accuracy= 0.550\n",
      "Epoch: 660, Minibatch Loss= 0.6869, Training Accuracy= 0.555\n",
      "Epoch: 670, Minibatch Loss= 0.6927, Training Accuracy= 0.542\n",
      "Epoch: 680, Minibatch Loss= 0.7021, Training Accuracy= 0.520\n",
      "Epoch: 690, Minibatch Loss= 0.6967, Training Accuracy= 0.508\n",
      "Epoch: 700, Minibatch Loss= 0.7172, Training Accuracy= 0.499\n",
      "Epoch: 710, Minibatch Loss= 0.7058, Training Accuracy= 0.499\n",
      "Epoch: 720, Minibatch Loss= 0.7082, Training Accuracy= 0.499\n",
      "Epoch: 730, Minibatch Loss= 0.7054, Training Accuracy= 0.499\n",
      "Epoch: 740, Minibatch Loss= 0.7033, Training Accuracy= 0.499\n",
      "Epoch: 750, Minibatch Loss= 0.7018, Training Accuracy= 0.499\n",
      "Epoch: 760, Minibatch Loss= 0.7008, Training Accuracy= 0.499\n",
      "Epoch: 770, Minibatch Loss= 0.6999, Training Accuracy= 0.499\n",
      "Epoch: 780, Minibatch Loss= 0.6990, Training Accuracy= 0.500\n",
      "Epoch: 790, Minibatch Loss= 0.6978, Training Accuracy= 0.500\n",
      "Epoch: 800, Minibatch Loss= 0.6973, Training Accuracy= 0.503\n",
      "Epoch: 810, Minibatch Loss= 0.6968, Training Accuracy= 0.504\n",
      "Epoch: 820, Minibatch Loss= 0.6961, Training Accuracy= 0.505\n",
      "Epoch: 830, Minibatch Loss= 0.6955, Training Accuracy= 0.509\n",
      "Epoch: 840, Minibatch Loss= 0.6951, Training Accuracy= 0.511\n",
      "Epoch: 850, Minibatch Loss= 0.6946, Training Accuracy= 0.515\n",
      "Epoch: 860, Minibatch Loss= 0.6941, Training Accuracy= 0.518\n",
      "Epoch: 870, Minibatch Loss= 0.6937, Training Accuracy= 0.520\n",
      "Epoch: 880, Minibatch Loss= 0.6932, Training Accuracy= 0.523\n",
      "Epoch: 890, Minibatch Loss= 0.6918, Training Accuracy= 0.528\n",
      "Epoch: 900, Minibatch Loss= 0.6939, Training Accuracy= 0.526\n",
      "Epoch: 910, Minibatch Loss= 0.6895, Training Accuracy= 0.532\n",
      "Epoch: 920, Minibatch Loss= 0.6899, Training Accuracy= 0.530\n",
      "Epoch: 930, Minibatch Loss= 0.6872, Training Accuracy= 0.539\n",
      "Epoch: 940, Minibatch Loss= 0.6856, Training Accuracy= 0.542\n",
      "Epoch: 950, Minibatch Loss= 0.6871, Training Accuracy= 0.542\n",
      "Epoch: 960, Minibatch Loss= 0.6899, Training Accuracy= 0.538\n",
      "Epoch: 970, Minibatch Loss= 0.6885, Training Accuracy= 0.544\n",
      "Epoch: 980, Minibatch Loss= 0.6825, Training Accuracy= 0.553\n",
      "Epoch: 990, Minibatch Loss= 0.6825, Training Accuracy= 0.555\n",
      "Epoch: 1000, Minibatch Loss= 0.6795, Training Accuracy= 0.563\n",
      "Epoch: 1010, Minibatch Loss= 0.6812, Training Accuracy= 0.561\n",
      "Epoch: 1020, Minibatch Loss= 0.6860, Training Accuracy= 0.554\n",
      "Epoch: 1030, Minibatch Loss= 0.6833, Training Accuracy= 0.555\n",
      "Epoch: 1040, Minibatch Loss= 0.6827, Training Accuracy= 0.562\n",
      "Epoch: 1050, Minibatch Loss= 0.6939, Training Accuracy= 0.528\n",
      "Epoch: 1060, Minibatch Loss= 0.6796, Training Accuracy= 0.560\n",
      "Epoch: 1070, Minibatch Loss= 0.6733, Training Accuracy= 0.573\n",
      "Epoch: 1080, Minibatch Loss= 0.6784, Training Accuracy= 0.564\n",
      "Epoch: 1090, Minibatch Loss= 0.6746, Training Accuracy= 0.568\n",
      "Epoch: 1100, Minibatch Loss= 0.6735, Training Accuracy= 0.574\n",
      "Epoch: 1110, Minibatch Loss= 0.6676, Training Accuracy= 0.582\n",
      "Epoch: 1120, Minibatch Loss= 0.6571, Training Accuracy= 0.597\n",
      "Epoch: 1130, Minibatch Loss= 0.6819, Training Accuracy= 0.552\n",
      "Epoch: 1140, Minibatch Loss= 0.6716, Training Accuracy= 0.582\n",
      "Epoch: 1150, Minibatch Loss= 0.6625, Training Accuracy= 0.591\n",
      "Epoch: 1160, Minibatch Loss= 0.6786, Training Accuracy= 0.568\n",
      "Epoch: 1170, Minibatch Loss= 0.6628, Training Accuracy= 0.588\n",
      "Epoch: 1180, Minibatch Loss= 0.6565, Training Accuracy= 0.604\n",
      "Epoch: 1190, Minibatch Loss= 0.6841, Training Accuracy= 0.545\n",
      "Epoch: 1200, Minibatch Loss= 0.6536, Training Accuracy= 0.604\n",
      "Epoch: 1210, Minibatch Loss= 0.6559, Training Accuracy= 0.594\n",
      "Epoch: 1220, Minibatch Loss= 0.6624, Training Accuracy= 0.590\n",
      "Epoch: 1230, Minibatch Loss= 0.6557, Training Accuracy= 0.603\n",
      "Epoch: 1240, Minibatch Loss= 0.6856, Training Accuracy= 0.558\n",
      "Epoch: 1250, Minibatch Loss= 0.6662, Training Accuracy= 0.584\n",
      "Epoch: 1260, Minibatch Loss= 0.6485, Training Accuracy= 0.608\n",
      "Epoch: 1270, Minibatch Loss= 0.6496, Training Accuracy= 0.604\n",
      "Epoch: 1280, Minibatch Loss= 0.6744, Training Accuracy= 0.581\n",
      "Epoch: 1290, Minibatch Loss= 0.6458, Training Accuracy= 0.612\n",
      "Epoch: 1300, Minibatch Loss= 0.6609, Training Accuracy= 0.602\n",
      "Epoch: 1310, Minibatch Loss= 0.6774, Training Accuracy= 0.573\n",
      "Epoch: 1320, Minibatch Loss= 0.6509, Training Accuracy= 0.612\n",
      "Epoch: 1330, Minibatch Loss= 0.7092, Training Accuracy= 0.533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1340, Minibatch Loss= 0.6428, Training Accuracy= 0.619\n",
      "Epoch: 1350, Minibatch Loss= 0.6484, Training Accuracy= 0.611\n",
      "Epoch: 1360, Minibatch Loss= 0.6966, Training Accuracy= 0.569\n",
      "Epoch: 1370, Minibatch Loss= 0.6573, Training Accuracy= 0.604\n",
      "Epoch: 1380, Minibatch Loss= 0.6739, Training Accuracy= 0.581\n",
      "Epoch: 1390, Minibatch Loss= 0.6342, Training Accuracy= 0.628\n",
      "Epoch: 1400, Minibatch Loss= 0.6404, Training Accuracy= 0.616\n",
      "Epoch: 1410, Minibatch Loss= 0.6388, Training Accuracy= 0.622\n",
      "Epoch: 1420, Minibatch Loss= 0.6550, Training Accuracy= 0.607\n",
      "Epoch: 1430, Minibatch Loss= 0.6842, Training Accuracy= 0.579\n",
      "Epoch: 1440, Minibatch Loss= 0.6340, Training Accuracy= 0.630\n",
      "Epoch: 1450, Minibatch Loss= 0.6430, Training Accuracy= 0.623\n",
      "Epoch: 1460, Minibatch Loss= 0.6259, Training Accuracy= 0.640\n",
      "Epoch: 1470, Minibatch Loss= 0.6972, Training Accuracy= 0.549\n",
      "Epoch: 1480, Minibatch Loss= 0.7349, Training Accuracy= 0.499\n",
      "Epoch: 1490, Minibatch Loss= 0.7185, Training Accuracy= 0.499\n",
      "Epoch: 1500, Minibatch Loss= 0.7110, Training Accuracy= 0.499\n",
      "Epoch: 1510, Minibatch Loss= 0.7065, Training Accuracy= 0.499\n",
      "Epoch: 1520, Minibatch Loss= 0.7042, Training Accuracy= 0.499\n",
      "Epoch: 1530, Minibatch Loss= 0.7025, Training Accuracy= 0.499\n",
      "Epoch: 1540, Minibatch Loss= 0.7012, Training Accuracy= 0.499\n",
      "Epoch: 1550, Minibatch Loss= 0.7000, Training Accuracy= 0.499\n",
      "Epoch: 1560, Minibatch Loss= 0.6989, Training Accuracy= 0.499\n",
      "Epoch: 1570, Minibatch Loss= 0.6980, Training Accuracy= 0.502\n",
      "Epoch: 1580, Minibatch Loss= 0.6970, Training Accuracy= 0.503\n",
      "Epoch: 1590, Minibatch Loss= 0.6962, Training Accuracy= 0.507\n",
      "Epoch: 1600, Minibatch Loss= 0.6950, Training Accuracy= 0.511\n",
      "Epoch: 1610, Minibatch Loss= 0.6940, Training Accuracy= 0.514\n",
      "Epoch: 1620, Minibatch Loss= 0.6933, Training Accuracy= 0.514\n",
      "Epoch: 1630, Minibatch Loss= 0.6927, Training Accuracy= 0.516\n",
      "Epoch: 1640, Minibatch Loss= 0.6922, Training Accuracy= 0.520\n",
      "Epoch: 1650, Minibatch Loss= 0.6916, Training Accuracy= 0.525\n",
      "Epoch: 1660, Minibatch Loss= 0.6913, Training Accuracy= 0.523\n",
      "Epoch: 1670, Minibatch Loss= 0.6902, Training Accuracy= 0.527\n",
      "Epoch: 1680, Minibatch Loss= 0.6895, Training Accuracy= 0.529\n",
      "Epoch: 1690, Minibatch Loss= 0.6887, Training Accuracy= 0.535\n",
      "Epoch: 1700, Minibatch Loss= 0.6907, Training Accuracy= 0.532\n",
      "Epoch: 1710, Minibatch Loss= 0.6872, Training Accuracy= 0.541\n",
      "Epoch: 1720, Minibatch Loss= 0.6893, Training Accuracy= 0.538\n",
      "Epoch: 1730, Minibatch Loss= 0.6891, Training Accuracy= 0.534\n",
      "Epoch: 1740, Minibatch Loss= 0.6863, Training Accuracy= 0.539\n",
      "Epoch: 1750, Minibatch Loss= 0.6854, Training Accuracy= 0.541\n",
      "Epoch: 1760, Minibatch Loss= 0.6848, Training Accuracy= 0.548\n",
      "Epoch: 1770, Minibatch Loss= 0.6843, Training Accuracy= 0.543\n",
      "Epoch: 1780, Minibatch Loss= 0.6824, Training Accuracy= 0.551\n",
      "Epoch: 1790, Minibatch Loss= 0.6861, Training Accuracy= 0.547\n",
      "Epoch: 1800, Minibatch Loss= 0.6831, Training Accuracy= 0.554\n",
      "Epoch: 1810, Minibatch Loss= 0.6800, Training Accuracy= 0.559\n",
      "Epoch: 1820, Minibatch Loss= 0.6817, Training Accuracy= 0.562\n",
      "Epoch: 1830, Minibatch Loss= 0.6791, Training Accuracy= 0.563\n",
      "Epoch: 1840, Minibatch Loss= 0.6812, Training Accuracy= 0.562\n",
      "Epoch: 1850, Minibatch Loss= 0.6780, Training Accuracy= 0.569\n",
      "Epoch: 1860, Minibatch Loss= 0.6841, Training Accuracy= 0.556\n",
      "Epoch: 1870, Minibatch Loss= 0.6878, Training Accuracy= 0.554\n",
      "Epoch: 1880, Minibatch Loss= 0.6770, Training Accuracy= 0.573\n",
      "Epoch: 1890, Minibatch Loss= 0.6925, Training Accuracy= 0.551\n",
      "Epoch: 1900, Minibatch Loss= 0.6794, Training Accuracy= 0.566\n",
      "Epoch: 1910, Minibatch Loss= 0.6814, Training Accuracy= 0.567\n",
      "Epoch: 1920, Minibatch Loss= 0.6708, Training Accuracy= 0.580\n",
      "Epoch: 1930, Minibatch Loss= 0.6756, Training Accuracy= 0.573\n",
      "Epoch: 1940, Minibatch Loss= 0.6745, Training Accuracy= 0.575\n",
      "Epoch: 1950, Minibatch Loss= 0.6640, Training Accuracy= 0.596\n",
      "Epoch: 1960, Minibatch Loss= 0.6746, Training Accuracy= 0.572\n",
      "Epoch: 1970, Minibatch Loss= 0.6724, Training Accuracy= 0.582\n",
      "Epoch: 1980, Minibatch Loss= 0.6853, Training Accuracy= 0.556\n",
      "Epoch: 1990, Minibatch Loss= 0.6584, Training Accuracy= 0.604\n",
      "Epoch: 2000, Minibatch Loss= 0.6581, Training Accuracy= 0.601\n",
      "Epoch: 2010, Minibatch Loss= 0.6632, Training Accuracy= 0.593\n",
      "Epoch: 2020, Minibatch Loss= 0.6592, Training Accuracy= 0.602\n",
      "Epoch: 2030, Minibatch Loss= 0.6603, Training Accuracy= 0.598\n",
      "Epoch: 2040, Minibatch Loss= 0.6518, Training Accuracy= 0.614\n",
      "Epoch: 2050, Minibatch Loss= 0.6617, Training Accuracy= 0.593\n",
      "Epoch: 2060, Minibatch Loss= 0.6657, Training Accuracy= 0.593\n",
      "Epoch: 2070, Minibatch Loss= 0.6572, Training Accuracy= 0.605\n",
      "Epoch: 2080, Minibatch Loss= 0.6509, Training Accuracy= 0.617\n",
      "Epoch: 2090, Minibatch Loss= 0.6548, Training Accuracy= 0.611\n",
      "Epoch: 2100, Minibatch Loss= 0.7122, Training Accuracy= 0.499\n",
      "Epoch: 2110, Minibatch Loss= 0.7068, Training Accuracy= 0.500\n",
      "Epoch: 2120, Minibatch Loss= 0.7041, Training Accuracy= 0.500\n",
      "Epoch: 2130, Minibatch Loss= 0.7026, Training Accuracy= 0.500\n",
      "Epoch: 2140, Minibatch Loss= 0.7014, Training Accuracy= 0.500\n",
      "Epoch: 2150, Minibatch Loss= 0.7004, Training Accuracy= 0.503\n",
      "Epoch: 2160, Minibatch Loss= 0.6996, Training Accuracy= 0.505\n",
      "Epoch: 2170, Minibatch Loss= 0.6989, Training Accuracy= 0.505\n",
      "Epoch: 2180, Minibatch Loss= 0.6982, Training Accuracy= 0.505\n",
      "Epoch: 2190, Minibatch Loss= 0.6975, Training Accuracy= 0.505\n",
      "Epoch: 2200, Minibatch Loss= 0.6969, Training Accuracy= 0.508\n",
      "Epoch: 2210, Minibatch Loss= 0.6962, Training Accuracy= 0.511\n",
      "Epoch: 2220, Minibatch Loss= 0.7142, Training Accuracy= 0.499\n",
      "Epoch: 2230, Minibatch Loss= 0.7124, Training Accuracy= 0.499\n",
      "Epoch: 2240, Minibatch Loss= 0.7114, Training Accuracy= 0.498\n",
      "Epoch: 2250, Minibatch Loss= 0.7105, Training Accuracy= 0.499\n",
      "Epoch: 2260, Minibatch Loss= 0.7097, Training Accuracy= 0.498\n",
      "Epoch: 2270, Minibatch Loss= 0.7090, Training Accuracy= 0.499\n",
      "Epoch: 2280, Minibatch Loss= 0.7083, Training Accuracy= 0.500\n",
      "Epoch: 2290, Minibatch Loss= 0.7077, Training Accuracy= 0.501\n",
      "Epoch: 2300, Minibatch Loss= 0.7071, Training Accuracy= 0.501\n",
      "Epoch: 2310, Minibatch Loss= 0.7065, Training Accuracy= 0.502\n",
      "Epoch: 2320, Minibatch Loss= 0.7058, Training Accuracy= 0.502\n",
      "Epoch: 2330, Minibatch Loss= 0.7049, Training Accuracy= 0.502\n",
      "Epoch: 2340, Minibatch Loss= 0.7043, Training Accuracy= 0.504\n",
      "Epoch: 2350, Minibatch Loss= 0.7037, Training Accuracy= 0.505\n",
      "Epoch: 2360, Minibatch Loss= 0.7032, Training Accuracy= 0.505\n",
      "Epoch: 2370, Minibatch Loss= 0.7027, Training Accuracy= 0.507\n",
      "Epoch: 2380, Minibatch Loss= 0.7020, Training Accuracy= 0.508\n",
      "Epoch: 2390, Minibatch Loss= 0.7015, Training Accuracy= 0.508\n",
      "Epoch: 2400, Minibatch Loss= 0.7009, Training Accuracy= 0.510\n",
      "Epoch: 2410, Minibatch Loss= 0.7005, Training Accuracy= 0.510\n",
      "Epoch: 2420, Minibatch Loss= 0.6999, Training Accuracy= 0.511\n",
      "Epoch: 2430, Minibatch Loss= 0.6992, Training Accuracy= 0.514\n",
      "Epoch: 2440, Minibatch Loss= 0.6988, Training Accuracy= 0.514\n",
      "Epoch: 2450, Minibatch Loss= 0.6981, Training Accuracy= 0.516\n",
      "Epoch: 2460, Minibatch Loss= 0.6975, Training Accuracy= 0.517\n",
      "Epoch: 2470, Minibatch Loss= 0.6976, Training Accuracy= 0.517\n",
      "Epoch: 2480, Minibatch Loss= 0.6961, Training Accuracy= 0.519\n",
      "Epoch: 2490, Minibatch Loss= 0.6962, Training Accuracy= 0.517\n",
      "Epoch: 2500, Minibatch Loss= 0.6956, Training Accuracy= 0.522\n",
      "Epoch: 2510, Minibatch Loss= 0.6942, Training Accuracy= 0.524\n",
      "Epoch: 2520, Minibatch Loss= 0.6931, Training Accuracy= 0.529\n",
      "Epoch: 2530, Minibatch Loss= 0.6920, Training Accuracy= 0.533\n",
      "Epoch: 2540, Minibatch Loss= 0.6932, Training Accuracy= 0.532\n",
      "Epoch: 2550, Minibatch Loss= 0.6917, Training Accuracy= 0.531\n",
      "Epoch: 2560, Minibatch Loss= 0.6920, Training Accuracy= 0.534\n",
      "Epoch: 2570, Minibatch Loss= 0.6910, Training Accuracy= 0.536\n",
      "Epoch: 2580, Minibatch Loss= 0.6944, Training Accuracy= 0.534\n",
      "Epoch: 2590, Minibatch Loss= 0.6891, Training Accuracy= 0.539\n",
      "Epoch: 2600, Minibatch Loss= 0.6888, Training Accuracy= 0.542\n",
      "Epoch: 2610, Minibatch Loss= 0.6899, Training Accuracy= 0.539\n",
      "Epoch: 2620, Minibatch Loss= 0.6873, Training Accuracy= 0.545\n",
      "Epoch: 2630, Minibatch Loss= 0.6897, Training Accuracy= 0.542\n",
      "Epoch: 2640, Minibatch Loss= 0.6845, Training Accuracy= 0.549\n",
      "Epoch: 2650, Minibatch Loss= 0.6834, Training Accuracy= 0.552\n",
      "Epoch: 2660, Minibatch Loss= 0.6838, Training Accuracy= 0.552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2670, Minibatch Loss= 0.7003, Training Accuracy= 0.535\n",
      "Epoch: 2680, Minibatch Loss= 0.6885, Training Accuracy= 0.550\n",
      "Epoch: 2690, Minibatch Loss= 0.6849, Training Accuracy= 0.555\n",
      "Epoch: 2700, Minibatch Loss= 0.7116, Training Accuracy= 0.516\n",
      "Epoch: 2710, Minibatch Loss= 0.6800, Training Accuracy= 0.559\n",
      "Epoch: 2720, Minibatch Loss= 0.6804, Training Accuracy= 0.556\n",
      "Epoch: 2730, Minibatch Loss= 0.6854, Training Accuracy= 0.548\n",
      "Epoch: 2740, Minibatch Loss= 0.6819, Training Accuracy= 0.559\n",
      "Epoch: 2750, Minibatch Loss= 0.6783, Training Accuracy= 0.561\n",
      "Epoch: 2760, Minibatch Loss= 0.6901, Training Accuracy= 0.535\n",
      "Epoch: 2770, Minibatch Loss= 0.6900, Training Accuracy= 0.537\n",
      "Epoch: 2780, Minibatch Loss= 0.7065, Training Accuracy= 0.502\n",
      "Epoch: 2790, Minibatch Loss= 0.6895, Training Accuracy= 0.536\n",
      "Epoch: 2800, Minibatch Loss= 0.6906, Training Accuracy= 0.540\n",
      "Epoch: 2810, Minibatch Loss= 0.6819, Training Accuracy= 0.559\n",
      "Epoch: 2820, Minibatch Loss= 0.6775, Training Accuracy= 0.569\n",
      "Epoch: 2830, Minibatch Loss= 0.6790, Training Accuracy= 0.562\n",
      "Epoch: 2840, Minibatch Loss= 0.7026, Training Accuracy= 0.535\n",
      "Epoch: 2850, Minibatch Loss= 0.6802, Training Accuracy= 0.563\n",
      "Epoch: 2860, Minibatch Loss= 0.6813, Training Accuracy= 0.557\n",
      "Epoch: 2870, Minibatch Loss= 0.6742, Training Accuracy= 0.572\n",
      "Epoch: 2880, Minibatch Loss= 0.6702, Training Accuracy= 0.579\n",
      "Epoch: 2890, Minibatch Loss= 0.6760, Training Accuracy= 0.572\n",
      "Epoch: 2900, Minibatch Loss= 0.7012, Training Accuracy= 0.518\n",
      "Epoch: 2910, Minibatch Loss= 0.6822, Training Accuracy= 0.553\n",
      "Epoch: 2920, Minibatch Loss= 0.6790, Training Accuracy= 0.562\n",
      "Epoch: 2930, Minibatch Loss= 0.6771, Training Accuracy= 0.567\n",
      "Epoch: 2940, Minibatch Loss= 0.6746, Training Accuracy= 0.571\n",
      "Epoch: 2950, Minibatch Loss= 0.6736, Training Accuracy= 0.574\n",
      "Epoch: 2960, Minibatch Loss= 0.6721, Training Accuracy= 0.576\n",
      "Epoch: 2970, Minibatch Loss= 0.6684, Training Accuracy= 0.582\n",
      "Epoch: 2980, Minibatch Loss= 0.7183, Training Accuracy= 0.499\n",
      "Epoch: 2990, Minibatch Loss= 0.7125, Training Accuracy= 0.501\n",
      "Epoch: 3000, Minibatch Loss= 0.7104, Training Accuracy= 0.501\n",
      "Epoch: 3010, Minibatch Loss= 0.7083, Training Accuracy= 0.503\n",
      "Epoch: 3020, Minibatch Loss= 0.7068, Training Accuracy= 0.506\n",
      "Epoch: 3030, Minibatch Loss= 0.7055, Training Accuracy= 0.508\n",
      "Epoch: 3040, Minibatch Loss= 0.7045, Training Accuracy= 0.510\n",
      "Epoch: 3050, Minibatch Loss= 0.7037, Training Accuracy= 0.514\n",
      "Epoch: 3060, Minibatch Loss= 0.7029, Training Accuracy= 0.516\n",
      "Epoch: 3070, Minibatch Loss= 0.7021, Training Accuracy= 0.520\n",
      "Epoch: 3080, Minibatch Loss= 0.7011, Training Accuracy= 0.524\n",
      "Epoch: 3090, Minibatch Loss= 0.7000, Training Accuracy= 0.525\n",
      "Epoch: 3100, Minibatch Loss= 0.6991, Training Accuracy= 0.527\n",
      "Epoch: 3110, Minibatch Loss= 0.6984, Training Accuracy= 0.527\n",
      "Epoch: 3120, Minibatch Loss= 0.6979, Training Accuracy= 0.530\n",
      "Epoch: 3130, Minibatch Loss= 0.6975, Training Accuracy= 0.531\n",
      "Epoch: 3140, Minibatch Loss= 0.6969, Training Accuracy= 0.533\n",
      "Epoch: 3150, Minibatch Loss= 0.6958, Training Accuracy= 0.533\n",
      "Epoch: 3160, Minibatch Loss= 0.6954, Training Accuracy= 0.534\n",
      "Epoch: 3170, Minibatch Loss= 0.6950, Training Accuracy= 0.536\n",
      "Epoch: 3180, Minibatch Loss= 0.6943, Training Accuracy= 0.537\n",
      "Epoch: 3190, Minibatch Loss= 0.6932, Training Accuracy= 0.536\n",
      "Epoch: 3200, Minibatch Loss= 0.6909, Training Accuracy= 0.543\n",
      "Epoch: 3210, Minibatch Loss= 0.6921, Training Accuracy= 0.542\n",
      "Epoch: 3220, Minibatch Loss= 0.6913, Training Accuracy= 0.545\n",
      "Epoch: 3230, Minibatch Loss= 0.6860, Training Accuracy= 0.552\n",
      "Epoch: 3240, Minibatch Loss= 0.6810, Training Accuracy= 0.559\n",
      "Epoch: 3250, Minibatch Loss= 0.6811, Training Accuracy= 0.562\n",
      "Epoch: 3260, Minibatch Loss= 0.6791, Training Accuracy= 0.562\n",
      "Epoch: 3270, Minibatch Loss= 0.6775, Training Accuracy= 0.567\n",
      "Epoch: 3280, Minibatch Loss= 0.6778, Training Accuracy= 0.568\n",
      "Epoch: 3290, Minibatch Loss= 0.6777, Training Accuracy= 0.567\n",
      "Epoch: 3300, Minibatch Loss= 0.6764, Training Accuracy= 0.571\n",
      "Epoch: 3310, Minibatch Loss= 0.6745, Training Accuracy= 0.572\n",
      "Epoch: 3320, Minibatch Loss= 0.6753, Training Accuracy= 0.571\n",
      "Epoch: 3330, Minibatch Loss= 0.6739, Training Accuracy= 0.571\n",
      "Epoch: 3340, Minibatch Loss= 0.6713, Training Accuracy= 0.578\n",
      "Epoch: 3350, Minibatch Loss= 0.6768, Training Accuracy= 0.571\n",
      "Epoch: 3360, Minibatch Loss= 0.6692, Training Accuracy= 0.578\n",
      "Epoch: 3370, Minibatch Loss= 0.6810, Training Accuracy= 0.567\n",
      "Epoch: 3380, Minibatch Loss= 0.6673, Training Accuracy= 0.583\n",
      "Epoch: 3390, Minibatch Loss= 0.6715, Training Accuracy= 0.578\n",
      "Epoch: 3400, Minibatch Loss= 0.6736, Training Accuracy= 0.577\n",
      "Epoch: 3410, Minibatch Loss= 0.6723, Training Accuracy= 0.578\n",
      "Epoch: 3420, Minibatch Loss= 0.6706, Training Accuracy= 0.581\n",
      "Epoch: 3430, Minibatch Loss= 0.6656, Training Accuracy= 0.589\n",
      "Epoch: 3440, Minibatch Loss= 0.6678, Training Accuracy= 0.585\n",
      "Epoch: 3450, Minibatch Loss= 0.6573, Training Accuracy= 0.597\n",
      "Epoch: 3460, Minibatch Loss= 0.6573, Training Accuracy= 0.600\n",
      "Epoch: 3470, Minibatch Loss= 0.6600, Training Accuracy= 0.594\n",
      "Epoch: 3480, Minibatch Loss= 0.6702, Training Accuracy= 0.576\n",
      "Epoch: 3490, Minibatch Loss= 0.6585, Training Accuracy= 0.602\n",
      "Epoch: 3500, Minibatch Loss= 0.7143, Training Accuracy= 0.521\n",
      "Epoch: 3510, Minibatch Loss= 0.6630, Training Accuracy= 0.593\n",
      "Epoch: 3520, Minibatch Loss= 0.6550, Training Accuracy= 0.607\n",
      "Epoch: 3530, Minibatch Loss= 0.7251, Training Accuracy= 0.509\n",
      "Epoch: 3540, Minibatch Loss= 0.7035, Training Accuracy= 0.522\n",
      "Epoch: 3550, Minibatch Loss= 0.6983, Training Accuracy= 0.527\n",
      "Epoch: 3560, Minibatch Loss= 0.6948, Training Accuracy= 0.532\n",
      "Epoch: 3570, Minibatch Loss= 0.6928, Training Accuracy= 0.537\n",
      "Epoch: 3580, Minibatch Loss= 0.6914, Training Accuracy= 0.542\n",
      "Epoch: 3590, Minibatch Loss= 0.6915, Training Accuracy= 0.541\n",
      "Epoch: 3600, Minibatch Loss= 0.6882, Training Accuracy= 0.545\n",
      "Epoch: 3610, Minibatch Loss= 0.6881, Training Accuracy= 0.544\n",
      "Epoch: 3620, Minibatch Loss= 0.6868, Training Accuracy= 0.547\n",
      "Epoch: 3630, Minibatch Loss= 0.6864, Training Accuracy= 0.547\n",
      "Epoch: 3640, Minibatch Loss= 0.6862, Training Accuracy= 0.548\n",
      "Epoch: 3650, Minibatch Loss= 0.6868, Training Accuracy= 0.549\n",
      "Epoch: 3660, Minibatch Loss= 0.6861, Training Accuracy= 0.549\n",
      "Epoch: 3670, Minibatch Loss= 0.6798, Training Accuracy= 0.555\n",
      "Epoch: 3680, Minibatch Loss= 0.6821, Training Accuracy= 0.553\n",
      "Epoch: 3690, Minibatch Loss= 0.6771, Training Accuracy= 0.561\n",
      "Epoch: 3700, Minibatch Loss= 0.6770, Training Accuracy= 0.559\n",
      "Epoch: 3710, Minibatch Loss= 0.6750, Training Accuracy= 0.561\n",
      "Epoch: 3720, Minibatch Loss= 0.7406, Training Accuracy= 0.501\n",
      "Epoch: 3730, Minibatch Loss= 0.7337, Training Accuracy= 0.502\n",
      "Epoch: 3740, Minibatch Loss= 0.7301, Training Accuracy= 0.501\n",
      "Epoch: 3750, Minibatch Loss= 0.7283, Training Accuracy= 0.502\n",
      "Epoch: 3760, Minibatch Loss= 0.7257, Training Accuracy= 0.503\n",
      "Epoch: 3770, Minibatch Loss= 0.7242, Training Accuracy= 0.503\n",
      "Epoch: 3780, Minibatch Loss= 0.7229, Training Accuracy= 0.504\n",
      "Epoch: 3790, Minibatch Loss= 0.7218, Training Accuracy= 0.504\n",
      "Epoch: 3800, Minibatch Loss= 0.7213, Training Accuracy= 0.505\n",
      "Epoch: 3810, Minibatch Loss= 0.7215, Training Accuracy= 0.504\n",
      "Epoch: 3820, Minibatch Loss= 0.7211, Training Accuracy= 0.506\n",
      "Epoch: 3830, Minibatch Loss= 0.7214, Training Accuracy= 0.507\n",
      "Epoch: 3840, Minibatch Loss= 0.7214, Training Accuracy= 0.507\n",
      "Epoch: 3850, Minibatch Loss= 0.7212, Training Accuracy= 0.507\n",
      "Epoch: 3860, Minibatch Loss= 0.7211, Training Accuracy= 0.507\n",
      "Epoch: 3870, Minibatch Loss= 0.7212, Training Accuracy= 0.508\n",
      "Epoch: 3880, Minibatch Loss= 0.7207, Training Accuracy= 0.509\n",
      "Epoch: 3890, Minibatch Loss= 0.7204, Training Accuracy= 0.509\n",
      "Epoch: 3900, Minibatch Loss= 0.7203, Training Accuracy= 0.510\n",
      "Epoch: 3910, Minibatch Loss= 0.7202, Training Accuracy= 0.510\n",
      "Epoch: 3920, Minibatch Loss= 0.7202, Training Accuracy= 0.511\n",
      "Epoch: 3930, Minibatch Loss= 0.7191, Training Accuracy= 0.510\n",
      "Epoch: 3940, Minibatch Loss= 0.7200, Training Accuracy= 0.512\n",
      "Epoch: 3950, Minibatch Loss= 0.7197, Training Accuracy= 0.509\n",
      "Epoch: 3960, Minibatch Loss= 0.7180, Training Accuracy= 0.511\n",
      "Epoch: 3970, Minibatch Loss= 0.7181, Training Accuracy= 0.512\n",
      "Epoch: 3980, Minibatch Loss= 0.7190, Training Accuracy= 0.513\n",
      "Epoch: 3990, Minibatch Loss= 0.7171, Training Accuracy= 0.509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4000, Minibatch Loss= 0.7177, Training Accuracy= 0.513\n",
      "Epoch: 4010, Minibatch Loss= 0.7176, Training Accuracy= 0.514\n",
      "Epoch: 4020, Minibatch Loss= 0.7178, Training Accuracy= 0.511\n",
      "Epoch: 4030, Minibatch Loss= 0.7165, Training Accuracy= 0.511\n",
      "Epoch: 4040, Minibatch Loss= 0.7162, Training Accuracy= 0.515\n",
      "Epoch: 4050, Minibatch Loss= 0.7156, Training Accuracy= 0.514\n",
      "Epoch: 4060, Minibatch Loss= 0.7154, Training Accuracy= 0.515\n",
      "Epoch: 4070, Minibatch Loss= 0.7134, Training Accuracy= 0.519\n",
      "Epoch: 4080, Minibatch Loss= 0.7150, Training Accuracy= 0.517\n",
      "Epoch: 4090, Minibatch Loss= 0.7159, Training Accuracy= 0.517\n",
      "Epoch: 4100, Minibatch Loss= 0.7247, Training Accuracy= 0.508\n",
      "Epoch: 4110, Minibatch Loss= 0.7103, Training Accuracy= 0.518\n",
      "Epoch: 4120, Minibatch Loss= 0.7149, Training Accuracy= 0.519\n",
      "Epoch: 4130, Minibatch Loss= 0.7091, Training Accuracy= 0.521\n",
      "Epoch: 4140, Minibatch Loss= 0.7086, Training Accuracy= 0.523\n",
      "Epoch: 4150, Minibatch Loss= 0.7082, Training Accuracy= 0.524\n",
      "Epoch: 4160, Minibatch Loss= 0.7094, Training Accuracy= 0.525\n",
      "Epoch: 4170, Minibatch Loss= 0.7096, Training Accuracy= 0.525\n",
      "Epoch: 4180, Minibatch Loss= 0.7101, Training Accuracy= 0.525\n",
      "Epoch: 4190, Minibatch Loss= 0.7086, Training Accuracy= 0.528\n",
      "Epoch: 4200, Minibatch Loss= 0.7087, Training Accuracy= 0.527\n",
      "Epoch: 4210, Minibatch Loss= 0.7026, Training Accuracy= 0.525\n",
      "Epoch: 4220, Minibatch Loss= 0.7068, Training Accuracy= 0.529\n",
      "Epoch: 4230, Minibatch Loss= 0.7057, Training Accuracy= 0.530\n",
      "Epoch: 4240, Minibatch Loss= 0.7072, Training Accuracy= 0.528\n",
      "Epoch: 4250, Minibatch Loss= 0.7111, Training Accuracy= 0.518\n",
      "Epoch: 4260, Minibatch Loss= 0.7061, Training Accuracy= 0.531\n",
      "Epoch: 4270, Minibatch Loss= 0.7095, Training Accuracy= 0.531\n",
      "Epoch: 4280, Minibatch Loss= 0.7040, Training Accuracy= 0.532\n",
      "Epoch: 4290, Minibatch Loss= 0.7082, Training Accuracy= 0.509\n",
      "Epoch: 4300, Minibatch Loss= 0.7035, Training Accuracy= 0.512\n",
      "Epoch: 4310, Minibatch Loss= 0.7019, Training Accuracy= 0.515\n",
      "Epoch: 4320, Minibatch Loss= 0.7027, Training Accuracy= 0.514\n",
      "Epoch: 4330, Minibatch Loss= 0.7025, Training Accuracy= 0.515\n",
      "Epoch: 4340, Minibatch Loss= 0.7018, Training Accuracy= 0.518\n",
      "Epoch: 4350, Minibatch Loss= 0.7008, Training Accuracy= 0.521\n",
      "Epoch: 4360, Minibatch Loss= 0.7011, Training Accuracy= 0.524\n",
      "Epoch: 4370, Minibatch Loss= 0.7005, Training Accuracy= 0.523\n",
      "Epoch: 4380, Minibatch Loss= 0.7010, Training Accuracy= 0.523\n",
      "Epoch: 4390, Minibatch Loss= 0.7004, Training Accuracy= 0.523\n",
      "Epoch: 4400, Minibatch Loss= 0.6997, Training Accuracy= 0.527\n",
      "Epoch: 4410, Minibatch Loss= 0.7012, Training Accuracy= 0.527\n",
      "Epoch: 4420, Minibatch Loss= 0.6988, Training Accuracy= 0.529\n",
      "Epoch: 4430, Minibatch Loss= 0.6980, Training Accuracy= 0.530\n",
      "Epoch: 4440, Minibatch Loss= 0.7034, Training Accuracy= 0.524\n",
      "Epoch: 4450, Minibatch Loss= 0.6977, Training Accuracy= 0.529\n",
      "Epoch: 4460, Minibatch Loss= 0.6977, Training Accuracy= 0.530\n",
      "Epoch: 4470, Minibatch Loss= 0.6988, Training Accuracy= 0.529\n",
      "Epoch: 4480, Minibatch Loss= 0.7070, Training Accuracy= 0.521\n",
      "Epoch: 4490, Minibatch Loss= 0.7022, Training Accuracy= 0.526\n",
      "Epoch: 4500, Minibatch Loss= 0.6975, Training Accuracy= 0.533\n",
      "Epoch: 4510, Minibatch Loss= 0.6963, Training Accuracy= 0.535\n",
      "Epoch: 4520, Minibatch Loss= 0.6962, Training Accuracy= 0.535\n",
      "Epoch: 4530, Minibatch Loss= 0.6958, Training Accuracy= 0.536\n",
      "Epoch: 4540, Minibatch Loss= 0.7068, Training Accuracy= 0.522\n",
      "Epoch: 4550, Minibatch Loss= 0.6942, Training Accuracy= 0.538\n",
      "Epoch: 4560, Minibatch Loss= 0.7108, Training Accuracy= 0.505\n",
      "Epoch: 4570, Minibatch Loss= 0.7037, Training Accuracy= 0.503\n",
      "Epoch: 4580, Minibatch Loss= 0.7026, Training Accuracy= 0.505\n",
      "Epoch: 4590, Minibatch Loss= 0.7019, Training Accuracy= 0.505\n",
      "Epoch: 4600, Minibatch Loss= 0.7011, Training Accuracy= 0.508\n",
      "Epoch: 4610, Minibatch Loss= 0.7012, Training Accuracy= 0.508\n",
      "Epoch: 4620, Minibatch Loss= 0.6990, Training Accuracy= 0.513\n",
      "Epoch: 4630, Minibatch Loss= 0.6992, Training Accuracy= 0.516\n",
      "Epoch: 4640, Minibatch Loss= 0.6952, Training Accuracy= 0.519\n",
      "Epoch: 4650, Minibatch Loss= 0.6948, Training Accuracy= 0.525\n",
      "Epoch: 4660, Minibatch Loss= 0.6919, Training Accuracy= 0.529\n",
      "Epoch: 4670, Minibatch Loss= 0.6903, Training Accuracy= 0.528\n",
      "Epoch: 4680, Minibatch Loss= 0.6872, Training Accuracy= 0.533\n",
      "Epoch: 4690, Minibatch Loss= 0.6870, Training Accuracy= 0.534\n",
      "Epoch: 4700, Minibatch Loss= 0.6977, Training Accuracy= 0.526\n",
      "Epoch: 4710, Minibatch Loss= 0.6860, Training Accuracy= 0.539\n",
      "Epoch: 4720, Minibatch Loss= 0.6917, Training Accuracy= 0.533\n",
      "Epoch: 4730, Minibatch Loss= 0.6841, Training Accuracy= 0.539\n",
      "Epoch: 4740, Minibatch Loss= 0.6851, Training Accuracy= 0.538\n",
      "Epoch: 4750, Minibatch Loss= 0.7238, Training Accuracy= 0.499\n",
      "Epoch: 4760, Minibatch Loss= 0.7197, Training Accuracy= 0.500\n",
      "Epoch: 4770, Minibatch Loss= 0.7179, Training Accuracy= 0.500\n",
      "Epoch: 4780, Minibatch Loss= 0.7164, Training Accuracy= 0.500\n",
      "Epoch: 4790, Minibatch Loss= 0.7150, Training Accuracy= 0.500\n",
      "Epoch: 4800, Minibatch Loss= 0.7144, Training Accuracy= 0.499\n",
      "Epoch: 4810, Minibatch Loss= 0.7126, Training Accuracy= 0.501\n",
      "Epoch: 4820, Minibatch Loss= 0.7117, Training Accuracy= 0.501\n",
      "Epoch: 4830, Minibatch Loss= 0.7111, Training Accuracy= 0.501\n",
      "Epoch: 4840, Minibatch Loss= 0.7104, Training Accuracy= 0.501\n",
      "Epoch: 4850, Minibatch Loss= 0.7094, Training Accuracy= 0.502\n",
      "Epoch: 4860, Minibatch Loss= 0.7087, Training Accuracy= 0.504\n",
      "Epoch: 4870, Minibatch Loss= 0.7077, Training Accuracy= 0.505\n",
      "Epoch: 4880, Minibatch Loss= 0.7076, Training Accuracy= 0.504\n",
      "Epoch: 4890, Minibatch Loss= 0.7062, Training Accuracy= 0.506\n",
      "Epoch: 4900, Minibatch Loss= 0.7057, Training Accuracy= 0.506\n",
      "Epoch: 4910, Minibatch Loss= 0.7064, Training Accuracy= 0.503\n",
      "Epoch: 4920, Minibatch Loss= 0.7025, Training Accuracy= 0.508\n",
      "Epoch: 4930, Minibatch Loss= 0.7011, Training Accuracy= 0.512\n",
      "Epoch: 4940, Minibatch Loss= 0.7006, Training Accuracy= 0.513\n",
      "Epoch: 4950, Minibatch Loss= 0.6992, Training Accuracy= 0.515\n",
      "Epoch: 4960, Minibatch Loss= 0.6984, Training Accuracy= 0.519\n",
      "Epoch: 4970, Minibatch Loss= 0.7010, Training Accuracy= 0.522\n",
      "Epoch: 4980, Minibatch Loss= 0.6984, Training Accuracy= 0.524\n",
      "Epoch: 4990, Minibatch Loss= 0.6965, Training Accuracy= 0.524\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5052\n",
      "Replication: 1: \n",
      "Epoch: 0, Minibatch Loss= 0.7308, Training Accuracy= 0.498\n",
      "Epoch: 10, Minibatch Loss= 0.7118, Training Accuracy= 0.498\n",
      "Epoch: 20, Minibatch Loss= 0.7051, Training Accuracy= 0.498\n",
      "Epoch: 30, Minibatch Loss= 0.7016, Training Accuracy= 0.498\n",
      "Epoch: 40, Minibatch Loss= 0.6994, Training Accuracy= 0.498\n",
      "Epoch: 50, Minibatch Loss= 0.6980, Training Accuracy= 0.498\n",
      "Epoch: 60, Minibatch Loss= 0.6970, Training Accuracy= 0.498\n",
      "Epoch: 70, Minibatch Loss= 0.6963, Training Accuracy= 0.498\n",
      "Epoch: 80, Minibatch Loss= 0.6957, Training Accuracy= 0.498\n",
      "Epoch: 90, Minibatch Loss= 0.6953, Training Accuracy= 0.498\n",
      "Epoch: 100, Minibatch Loss= 0.6950, Training Accuracy= 0.498\n",
      "Epoch: 110, Minibatch Loss= 0.6947, Training Accuracy= 0.498\n",
      "Epoch: 120, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 130, Minibatch Loss= 0.6943, Training Accuracy= 0.498\n",
      "Epoch: 140, Minibatch Loss= 0.6942, Training Accuracy= 0.498\n",
      "Epoch: 150, Minibatch Loss= 0.6941, Training Accuracy= 0.498\n",
      "Epoch: 160, Minibatch Loss= 0.6940, Training Accuracy= 0.498\n",
      "Epoch: 170, Minibatch Loss= 0.6939, Training Accuracy= 0.498\n",
      "Epoch: 180, Minibatch Loss= 0.6938, Training Accuracy= 0.498\n",
      "Epoch: 190, Minibatch Loss= 0.6937, Training Accuracy= 0.498\n",
      "Epoch: 200, Minibatch Loss= 0.6937, Training Accuracy= 0.498\n",
      "Epoch: 210, Minibatch Loss= 0.6936, Training Accuracy= 0.499\n",
      "Epoch: 220, Minibatch Loss= 0.6936, Training Accuracy= 0.499\n",
      "Epoch: 230, Minibatch Loss= 0.6935, Training Accuracy= 0.498\n",
      "Epoch: 240, Minibatch Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 250, Minibatch Loss= 0.6935, Training Accuracy= 0.500\n",
      "Epoch: 260, Minibatch Loss= 0.6934, Training Accuracy= 0.499\n",
      "Epoch: 270, Minibatch Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 280, Minibatch Loss= 0.6934, Training Accuracy= 0.501\n",
      "Epoch: 290, Minibatch Loss= 0.6934, Training Accuracy= 0.500\n",
      "Epoch: 300, Minibatch Loss= 0.6933, Training Accuracy= 0.500\n",
      "Epoch: 310, Minibatch Loss= 0.6933, Training Accuracy= 0.500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 320, Minibatch Loss= 0.6933, Training Accuracy= 0.500\n",
      "Epoch: 330, Minibatch Loss= 0.6933, Training Accuracy= 0.500\n",
      "Epoch: 340, Minibatch Loss= 0.6933, Training Accuracy= 0.500\n",
      "Epoch: 350, Minibatch Loss= 0.6933, Training Accuracy= 0.500\n",
      "Epoch: 360, Minibatch Loss= 0.6933, Training Accuracy= 0.499\n",
      "Epoch: 370, Minibatch Loss= 0.6932, Training Accuracy= 0.499\n",
      "Epoch: 380, Minibatch Loss= 0.6932, Training Accuracy= 0.499\n",
      "Epoch: 390, Minibatch Loss= 0.6932, Training Accuracy= 0.500\n",
      "Epoch: 400, Minibatch Loss= 0.6932, Training Accuracy= 0.500\n",
      "Epoch: 410, Minibatch Loss= 0.6932, Training Accuracy= 0.502\n",
      "Epoch: 420, Minibatch Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 430, Minibatch Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 440, Minibatch Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 450, Minibatch Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 460, Minibatch Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 470, Minibatch Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 480, Minibatch Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 490, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 500, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 510, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 520, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 530, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 540, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 550, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 560, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 570, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 580, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 590, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 600, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 610, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 620, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 630, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 640, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 650, Minibatch Loss= 0.6930, Training Accuracy= 0.503\n",
      "Epoch: 660, Minibatch Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 670, Minibatch Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 680, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 690, Minibatch Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 700, Minibatch Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 710, Minibatch Loss= 0.6929, Training Accuracy= 0.508\n",
      "Epoch: 720, Minibatch Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 730, Minibatch Loss= 0.6928, Training Accuracy= 0.510\n",
      "Epoch: 740, Minibatch Loss= 0.6927, Training Accuracy= 0.511\n",
      "Epoch: 750, Minibatch Loss= 0.6926, Training Accuracy= 0.511\n",
      "Epoch: 760, Minibatch Loss= 0.6926, Training Accuracy= 0.516\n",
      "Epoch: 770, Minibatch Loss= 0.6925, Training Accuracy= 0.517\n",
      "Epoch: 780, Minibatch Loss= 0.6925, Training Accuracy= 0.519\n",
      "Epoch: 790, Minibatch Loss= 0.6925, Training Accuracy= 0.521\n",
      "Epoch: 800, Minibatch Loss= 0.6924, Training Accuracy= 0.516\n",
      "Epoch: 810, Minibatch Loss= 0.6924, Training Accuracy= 0.520\n",
      "Epoch: 820, Minibatch Loss= 0.6923, Training Accuracy= 0.519\n",
      "Epoch: 830, Minibatch Loss= 0.6922, Training Accuracy= 0.521\n",
      "Epoch: 840, Minibatch Loss= 0.6922, Training Accuracy= 0.522\n",
      "Epoch: 850, Minibatch Loss= 0.6921, Training Accuracy= 0.521\n",
      "Epoch: 860, Minibatch Loss= 0.6921, Training Accuracy= 0.522\n",
      "Epoch: 870, Minibatch Loss= 0.6921, Training Accuracy= 0.522\n",
      "Epoch: 880, Minibatch Loss= 0.6920, Training Accuracy= 0.524\n",
      "Epoch: 890, Minibatch Loss= 0.6918, Training Accuracy= 0.525\n",
      "Epoch: 900, Minibatch Loss= 0.6916, Training Accuracy= 0.525\n",
      "Epoch: 910, Minibatch Loss= 0.6915, Training Accuracy= 0.525\n",
      "Epoch: 920, Minibatch Loss= 0.6913, Training Accuracy= 0.525\n",
      "Epoch: 930, Minibatch Loss= 0.6911, Training Accuracy= 0.525\n",
      "Epoch: 940, Minibatch Loss= 0.6909, Training Accuracy= 0.527\n",
      "Epoch: 950, Minibatch Loss= 0.6907, Training Accuracy= 0.528\n",
      "Epoch: 960, Minibatch Loss= 0.6904, Training Accuracy= 0.531\n",
      "Epoch: 970, Minibatch Loss= 0.6902, Training Accuracy= 0.532\n",
      "Epoch: 980, Minibatch Loss= 0.6914, Training Accuracy= 0.525\n",
      "Epoch: 990, Minibatch Loss= 0.6905, Training Accuracy= 0.532\n",
      "Epoch: 1000, Minibatch Loss= 0.6904, Training Accuracy= 0.533\n",
      "Epoch: 1010, Minibatch Loss= 0.6903, Training Accuracy= 0.532\n",
      "Epoch: 1020, Minibatch Loss= 0.6910, Training Accuracy= 0.523\n",
      "Epoch: 1030, Minibatch Loss= 0.6904, Training Accuracy= 0.531\n",
      "Epoch: 1040, Minibatch Loss= 0.6906, Training Accuracy= 0.528\n",
      "Epoch: 1050, Minibatch Loss= 0.6909, Training Accuracy= 0.521\n",
      "Epoch: 1060, Minibatch Loss= 0.6897, Training Accuracy= 0.533\n",
      "Epoch: 1070, Minibatch Loss= 0.6900, Training Accuracy= 0.531\n",
      "Epoch: 1080, Minibatch Loss= 0.6886, Training Accuracy= 0.538\n",
      "Epoch: 1090, Minibatch Loss= 0.6883, Training Accuracy= 0.540\n",
      "Epoch: 1100, Minibatch Loss= 0.6891, Training Accuracy= 0.539\n",
      "Epoch: 1110, Minibatch Loss= 0.6873, Training Accuracy= 0.547\n",
      "Epoch: 1120, Minibatch Loss= 0.6880, Training Accuracy= 0.541\n",
      "Epoch: 1130, Minibatch Loss= 0.6882, Training Accuracy= 0.542\n",
      "Epoch: 1140, Minibatch Loss= 0.6881, Training Accuracy= 0.541\n",
      "Epoch: 1150, Minibatch Loss= 0.6871, Training Accuracy= 0.543\n",
      "Epoch: 1160, Minibatch Loss= 0.6867, Training Accuracy= 0.546\n",
      "Epoch: 1170, Minibatch Loss= 0.6860, Training Accuracy= 0.545\n",
      "Epoch: 1180, Minibatch Loss= 0.6900, Training Accuracy= 0.535\n",
      "Epoch: 1190, Minibatch Loss= 0.6871, Training Accuracy= 0.540\n",
      "Epoch: 1200, Minibatch Loss= 0.6865, Training Accuracy= 0.545\n",
      "Epoch: 1210, Minibatch Loss= 0.6928, Training Accuracy= 0.527\n",
      "Epoch: 1220, Minibatch Loss= 0.6964, Training Accuracy= 0.525\n",
      "Epoch: 1230, Minibatch Loss= 0.6857, Training Accuracy= 0.546\n",
      "Epoch: 1240, Minibatch Loss= 0.6830, Training Accuracy= 0.558\n",
      "Epoch: 1250, Minibatch Loss= 0.6820, Training Accuracy= 0.557\n",
      "Epoch: 1260, Minibatch Loss= 0.6905, Training Accuracy= 0.533\n",
      "Epoch: 1270, Minibatch Loss= 0.6817, Training Accuracy= 0.561\n",
      "Epoch: 1280, Minibatch Loss= 0.6874, Training Accuracy= 0.545\n",
      "Epoch: 1290, Minibatch Loss= 0.6768, Training Accuracy= 0.577\n",
      "Epoch: 1300, Minibatch Loss= 0.6820, Training Accuracy= 0.562\n",
      "Epoch: 1310, Minibatch Loss= 0.6757, Training Accuracy= 0.576\n",
      "Epoch: 1320, Minibatch Loss= 0.6863, Training Accuracy= 0.561\n",
      "Epoch: 1330, Minibatch Loss= 0.6735, Training Accuracy= 0.584\n",
      "Epoch: 1340, Minibatch Loss= 0.6869, Training Accuracy= 0.551\n",
      "Epoch: 1350, Minibatch Loss= 0.6756, Training Accuracy= 0.575\n",
      "Epoch: 1360, Minibatch Loss= 0.6933, Training Accuracy= 0.541\n",
      "Epoch: 1370, Minibatch Loss= 0.6692, Training Accuracy= 0.587\n",
      "Epoch: 1380, Minibatch Loss= 0.6660, Training Accuracy= 0.597\n",
      "Epoch: 1390, Minibatch Loss= 0.6679, Training Accuracy= 0.592\n",
      "Epoch: 1400, Minibatch Loss= 0.6828, Training Accuracy= 0.562\n",
      "Epoch: 1410, Minibatch Loss= 0.6919, Training Accuracy= 0.541\n",
      "Epoch: 1420, Minibatch Loss= 0.6650, Training Accuracy= 0.596\n",
      "Epoch: 1430, Minibatch Loss= 0.6759, Training Accuracy= 0.576\n",
      "Epoch: 1440, Minibatch Loss= 0.6757, Training Accuracy= 0.577\n",
      "Epoch: 1450, Minibatch Loss= 0.6720, Training Accuracy= 0.580\n",
      "Epoch: 1460, Minibatch Loss= 0.6656, Training Accuracy= 0.594\n",
      "Epoch: 1470, Minibatch Loss= 0.6741, Training Accuracy= 0.580\n",
      "Epoch: 1480, Minibatch Loss= 0.6589, Training Accuracy= 0.606\n",
      "Epoch: 1490, Minibatch Loss= 0.6614, Training Accuracy= 0.596\n",
      "Epoch: 1500, Minibatch Loss= 0.6602, Training Accuracy= 0.598\n",
      "Epoch: 1510, Minibatch Loss= 0.6705, Training Accuracy= 0.587\n",
      "Epoch: 1520, Minibatch Loss= 0.6816, Training Accuracy= 0.571\n",
      "Epoch: 1530, Minibatch Loss= 0.6537, Training Accuracy= 0.612\n",
      "Epoch: 1540, Minibatch Loss= 0.6522, Training Accuracy= 0.612\n",
      "Epoch: 1550, Minibatch Loss= 0.6550, Training Accuracy= 0.611\n",
      "Epoch: 1560, Minibatch Loss= 0.6569, Training Accuracy= 0.608\n",
      "Epoch: 1570, Minibatch Loss= 0.6538, Training Accuracy= 0.613\n",
      "Epoch: 1580, Minibatch Loss= 0.6478, Training Accuracy= 0.614\n",
      "Epoch: 1590, Minibatch Loss= 0.6550, Training Accuracy= 0.614\n",
      "Epoch: 1600, Minibatch Loss= 0.6459, Training Accuracy= 0.623\n",
      "Epoch: 1610, Minibatch Loss= 0.6624, Training Accuracy= 0.603\n",
      "Epoch: 1620, Minibatch Loss= 0.7225, Training Accuracy= 0.499\n",
      "Epoch: 1630, Minibatch Loss= 0.7190, Training Accuracy= 0.501\n",
      "Epoch: 1640, Minibatch Loss= 0.7121, Training Accuracy= 0.505\n",
      "Epoch: 1650, Minibatch Loss= 0.7108, Training Accuracy= 0.508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1660, Minibatch Loss= 0.7074, Training Accuracy= 0.510\n",
      "Epoch: 1670, Minibatch Loss= 0.7069, Training Accuracy= 0.509\n",
      "Epoch: 1680, Minibatch Loss= 0.7052, Training Accuracy= 0.511\n",
      "Epoch: 1690, Minibatch Loss= 0.7017, Training Accuracy= 0.515\n",
      "Epoch: 1700, Minibatch Loss= 0.7014, Training Accuracy= 0.515\n",
      "Epoch: 1710, Minibatch Loss= 0.7012, Training Accuracy= 0.517\n",
      "Epoch: 1720, Minibatch Loss= 0.7021, Training Accuracy= 0.514\n",
      "Epoch: 1730, Minibatch Loss= 0.6988, Training Accuracy= 0.522\n",
      "Epoch: 1740, Minibatch Loss= 0.6984, Training Accuracy= 0.523\n",
      "Epoch: 1750, Minibatch Loss= 0.6981, Training Accuracy= 0.526\n",
      "Epoch: 1760, Minibatch Loss= 0.6983, Training Accuracy= 0.527\n",
      "Epoch: 1770, Minibatch Loss= 0.6991, Training Accuracy= 0.525\n",
      "Epoch: 1780, Minibatch Loss= 0.7043, Training Accuracy= 0.513\n",
      "Epoch: 1790, Minibatch Loss= 0.6985, Training Accuracy= 0.523\n",
      "Epoch: 1800, Minibatch Loss= 0.6939, Training Accuracy= 0.526\n",
      "Epoch: 1810, Minibatch Loss= 0.6908, Training Accuracy= 0.536\n",
      "Epoch: 1820, Minibatch Loss= 0.6906, Training Accuracy= 0.536\n",
      "Epoch: 1830, Minibatch Loss= 0.6945, Training Accuracy= 0.528\n",
      "Epoch: 1840, Minibatch Loss= 0.6900, Training Accuracy= 0.538\n",
      "Epoch: 1850, Minibatch Loss= 0.6891, Training Accuracy= 0.542\n",
      "Epoch: 1860, Minibatch Loss= 0.6923, Training Accuracy= 0.533\n",
      "Epoch: 1870, Minibatch Loss= 0.6887, Training Accuracy= 0.539\n",
      "Epoch: 1880, Minibatch Loss= 0.6913, Training Accuracy= 0.543\n",
      "Epoch: 1890, Minibatch Loss= 0.6906, Training Accuracy= 0.541\n",
      "Epoch: 1900, Minibatch Loss= 0.6921, Training Accuracy= 0.535\n",
      "Epoch: 1910, Minibatch Loss= 0.6864, Training Accuracy= 0.548\n",
      "Epoch: 1920, Minibatch Loss= 0.6834, Training Accuracy= 0.553\n",
      "Epoch: 1930, Minibatch Loss= 0.7140, Training Accuracy= 0.509\n",
      "Epoch: 1940, Minibatch Loss= 0.7198, Training Accuracy= 0.498\n",
      "Epoch: 1950, Minibatch Loss= 0.7160, Training Accuracy= 0.498\n",
      "Epoch: 1960, Minibatch Loss= 0.7132, Training Accuracy= 0.498\n",
      "Epoch: 1970, Minibatch Loss= 0.7111, Training Accuracy= 0.498\n",
      "Epoch: 1980, Minibatch Loss= 0.7093, Training Accuracy= 0.498\n",
      "Epoch: 1990, Minibatch Loss= 0.7077, Training Accuracy= 0.498\n",
      "Epoch: 2000, Minibatch Loss= 0.7063, Training Accuracy= 0.498\n",
      "Epoch: 2010, Minibatch Loss= 0.7055, Training Accuracy= 0.498\n",
      "Epoch: 2020, Minibatch Loss= 0.7047, Training Accuracy= 0.498\n",
      "Epoch: 2030, Minibatch Loss= 0.7042, Training Accuracy= 0.499\n",
      "Epoch: 2040, Minibatch Loss= 0.7038, Training Accuracy= 0.499\n",
      "Epoch: 2050, Minibatch Loss= 0.7044, Training Accuracy= 0.500\n",
      "Epoch: 2060, Minibatch Loss= 0.7033, Training Accuracy= 0.502\n",
      "Epoch: 2070, Minibatch Loss= 0.7020, Training Accuracy= 0.504\n",
      "Epoch: 2080, Minibatch Loss= 0.7022, Training Accuracy= 0.506\n",
      "Epoch: 2090, Minibatch Loss= 0.7024, Training Accuracy= 0.508\n",
      "Epoch: 2100, Minibatch Loss= 0.7013, Training Accuracy= 0.511\n",
      "Epoch: 2110, Minibatch Loss= 0.6974, Training Accuracy= 0.515\n",
      "Epoch: 2120, Minibatch Loss= 0.6987, Training Accuracy= 0.516\n",
      "Epoch: 2130, Minibatch Loss= 0.6985, Training Accuracy= 0.517\n",
      "Epoch: 2140, Minibatch Loss= 0.6993, Training Accuracy= 0.516\n",
      "Epoch: 2150, Minibatch Loss= 0.6948, Training Accuracy= 0.530\n",
      "Epoch: 2160, Minibatch Loss= 0.6942, Training Accuracy= 0.527\n",
      "Epoch: 2170, Minibatch Loss= 0.6935, Training Accuracy= 0.533\n",
      "Epoch: 2180, Minibatch Loss= 0.6969, Training Accuracy= 0.531\n",
      "Epoch: 2190, Minibatch Loss= 0.6974, Training Accuracy= 0.522\n",
      "Epoch: 2200, Minibatch Loss= 0.6920, Training Accuracy= 0.537\n",
      "Epoch: 2210, Minibatch Loss= 0.6973, Training Accuracy= 0.519\n",
      "Epoch: 2220, Minibatch Loss= 0.6917, Training Accuracy= 0.536\n",
      "Epoch: 2230, Minibatch Loss= 0.6917, Training Accuracy= 0.537\n",
      "Epoch: 2240, Minibatch Loss= 0.6902, Training Accuracy= 0.544\n",
      "Epoch: 2250, Minibatch Loss= 0.6891, Training Accuracy= 0.544\n",
      "Epoch: 2260, Minibatch Loss= 0.6899, Training Accuracy= 0.545\n",
      "Epoch: 2270, Minibatch Loss= 0.6868, Training Accuracy= 0.550\n",
      "Epoch: 2280, Minibatch Loss= 0.6878, Training Accuracy= 0.550\n",
      "Epoch: 2290, Minibatch Loss= 0.6855, Training Accuracy= 0.556\n",
      "Epoch: 2300, Minibatch Loss= 0.7046, Training Accuracy= 0.530\n",
      "Epoch: 2310, Minibatch Loss= 0.6858, Training Accuracy= 0.554\n",
      "Epoch: 2320, Minibatch Loss= 0.7013, Training Accuracy= 0.508\n",
      "Epoch: 2330, Minibatch Loss= 0.6967, Training Accuracy= 0.514\n",
      "Epoch: 2340, Minibatch Loss= 0.6941, Training Accuracy= 0.508\n",
      "Epoch: 2350, Minibatch Loss= 0.6918, Training Accuracy= 0.527\n",
      "Epoch: 2360, Minibatch Loss= 0.6959, Training Accuracy= 0.507\n",
      "Epoch: 2370, Minibatch Loss= 0.6936, Training Accuracy= 0.512\n",
      "Epoch: 2380, Minibatch Loss= 0.6921, Training Accuracy= 0.516\n",
      "Epoch: 2390, Minibatch Loss= 0.6909, Training Accuracy= 0.525\n",
      "Epoch: 2400, Minibatch Loss= 0.6894, Training Accuracy= 0.536\n",
      "Epoch: 2410, Minibatch Loss= 0.6878, Training Accuracy= 0.543\n",
      "Epoch: 2420, Minibatch Loss= 0.6864, Training Accuracy= 0.545\n",
      "Epoch: 2430, Minibatch Loss= 0.6860, Training Accuracy= 0.547\n",
      "Epoch: 2440, Minibatch Loss= 0.6858, Training Accuracy= 0.548\n",
      "Epoch: 2450, Minibatch Loss= 0.6809, Training Accuracy= 0.565\n",
      "Epoch: 2460, Minibatch Loss= 0.6822, Training Accuracy= 0.562\n",
      "Epoch: 2470, Minibatch Loss= 0.6838, Training Accuracy= 0.556\n",
      "Epoch: 2480, Minibatch Loss= 0.6851, Training Accuracy= 0.551\n",
      "Epoch: 2490, Minibatch Loss= 0.6784, Training Accuracy= 0.567\n",
      "Epoch: 2500, Minibatch Loss= 0.6766, Training Accuracy= 0.575\n",
      "Epoch: 2510, Minibatch Loss= 0.6784, Training Accuracy= 0.568\n",
      "Epoch: 2520, Minibatch Loss= 0.6734, Training Accuracy= 0.585\n",
      "Epoch: 2530, Minibatch Loss= 0.6733, Training Accuracy= 0.580\n",
      "Epoch: 2540, Minibatch Loss= 0.7046, Training Accuracy= 0.520\n",
      "Epoch: 2550, Minibatch Loss= 0.6727, Training Accuracy= 0.585\n",
      "Epoch: 2560, Minibatch Loss= 0.6689, Training Accuracy= 0.583\n",
      "Epoch: 2570, Minibatch Loss= 0.6782, Training Accuracy= 0.568\n",
      "Epoch: 2580, Minibatch Loss= 0.6648, Training Accuracy= 0.594\n",
      "Epoch: 2590, Minibatch Loss= 0.6669, Training Accuracy= 0.589\n",
      "Epoch: 2600, Minibatch Loss= 0.7038, Training Accuracy= 0.509\n",
      "Epoch: 2610, Minibatch Loss= 0.6988, Training Accuracy= 0.514\n",
      "Epoch: 2620, Minibatch Loss= 0.6968, Training Accuracy= 0.519\n",
      "Epoch: 2630, Minibatch Loss= 0.6938, Training Accuracy= 0.525\n",
      "Epoch: 2640, Minibatch Loss= 0.6910, Training Accuracy= 0.530\n",
      "Epoch: 2650, Minibatch Loss= 0.6922, Training Accuracy= 0.529\n",
      "Epoch: 2660, Minibatch Loss= 0.6933, Training Accuracy= 0.529\n",
      "Epoch: 2670, Minibatch Loss= 0.6906, Training Accuracy= 0.539\n",
      "Epoch: 2680, Minibatch Loss= 0.6909, Training Accuracy= 0.539\n",
      "Epoch: 2690, Minibatch Loss= 0.6861, Training Accuracy= 0.547\n",
      "Epoch: 2700, Minibatch Loss= 0.6950, Training Accuracy= 0.529\n",
      "Epoch: 2710, Minibatch Loss= 0.6863, Training Accuracy= 0.546\n",
      "Epoch: 2720, Minibatch Loss= 0.6935, Training Accuracy= 0.531\n",
      "Epoch: 2730, Minibatch Loss= 0.6843, Training Accuracy= 0.551\n",
      "Epoch: 2740, Minibatch Loss= 0.6837, Training Accuracy= 0.556\n",
      "Epoch: 2750, Minibatch Loss= 0.6813, Training Accuracy= 0.558\n",
      "Epoch: 2760, Minibatch Loss= 0.7021, Training Accuracy= 0.519\n",
      "Epoch: 2770, Minibatch Loss= 0.6827, Training Accuracy= 0.551\n",
      "Epoch: 2780, Minibatch Loss= 0.6779, Training Accuracy= 0.564\n",
      "Epoch: 2790, Minibatch Loss= 0.6742, Training Accuracy= 0.566\n",
      "Epoch: 2800, Minibatch Loss= 0.6840, Training Accuracy= 0.558\n",
      "Epoch: 2810, Minibatch Loss= 0.6874, Training Accuracy= 0.555\n",
      "Epoch: 2820, Minibatch Loss= 0.6897, Training Accuracy= 0.553\n",
      "Epoch: 2830, Minibatch Loss= 0.6895, Training Accuracy= 0.550\n",
      "Epoch: 2840, Minibatch Loss= 0.6845, Training Accuracy= 0.563\n",
      "Epoch: 2850, Minibatch Loss= 0.6778, Training Accuracy= 0.565\n",
      "Epoch: 2860, Minibatch Loss= 0.7130, Training Accuracy= 0.507\n",
      "Epoch: 2870, Minibatch Loss= 0.7119, Training Accuracy= 0.511\n",
      "Epoch: 2880, Minibatch Loss= 0.7101, Training Accuracy= 0.512\n",
      "Epoch: 2890, Minibatch Loss= 0.7081, Training Accuracy= 0.513\n",
      "Epoch: 2900, Minibatch Loss= 0.7086, Training Accuracy= 0.516\n",
      "Epoch: 2910, Minibatch Loss= 0.7074, Training Accuracy= 0.517\n",
      "Epoch: 2920, Minibatch Loss= 0.7053, Training Accuracy= 0.521\n",
      "Epoch: 2930, Minibatch Loss= 0.7048, Training Accuracy= 0.521\n",
      "Epoch: 2940, Minibatch Loss= 0.7023, Training Accuracy= 0.527\n",
      "Epoch: 2950, Minibatch Loss= 0.6999, Training Accuracy= 0.528\n",
      "Epoch: 2960, Minibatch Loss= 0.7068, Training Accuracy= 0.523\n",
      "Epoch: 2970, Minibatch Loss= 0.6987, Training Accuracy= 0.531\n",
      "Epoch: 2980, Minibatch Loss= 0.7089, Training Accuracy= 0.524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2990, Minibatch Loss= 0.6918, Training Accuracy= 0.542\n",
      "Epoch: 3000, Minibatch Loss= 0.6959, Training Accuracy= 0.538\n",
      "Epoch: 3010, Minibatch Loss= 0.7021, Training Accuracy= 0.525\n",
      "Epoch: 3020, Minibatch Loss= 0.6925, Training Accuracy= 0.539\n",
      "Epoch: 3030, Minibatch Loss= 0.6980, Training Accuracy= 0.534\n",
      "Epoch: 3040, Minibatch Loss= 0.6848, Training Accuracy= 0.556\n",
      "Epoch: 3050, Minibatch Loss= 0.6989, Training Accuracy= 0.540\n",
      "Epoch: 3060, Minibatch Loss= 0.7268, Training Accuracy= 0.520\n",
      "Epoch: 3070, Minibatch Loss= 0.6830, Training Accuracy= 0.562\n",
      "Epoch: 3080, Minibatch Loss= 0.6919, Training Accuracy= 0.543\n",
      "Epoch: 3090, Minibatch Loss= 0.7042, Training Accuracy= 0.539\n",
      "Epoch: 3100, Minibatch Loss= 0.6780, Training Accuracy= 0.565\n",
      "Epoch: 3110, Minibatch Loss= 0.7293, Training Accuracy= 0.498\n",
      "Epoch: 3120, Minibatch Loss= 0.7261, Training Accuracy= 0.498\n",
      "Epoch: 3130, Minibatch Loss= 0.7254, Training Accuracy= 0.498\n",
      "Epoch: 3140, Minibatch Loss= 0.7245, Training Accuracy= 0.498\n",
      "Epoch: 3150, Minibatch Loss= 0.7233, Training Accuracy= 0.498\n",
      "Epoch: 3160, Minibatch Loss= 0.7218, Training Accuracy= 0.498\n",
      "Epoch: 3170, Minibatch Loss= 0.7205, Training Accuracy= 0.498\n",
      "Epoch: 3180, Minibatch Loss= 0.7195, Training Accuracy= 0.498\n",
      "Epoch: 3190, Minibatch Loss= 0.7187, Training Accuracy= 0.498\n",
      "Epoch: 3200, Minibatch Loss= 0.7181, Training Accuracy= 0.498\n",
      "Epoch: 3210, Minibatch Loss= 0.7176, Training Accuracy= 0.498\n",
      "Epoch: 3220, Minibatch Loss= 0.7171, Training Accuracy= 0.498\n",
      "Epoch: 3230, Minibatch Loss= 0.7167, Training Accuracy= 0.498\n",
      "Epoch: 3240, Minibatch Loss= 0.7163, Training Accuracy= 0.498\n",
      "Epoch: 3250, Minibatch Loss= 0.7160, Training Accuracy= 0.498\n",
      "Epoch: 3260, Minibatch Loss= 0.7156, Training Accuracy= 0.498\n",
      "Epoch: 3270, Minibatch Loss= 0.7152, Training Accuracy= 0.498\n",
      "Epoch: 3280, Minibatch Loss= 0.7149, Training Accuracy= 0.498\n",
      "Epoch: 3290, Minibatch Loss= 0.7145, Training Accuracy= 0.498\n",
      "Epoch: 3300, Minibatch Loss= 0.7141, Training Accuracy= 0.498\n",
      "Epoch: 3310, Minibatch Loss= 0.7138, Training Accuracy= 0.498\n",
      "Epoch: 3320, Minibatch Loss= 0.7135, Training Accuracy= 0.498\n",
      "Epoch: 3330, Minibatch Loss= 0.7132, Training Accuracy= 0.498\n",
      "Epoch: 3340, Minibatch Loss= 0.7129, Training Accuracy= 0.498\n",
      "Epoch: 3350, Minibatch Loss= 0.7126, Training Accuracy= 0.498\n",
      "Epoch: 3360, Minibatch Loss= 0.7123, Training Accuracy= 0.498\n",
      "Epoch: 3370, Minibatch Loss= 0.7121, Training Accuracy= 0.498\n",
      "Epoch: 3380, Minibatch Loss= 0.7119, Training Accuracy= 0.498\n",
      "Epoch: 3390, Minibatch Loss= 0.7117, Training Accuracy= 0.498\n",
      "Epoch: 3400, Minibatch Loss= 0.7115, Training Accuracy= 0.498\n",
      "Epoch: 3410, Minibatch Loss= 0.7113, Training Accuracy= 0.498\n",
      "Epoch: 3420, Minibatch Loss= 0.7111, Training Accuracy= 0.498\n",
      "Epoch: 3430, Minibatch Loss= 0.7109, Training Accuracy= 0.498\n",
      "Epoch: 3440, Minibatch Loss= 0.7108, Training Accuracy= 0.498\n",
      "Epoch: 3450, Minibatch Loss= 0.7106, Training Accuracy= 0.498\n",
      "Epoch: 3460, Minibatch Loss= 0.7105, Training Accuracy= 0.498\n",
      "Epoch: 3470, Minibatch Loss= 0.7104, Training Accuracy= 0.498\n",
      "Epoch: 3480, Minibatch Loss= 0.7102, Training Accuracy= 0.498\n",
      "Epoch: 3490, Minibatch Loss= 0.7101, Training Accuracy= 0.498\n",
      "Epoch: 3500, Minibatch Loss= 0.7100, Training Accuracy= 0.498\n",
      "Epoch: 3510, Minibatch Loss= 0.7099, Training Accuracy= 0.498\n",
      "Epoch: 3520, Minibatch Loss= 0.7098, Training Accuracy= 0.498\n",
      "Epoch: 3530, Minibatch Loss= 0.7097, Training Accuracy= 0.498\n",
      "Epoch: 3540, Minibatch Loss= 0.7096, Training Accuracy= 0.498\n",
      "Epoch: 3550, Minibatch Loss= 0.7095, Training Accuracy= 0.498\n",
      "Epoch: 3560, Minibatch Loss= 0.7095, Training Accuracy= 0.498\n",
      "Epoch: 3570, Minibatch Loss= 0.7094, Training Accuracy= 0.498\n",
      "Epoch: 3580, Minibatch Loss= 0.7093, Training Accuracy= 0.498\n",
      "Epoch: 3590, Minibatch Loss= 0.7093, Training Accuracy= 0.498\n",
      "Epoch: 3600, Minibatch Loss= 0.7092, Training Accuracy= 0.498\n",
      "Epoch: 3610, Minibatch Loss= 0.7092, Training Accuracy= 0.498\n",
      "Epoch: 3620, Minibatch Loss= 0.7092, Training Accuracy= 0.498\n",
      "Epoch: 3630, Minibatch Loss= 0.7091, Training Accuracy= 0.498\n",
      "Epoch: 3640, Minibatch Loss= 0.7091, Training Accuracy= 0.498\n",
      "Epoch: 3650, Minibatch Loss= 0.7091, Training Accuracy= 0.498\n",
      "Epoch: 3660, Minibatch Loss= 0.7091, Training Accuracy= 0.498\n",
      "Epoch: 3670, Minibatch Loss= 0.7091, Training Accuracy= 0.498\n",
      "Epoch: 3680, Minibatch Loss= 0.7091, Training Accuracy= 0.498\n",
      "Epoch: 3690, Minibatch Loss= 0.7091, Training Accuracy= 0.498\n",
      "Epoch: 3700, Minibatch Loss= 0.7090, Training Accuracy= 0.498\n",
      "Epoch: 3710, Minibatch Loss= 0.7090, Training Accuracy= 0.498\n",
      "Epoch: 3720, Minibatch Loss= 0.7090, Training Accuracy= 0.498\n",
      "Epoch: 3730, Minibatch Loss= 0.7090, Training Accuracy= 0.498\n",
      "Epoch: 3740, Minibatch Loss= 0.7089, Training Accuracy= 0.498\n",
      "Epoch: 3750, Minibatch Loss= 0.7088, Training Accuracy= 0.498\n",
      "Epoch: 3760, Minibatch Loss= 0.7087, Training Accuracy= 0.498\n",
      "Epoch: 3770, Minibatch Loss= 0.7086, Training Accuracy= 0.498\n",
      "Epoch: 3780, Minibatch Loss= 0.7085, Training Accuracy= 0.498\n",
      "Epoch: 3790, Minibatch Loss= 0.7084, Training Accuracy= 0.498\n",
      "Epoch: 3800, Minibatch Loss= 0.7082, Training Accuracy= 0.498\n",
      "Epoch: 3810, Minibatch Loss= 0.7081, Training Accuracy= 0.498\n",
      "Epoch: 3820, Minibatch Loss= 0.7079, Training Accuracy= 0.498\n",
      "Epoch: 3830, Minibatch Loss= 0.7077, Training Accuracy= 0.498\n",
      "Epoch: 3840, Minibatch Loss= 0.7076, Training Accuracy= 0.498\n",
      "Epoch: 3850, Minibatch Loss= 0.7074, Training Accuracy= 0.499\n",
      "Epoch: 3860, Minibatch Loss= 0.7072, Training Accuracy= 0.499\n",
      "Epoch: 3870, Minibatch Loss= 0.7070, Training Accuracy= 0.498\n",
      "Epoch: 3880, Minibatch Loss= 0.7068, Training Accuracy= 0.499\n",
      "Epoch: 3890, Minibatch Loss= 0.7066, Training Accuracy= 0.500\n",
      "Epoch: 3900, Minibatch Loss= 0.7064, Training Accuracy= 0.501\n",
      "Epoch: 3910, Minibatch Loss= 0.7062, Training Accuracy= 0.501\n",
      "Epoch: 3920, Minibatch Loss= 0.7060, Training Accuracy= 0.501\n",
      "Epoch: 3930, Minibatch Loss= 0.7058, Training Accuracy= 0.501\n",
      "Epoch: 3940, Minibatch Loss= 0.7056, Training Accuracy= 0.501\n",
      "Epoch: 3950, Minibatch Loss= 0.7054, Training Accuracy= 0.501\n",
      "Epoch: 3960, Minibatch Loss= 0.7052, Training Accuracy= 0.502\n",
      "Epoch: 3970, Minibatch Loss= 0.7050, Training Accuracy= 0.503\n",
      "Epoch: 3980, Minibatch Loss= 0.7048, Training Accuracy= 0.503\n",
      "Epoch: 3990, Minibatch Loss= 0.7046, Training Accuracy= 0.504\n",
      "Epoch: 4000, Minibatch Loss= 0.7044, Training Accuracy= 0.505\n",
      "Epoch: 4010, Minibatch Loss= 0.7042, Training Accuracy= 0.506\n",
      "Epoch: 4020, Minibatch Loss= 0.7039, Training Accuracy= 0.506\n",
      "Epoch: 4030, Minibatch Loss= 0.7037, Training Accuracy= 0.506\n",
      "Epoch: 4040, Minibatch Loss= 0.7035, Training Accuracy= 0.506\n",
      "Epoch: 4050, Minibatch Loss= 0.7033, Training Accuracy= 0.506\n",
      "Epoch: 4060, Minibatch Loss= 0.7032, Training Accuracy= 0.506\n",
      "Epoch: 4070, Minibatch Loss= 0.7031, Training Accuracy= 0.507\n",
      "Epoch: 4080, Minibatch Loss= 0.7031, Training Accuracy= 0.507\n",
      "Epoch: 4090, Minibatch Loss= 0.7031, Training Accuracy= 0.507\n",
      "Epoch: 4100, Minibatch Loss= 0.7032, Training Accuracy= 0.507\n",
      "Epoch: 4110, Minibatch Loss= 0.7034, Training Accuracy= 0.508\n",
      "Epoch: 4120, Minibatch Loss= 0.7035, Training Accuracy= 0.508\n",
      "Epoch: 4130, Minibatch Loss= 0.7034, Training Accuracy= 0.507\n",
      "Epoch: 4140, Minibatch Loss= 0.7032, Training Accuracy= 0.509\n",
      "Epoch: 4150, Minibatch Loss= 0.7028, Training Accuracy= 0.509\n",
      "Epoch: 4160, Minibatch Loss= 0.7027, Training Accuracy= 0.510\n",
      "Epoch: 4170, Minibatch Loss= 0.7028, Training Accuracy= 0.511\n",
      "Epoch: 4180, Minibatch Loss= 0.7029, Training Accuracy= 0.511\n",
      "Epoch: 4190, Minibatch Loss= 0.7028, Training Accuracy= 0.514\n",
      "Epoch: 4200, Minibatch Loss= 0.7031, Training Accuracy= 0.513\n",
      "Epoch: 4210, Minibatch Loss= 0.7020, Training Accuracy= 0.513\n",
      "Epoch: 4220, Minibatch Loss= 0.7020, Training Accuracy= 0.514\n",
      "Epoch: 4230, Minibatch Loss= 0.7027, Training Accuracy= 0.514\n",
      "Epoch: 4240, Minibatch Loss= 0.7017, Training Accuracy= 0.515\n",
      "Epoch: 4250, Minibatch Loss= 0.7040, Training Accuracy= 0.514\n",
      "Epoch: 4260, Minibatch Loss= 0.7028, Training Accuracy= 0.515\n",
      "Epoch: 4270, Minibatch Loss= 0.7048, Training Accuracy= 0.512\n",
      "Epoch: 4280, Minibatch Loss= 0.7046, Training Accuracy= 0.513\n",
      "Epoch: 4290, Minibatch Loss= 0.7033, Training Accuracy= 0.515\n",
      "Epoch: 4300, Minibatch Loss= 0.7051, Training Accuracy= 0.512\n",
      "Epoch: 4310, Minibatch Loss= 0.7040, Training Accuracy= 0.514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4320, Minibatch Loss= 0.7043, Training Accuracy= 0.515\n",
      "Epoch: 4330, Minibatch Loss= 0.7044, Training Accuracy= 0.512\n",
      "Epoch: 4340, Minibatch Loss= 0.7024, Training Accuracy= 0.516\n",
      "Epoch: 4350, Minibatch Loss= 0.7098, Training Accuracy= 0.511\n",
      "Epoch: 4360, Minibatch Loss= 0.7019, Training Accuracy= 0.516\n",
      "Epoch: 4370, Minibatch Loss= 0.7022, Training Accuracy= 0.517\n",
      "Epoch: 4380, Minibatch Loss= 0.7013, Training Accuracy= 0.515\n",
      "Epoch: 4390, Minibatch Loss= 0.7016, Training Accuracy= 0.515\n",
      "Epoch: 4400, Minibatch Loss= 0.7021, Training Accuracy= 0.515\n",
      "Epoch: 4410, Minibatch Loss= 0.6987, Training Accuracy= 0.523\n",
      "Epoch: 4420, Minibatch Loss= 0.7000, Training Accuracy= 0.521\n",
      "Epoch: 4430, Minibatch Loss= 0.7000, Training Accuracy= 0.516\n",
      "Epoch: 4440, Minibatch Loss= 0.6969, Training Accuracy= 0.521\n",
      "Epoch: 4450, Minibatch Loss= 0.7074, Training Accuracy= 0.512\n",
      "Epoch: 4460, Minibatch Loss= 0.6954, Training Accuracy= 0.526\n",
      "Epoch: 4470, Minibatch Loss= 0.6961, Training Accuracy= 0.525\n",
      "Epoch: 4480, Minibatch Loss= 0.6944, Training Accuracy= 0.526\n",
      "Epoch: 4490, Minibatch Loss= 0.7127, Training Accuracy= 0.509\n",
      "Epoch: 4500, Minibatch Loss= 0.7012, Training Accuracy= 0.516\n",
      "Epoch: 4510, Minibatch Loss= 0.6993, Training Accuracy= 0.522\n",
      "Epoch: 4520, Minibatch Loss= 0.6961, Training Accuracy= 0.529\n",
      "Epoch: 4530, Minibatch Loss= 0.7069, Training Accuracy= 0.519\n",
      "Epoch: 4540, Minibatch Loss= 0.6994, Training Accuracy= 0.527\n",
      "Epoch: 4550, Minibatch Loss= 0.6914, Training Accuracy= 0.537\n",
      "Epoch: 4560, Minibatch Loss= 0.7173, Training Accuracy= 0.511\n",
      "Epoch: 4570, Minibatch Loss= 0.6984, Training Accuracy= 0.525\n",
      "Epoch: 4580, Minibatch Loss= 0.7053, Training Accuracy= 0.510\n",
      "Epoch: 4590, Minibatch Loss= 0.7048, Training Accuracy= 0.511\n",
      "Epoch: 4600, Minibatch Loss= 0.7044, Training Accuracy= 0.510\n",
      "Epoch: 4610, Minibatch Loss= 0.7051, Training Accuracy= 0.511\n",
      "Epoch: 4620, Minibatch Loss= 0.7050, Training Accuracy= 0.512\n",
      "Epoch: 4630, Minibatch Loss= 0.7065, Training Accuracy= 0.513\n",
      "Epoch: 4640, Minibatch Loss= 0.7064, Training Accuracy= 0.514\n",
      "Epoch: 4650, Minibatch Loss= 0.7060, Training Accuracy= 0.516\n",
      "Epoch: 4660, Minibatch Loss= 0.7063, Training Accuracy= 0.516\n",
      "Epoch: 4670, Minibatch Loss= 0.7067, Training Accuracy= 0.515\n",
      "Epoch: 4680, Minibatch Loss= 0.7069, Training Accuracy= 0.516\n",
      "Epoch: 4690, Minibatch Loss= 0.7062, Training Accuracy= 0.519\n",
      "Epoch: 4700, Minibatch Loss= 0.7056, Training Accuracy= 0.521\n",
      "Epoch: 4710, Minibatch Loss= 0.7056, Training Accuracy= 0.521\n",
      "Epoch: 4720, Minibatch Loss= 0.7045, Training Accuracy= 0.524\n",
      "Epoch: 4730, Minibatch Loss= 0.7063, Training Accuracy= 0.521\n",
      "Epoch: 4740, Minibatch Loss= 0.7061, Training Accuracy= 0.523\n",
      "Epoch: 4750, Minibatch Loss= 0.6978, Training Accuracy= 0.531\n",
      "Epoch: 4760, Minibatch Loss= 0.7103, Training Accuracy= 0.525\n",
      "Epoch: 4770, Minibatch Loss= 0.7050, Training Accuracy= 0.529\n",
      "Epoch: 4780, Minibatch Loss= 0.7022, Training Accuracy= 0.530\n",
      "Epoch: 4790, Minibatch Loss= 0.7064, Training Accuracy= 0.526\n",
      "Epoch: 4800, Minibatch Loss= 0.7046, Training Accuracy= 0.533\n",
      "Epoch: 4810, Minibatch Loss= 0.6973, Training Accuracy= 0.534\n",
      "Epoch: 4820, Minibatch Loss= 0.7001, Training Accuracy= 0.538\n",
      "Epoch: 4830, Minibatch Loss= 0.7087, Training Accuracy= 0.521\n",
      "Epoch: 4840, Minibatch Loss= 0.6926, Training Accuracy= 0.538\n",
      "Epoch: 4850, Minibatch Loss= 0.7051, Training Accuracy= 0.530\n",
      "Epoch: 4860, Minibatch Loss= 0.7025, Training Accuracy= 0.535\n",
      "Epoch: 4870, Minibatch Loss= 0.7002, Training Accuracy= 0.537\n",
      "Epoch: 4880, Minibatch Loss= 0.6958, Training Accuracy= 0.542\n",
      "Epoch: 4890, Minibatch Loss= 0.7032, Training Accuracy= 0.538\n",
      "Epoch: 4900, Minibatch Loss= 0.6961, Training Accuracy= 0.546\n",
      "Epoch: 4910, Minibatch Loss= 0.7093, Training Accuracy= 0.527\n",
      "Epoch: 4920, Minibatch Loss= 0.6911, Training Accuracy= 0.548\n",
      "Epoch: 4930, Minibatch Loss= 0.6912, Training Accuracy= 0.547\n",
      "Epoch: 4940, Minibatch Loss= 0.6957, Training Accuracy= 0.538\n",
      "Epoch: 4950, Minibatch Loss= 0.6997, Training Accuracy= 0.542\n",
      "Epoch: 4960, Minibatch Loss= 0.6858, Training Accuracy= 0.550\n",
      "Epoch: 4970, Minibatch Loss= 0.7047, Training Accuracy= 0.522\n",
      "Epoch: 4980, Minibatch Loss= 0.6906, Training Accuracy= 0.546\n",
      "Epoch: 4990, Minibatch Loss= 0.6935, Training Accuracy= 0.550\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5046\n",
      "Replication: 2: \n",
      "Epoch: 0, Minibatch Loss= 0.7105, Training Accuracy= 0.500\n",
      "Epoch: 10, Minibatch Loss= 0.6952, Training Accuracy= 0.500\n",
      "Epoch: 20, Minibatch Loss= 0.6938, Training Accuracy= 0.501\n",
      "Epoch: 30, Minibatch Loss= 0.6934, Training Accuracy= 0.505\n",
      "Epoch: 40, Minibatch Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 50, Minibatch Loss= 0.6932, Training Accuracy= 0.501\n",
      "Epoch: 60, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 70, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 80, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 90, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 100, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 110, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 120, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 130, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 140, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 150, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 160, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 170, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 180, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 190, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 200, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 210, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 220, Minibatch Loss= 0.6931, Training Accuracy= 0.503\n",
      "Epoch: 230, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 240, Minibatch Loss= 0.6931, Training Accuracy= 0.504\n",
      "Epoch: 250, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 260, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 270, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 280, Minibatch Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 290, Minibatch Loss= 0.6929, Training Accuracy= 0.509\n",
      "Epoch: 300, Minibatch Loss= 0.6929, Training Accuracy= 0.511\n",
      "Epoch: 310, Minibatch Loss= 0.6928, Training Accuracy= 0.512\n",
      "Epoch: 320, Minibatch Loss= 0.6927, Training Accuracy= 0.515\n",
      "Epoch: 330, Minibatch Loss= 0.6926, Training Accuracy= 0.514\n",
      "Epoch: 340, Minibatch Loss= 0.6925, Training Accuracy= 0.515\n",
      "Epoch: 350, Minibatch Loss= 0.6924, Training Accuracy= 0.515\n",
      "Epoch: 360, Minibatch Loss= 0.6923, Training Accuracy= 0.514\n",
      "Epoch: 370, Minibatch Loss= 0.6923, Training Accuracy= 0.515\n",
      "Epoch: 380, Minibatch Loss= 0.6922, Training Accuracy= 0.514\n",
      "Epoch: 390, Minibatch Loss= 0.6921, Training Accuracy= 0.515\n",
      "Epoch: 400, Minibatch Loss= 0.6920, Training Accuracy= 0.515\n",
      "Epoch: 410, Minibatch Loss= 0.6920, Training Accuracy= 0.515\n",
      "Epoch: 420, Minibatch Loss= 0.6919, Training Accuracy= 0.513\n",
      "Epoch: 430, Minibatch Loss= 0.6919, Training Accuracy= 0.513\n",
      "Epoch: 440, Minibatch Loss= 0.6918, Training Accuracy= 0.512\n",
      "Epoch: 450, Minibatch Loss= 0.6918, Training Accuracy= 0.512\n",
      "Epoch: 460, Minibatch Loss= 0.6918, Training Accuracy= 0.512\n",
      "Epoch: 470, Minibatch Loss= 0.6918, Training Accuracy= 0.511\n",
      "Epoch: 480, Minibatch Loss= 0.6917, Training Accuracy= 0.513\n",
      "Epoch: 490, Minibatch Loss= 0.6917, Training Accuracy= 0.512\n",
      "Epoch: 500, Minibatch Loss= 0.6917, Training Accuracy= 0.512\n",
      "Epoch: 510, Minibatch Loss= 0.6917, Training Accuracy= 0.512\n",
      "Epoch: 520, Minibatch Loss= 0.6916, Training Accuracy= 0.514\n",
      "Epoch: 530, Minibatch Loss= 0.6916, Training Accuracy= 0.514\n",
      "Epoch: 540, Minibatch Loss= 0.6916, Training Accuracy= 0.515\n",
      "Epoch: 550, Minibatch Loss= 0.6917, Training Accuracy= 0.516\n",
      "Epoch: 560, Minibatch Loss= 0.6916, Training Accuracy= 0.516\n",
      "Epoch: 570, Minibatch Loss= 0.6915, Training Accuracy= 0.514\n",
      "Epoch: 580, Minibatch Loss= 0.6915, Training Accuracy= 0.513\n",
      "Epoch: 590, Minibatch Loss= 0.6916, Training Accuracy= 0.515\n",
      "Epoch: 600, Minibatch Loss= 0.6917, Training Accuracy= 0.522\n",
      "Epoch: 610, Minibatch Loss= 0.6915, Training Accuracy= 0.517\n",
      "Epoch: 620, Minibatch Loss= 0.6914, Training Accuracy= 0.515\n",
      "Epoch: 630, Minibatch Loss= 0.6912, Training Accuracy= 0.517\n",
      "Epoch: 640, Minibatch Loss= 0.6912, Training Accuracy= 0.518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 650, Minibatch Loss= 0.6910, Training Accuracy= 0.520\n",
      "Epoch: 660, Minibatch Loss= 0.6908, Training Accuracy= 0.522\n",
      "Epoch: 670, Minibatch Loss= 0.6908, Training Accuracy= 0.519\n",
      "Epoch: 680, Minibatch Loss= 0.6916, Training Accuracy= 0.522\n",
      "Epoch: 690, Minibatch Loss= 0.6913, Training Accuracy= 0.521\n",
      "Epoch: 700, Minibatch Loss= 0.6912, Training Accuracy= 0.522\n",
      "Epoch: 710, Minibatch Loss= 0.6909, Training Accuracy= 0.525\n",
      "Epoch: 720, Minibatch Loss= 0.6911, Training Accuracy= 0.526\n",
      "Epoch: 730, Minibatch Loss= 0.6911, Training Accuracy= 0.521\n",
      "Epoch: 740, Minibatch Loss= 0.6919, Training Accuracy= 0.512\n",
      "Epoch: 750, Minibatch Loss= 0.6922, Training Accuracy= 0.512\n",
      "Epoch: 760, Minibatch Loss= 0.6963, Training Accuracy= 0.503\n",
      "Epoch: 770, Minibatch Loss= 0.6926, Training Accuracy= 0.510\n",
      "Epoch: 780, Minibatch Loss= 0.6917, Training Accuracy= 0.522\n",
      "Epoch: 790, Minibatch Loss= 0.6915, Training Accuracy= 0.523\n",
      "Epoch: 800, Minibatch Loss= 0.6918, Training Accuracy= 0.522\n",
      "Epoch: 810, Minibatch Loss= 0.6916, Training Accuracy= 0.523\n",
      "Epoch: 820, Minibatch Loss= 0.6932, Training Accuracy= 0.504\n",
      "Epoch: 830, Minibatch Loss= 0.6929, Training Accuracy= 0.507\n",
      "Epoch: 840, Minibatch Loss= 0.6928, Training Accuracy= 0.512\n",
      "Epoch: 850, Minibatch Loss= 0.6926, Training Accuracy= 0.512\n",
      "Epoch: 860, Minibatch Loss= 0.6925, Training Accuracy= 0.512\n",
      "Epoch: 870, Minibatch Loss= 0.6922, Training Accuracy= 0.522\n",
      "Epoch: 880, Minibatch Loss= 0.6918, Training Accuracy= 0.524\n",
      "Epoch: 890, Minibatch Loss= 0.6914, Training Accuracy= 0.521\n",
      "Epoch: 900, Minibatch Loss= 0.6908, Training Accuracy= 0.524\n",
      "Epoch: 910, Minibatch Loss= 0.6905, Training Accuracy= 0.530\n",
      "Epoch: 920, Minibatch Loss= 0.6902, Training Accuracy= 0.533\n",
      "Epoch: 930, Minibatch Loss= 0.6902, Training Accuracy= 0.530\n",
      "Epoch: 940, Minibatch Loss= 0.6904, Training Accuracy= 0.529\n",
      "Epoch: 950, Minibatch Loss= 0.6898, Training Accuracy= 0.534\n",
      "Epoch: 960, Minibatch Loss= 0.6887, Training Accuracy= 0.536\n",
      "Epoch: 970, Minibatch Loss= 0.6885, Training Accuracy= 0.540\n",
      "Epoch: 980, Minibatch Loss= 0.6881, Training Accuracy= 0.541\n",
      "Epoch: 990, Minibatch Loss= 0.6915, Training Accuracy= 0.526\n",
      "Epoch: 1000, Minibatch Loss= 0.6929, Training Accuracy= 0.528\n",
      "Epoch: 1010, Minibatch Loss= 0.6881, Training Accuracy= 0.542\n",
      "Epoch: 1020, Minibatch Loss= 0.6852, Training Accuracy= 0.546\n",
      "Epoch: 1030, Minibatch Loss= 0.6871, Training Accuracy= 0.544\n",
      "Epoch: 1040, Minibatch Loss= 0.6952, Training Accuracy= 0.525\n",
      "Epoch: 1050, Minibatch Loss= 0.6840, Training Accuracy= 0.555\n",
      "Epoch: 1060, Minibatch Loss= 0.6864, Training Accuracy= 0.546\n",
      "Epoch: 1070, Minibatch Loss= 0.6876, Training Accuracy= 0.545\n",
      "Epoch: 1080, Minibatch Loss= 0.6886, Training Accuracy= 0.545\n",
      "Epoch: 1090, Minibatch Loss= 0.6823, Training Accuracy= 0.564\n",
      "Epoch: 1100, Minibatch Loss= 0.6840, Training Accuracy= 0.558\n",
      "Epoch: 1110, Minibatch Loss= 0.6942, Training Accuracy= 0.533\n",
      "Epoch: 1120, Minibatch Loss= 0.6878, Training Accuracy= 0.544\n",
      "Epoch: 1130, Minibatch Loss= 0.6866, Training Accuracy= 0.550\n",
      "Epoch: 1140, Minibatch Loss= 0.6858, Training Accuracy= 0.551\n",
      "Epoch: 1150, Minibatch Loss= 0.6839, Training Accuracy= 0.555\n",
      "Epoch: 1160, Minibatch Loss= 0.6799, Training Accuracy= 0.562\n",
      "Epoch: 1170, Minibatch Loss= 0.6816, Training Accuracy= 0.555\n",
      "Epoch: 1180, Minibatch Loss= 0.6815, Training Accuracy= 0.561\n",
      "Epoch: 1190, Minibatch Loss= 0.6882, Training Accuracy= 0.550\n",
      "Epoch: 1200, Minibatch Loss= 0.6764, Training Accuracy= 0.572\n",
      "Epoch: 1210, Minibatch Loss= 0.6715, Training Accuracy= 0.585\n",
      "Epoch: 1220, Minibatch Loss= 0.6728, Training Accuracy= 0.581\n",
      "Epoch: 1230, Minibatch Loss= 0.6823, Training Accuracy= 0.565\n",
      "Epoch: 1240, Minibatch Loss= 0.6729, Training Accuracy= 0.580\n",
      "Epoch: 1250, Minibatch Loss= 0.6716, Training Accuracy= 0.583\n",
      "Epoch: 1260, Minibatch Loss= 0.6919, Training Accuracy= 0.561\n",
      "Epoch: 1270, Minibatch Loss= 0.6678, Training Accuracy= 0.594\n",
      "Epoch: 1280, Minibatch Loss= 0.6636, Training Accuracy= 0.599\n",
      "Epoch: 1290, Minibatch Loss= 0.6565, Training Accuracy= 0.607\n",
      "Epoch: 1300, Minibatch Loss= 0.6611, Training Accuracy= 0.603\n",
      "Epoch: 1310, Minibatch Loss= 0.6688, Training Accuracy= 0.589\n",
      "Epoch: 1320, Minibatch Loss= 0.6563, Training Accuracy= 0.611\n",
      "Epoch: 1330, Minibatch Loss= 0.6463, Training Accuracy= 0.618\n",
      "Epoch: 1340, Minibatch Loss= 0.6696, Training Accuracy= 0.591\n",
      "Epoch: 1350, Minibatch Loss= 0.6440, Training Accuracy= 0.629\n",
      "Epoch: 1360, Minibatch Loss= 0.6377, Training Accuracy= 0.633\n",
      "Epoch: 1370, Minibatch Loss= 0.6549, Training Accuracy= 0.614\n",
      "Epoch: 1380, Minibatch Loss= 0.6744, Training Accuracy= 0.593\n",
      "Epoch: 1390, Minibatch Loss= 0.6879, Training Accuracy= 0.545\n",
      "Epoch: 1400, Minibatch Loss= 0.6756, Training Accuracy= 0.568\n",
      "Epoch: 1410, Minibatch Loss= 0.6692, Training Accuracy= 0.588\n",
      "Epoch: 1420, Minibatch Loss= 0.6584, Training Accuracy= 0.606\n",
      "Epoch: 1430, Minibatch Loss= 0.6485, Training Accuracy= 0.615\n",
      "Epoch: 1440, Minibatch Loss= 0.6453, Training Accuracy= 0.623\n",
      "Epoch: 1450, Minibatch Loss= 0.6446, Training Accuracy= 0.623\n",
      "Epoch: 1460, Minibatch Loss= 0.6335, Training Accuracy= 0.636\n",
      "Epoch: 1470, Minibatch Loss= 0.6430, Training Accuracy= 0.626\n",
      "Epoch: 1480, Minibatch Loss= 0.6392, Training Accuracy= 0.631\n",
      "Epoch: 1490, Minibatch Loss= 0.6502, Training Accuracy= 0.619\n",
      "Epoch: 1500, Minibatch Loss= 0.6427, Training Accuracy= 0.626\n",
      "Epoch: 1510, Minibatch Loss= 0.6226, Training Accuracy= 0.649\n",
      "Epoch: 1520, Minibatch Loss= 0.7184, Training Accuracy= 0.516\n",
      "Epoch: 1530, Minibatch Loss= 0.6832, Training Accuracy= 0.542\n",
      "Epoch: 1540, Minibatch Loss= 0.6755, Training Accuracy= 0.563\n",
      "Epoch: 1550, Minibatch Loss= 0.6747, Training Accuracy= 0.566\n",
      "Epoch: 1560, Minibatch Loss= 0.6690, Training Accuracy= 0.574\n",
      "Epoch: 1570, Minibatch Loss= 0.6653, Training Accuracy= 0.581\n",
      "Epoch: 1580, Minibatch Loss= 0.6675, Training Accuracy= 0.581\n",
      "Epoch: 1590, Minibatch Loss= 0.7174, Training Accuracy= 0.524\n",
      "Epoch: 1600, Minibatch Loss= 0.6793, Training Accuracy= 0.564\n",
      "Epoch: 1610, Minibatch Loss= 0.6715, Training Accuracy= 0.585\n",
      "Epoch: 1620, Minibatch Loss= 0.6630, Training Accuracy= 0.592\n",
      "Epoch: 1630, Minibatch Loss= 0.6619, Training Accuracy= 0.598\n",
      "Epoch: 1640, Minibatch Loss= 0.6625, Training Accuracy= 0.592\n",
      "Epoch: 1650, Minibatch Loss= 0.6578, Training Accuracy= 0.600\n",
      "Epoch: 1660, Minibatch Loss= 0.6637, Training Accuracy= 0.595\n",
      "Epoch: 1670, Minibatch Loss= 0.6568, Training Accuracy= 0.599\n",
      "Epoch: 1680, Minibatch Loss= 0.6702, Training Accuracy= 0.593\n",
      "Epoch: 1690, Minibatch Loss= 0.6869, Training Accuracy= 0.552\n",
      "Epoch: 1700, Minibatch Loss= 0.6660, Training Accuracy= 0.588\n",
      "Epoch: 1710, Minibatch Loss= 0.6591, Training Accuracy= 0.597\n",
      "Epoch: 1720, Minibatch Loss= 0.6595, Training Accuracy= 0.602\n",
      "Epoch: 1730, Minibatch Loss= 0.6498, Training Accuracy= 0.610\n",
      "Epoch: 1740, Minibatch Loss= 0.6524, Training Accuracy= 0.610\n",
      "Epoch: 1750, Minibatch Loss= 0.6505, Training Accuracy= 0.613\n",
      "Epoch: 1760, Minibatch Loss= 0.6491, Training Accuracy= 0.613\n",
      "Epoch: 1770, Minibatch Loss= 0.6470, Training Accuracy= 0.616\n",
      "Epoch: 1780, Minibatch Loss= 0.6446, Training Accuracy= 0.623\n",
      "Epoch: 1790, Minibatch Loss= 0.6934, Training Accuracy= 0.550\n",
      "Epoch: 1800, Minibatch Loss= 0.6747, Training Accuracy= 0.576\n",
      "Epoch: 1810, Minibatch Loss= 0.6673, Training Accuracy= 0.594\n",
      "Epoch: 1820, Minibatch Loss= 0.6706, Training Accuracy= 0.586\n",
      "Epoch: 1830, Minibatch Loss= 0.6684, Training Accuracy= 0.590\n",
      "Epoch: 1840, Minibatch Loss= 0.6759, Training Accuracy= 0.585\n",
      "Epoch: 1850, Minibatch Loss= 0.6456, Training Accuracy= 0.622\n",
      "Epoch: 1860, Minibatch Loss= 0.6538, Training Accuracy= 0.614\n",
      "Epoch: 1870, Minibatch Loss= 0.6418, Training Accuracy= 0.625\n",
      "Epoch: 1880, Minibatch Loss= 0.6539, Training Accuracy= 0.610\n",
      "Epoch: 1890, Minibatch Loss= 0.6314, Training Accuracy= 0.637\n",
      "Epoch: 1900, Minibatch Loss= 0.6309, Training Accuracy= 0.638\n",
      "Epoch: 1910, Minibatch Loss= 0.6273, Training Accuracy= 0.640\n",
      "Epoch: 1920, Minibatch Loss= 0.6272, Training Accuracy= 0.649\n",
      "Epoch: 1930, Minibatch Loss= 0.6175, Training Accuracy= 0.653\n",
      "Epoch: 1940, Minibatch Loss= 0.6215, Training Accuracy= 0.649\n",
      "Epoch: 1950, Minibatch Loss= 0.6221, Training Accuracy= 0.648\n",
      "Epoch: 1960, Minibatch Loss= 0.6234, Training Accuracy= 0.648\n",
      "Epoch: 1970, Minibatch Loss= 0.6351, Training Accuracy= 0.638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1980, Minibatch Loss= 0.6169, Training Accuracy= 0.651\n",
      "Epoch: 1990, Minibatch Loss= 0.6076, Training Accuracy= 0.662\n",
      "Epoch: 2000, Minibatch Loss= 0.6148, Training Accuracy= 0.658\n",
      "Epoch: 2010, Minibatch Loss= 0.6218, Training Accuracy= 0.652\n",
      "Epoch: 2020, Minibatch Loss= 0.6113, Training Accuracy= 0.660\n",
      "Epoch: 2030, Minibatch Loss= 0.6237, Training Accuracy= 0.644\n",
      "Epoch: 2040, Minibatch Loss= 0.5879, Training Accuracy= 0.679\n",
      "Epoch: 2050, Minibatch Loss= 0.5908, Training Accuracy= 0.676\n",
      "Epoch: 2060, Minibatch Loss= 0.5940, Training Accuracy= 0.679\n",
      "Epoch: 2070, Minibatch Loss= 0.5950, Training Accuracy= 0.674\n",
      "Epoch: 2080, Minibatch Loss= 0.5905, Training Accuracy= 0.677\n",
      "Epoch: 2090, Minibatch Loss= 0.6044, Training Accuracy= 0.670\n",
      "Epoch: 2100, Minibatch Loss= 0.6007, Training Accuracy= 0.670\n",
      "Epoch: 2110, Minibatch Loss= 0.5887, Training Accuracy= 0.679\n",
      "Epoch: 2120, Minibatch Loss= 0.6227, Training Accuracy= 0.649\n",
      "Epoch: 2130, Minibatch Loss= 0.6805, Training Accuracy= 0.604\n",
      "Epoch: 2140, Minibatch Loss= 0.6271, Training Accuracy= 0.643\n",
      "Epoch: 2150, Minibatch Loss= 0.6348, Training Accuracy= 0.643\n",
      "Epoch: 2160, Minibatch Loss= 0.6735, Training Accuracy= 0.596\n",
      "Epoch: 2170, Minibatch Loss= 0.6028, Training Accuracy= 0.672\n",
      "Epoch: 2180, Minibatch Loss= 0.5770, Training Accuracy= 0.692\n",
      "Epoch: 2190, Minibatch Loss= 0.5886, Training Accuracy= 0.685\n",
      "Epoch: 2200, Minibatch Loss= 0.5660, Training Accuracy= 0.702\n",
      "Epoch: 2210, Minibatch Loss= 0.5885, Training Accuracy= 0.687\n",
      "Epoch: 2220, Minibatch Loss= 0.6377, Training Accuracy= 0.639\n",
      "Epoch: 2230, Minibatch Loss= 0.5782, Training Accuracy= 0.695\n",
      "Epoch: 2240, Minibatch Loss= 0.6286, Training Accuracy= 0.647\n",
      "Epoch: 2250, Minibatch Loss= 0.5726, Training Accuracy= 0.694\n",
      "Epoch: 2260, Minibatch Loss= 0.6177, Training Accuracy= 0.648\n",
      "Epoch: 2270, Minibatch Loss= 0.5838, Training Accuracy= 0.686\n",
      "Epoch: 2280, Minibatch Loss= 0.5726, Training Accuracy= 0.699\n",
      "Epoch: 2290, Minibatch Loss= 0.6043, Training Accuracy= 0.668\n",
      "Epoch: 2300, Minibatch Loss= 0.5757, Training Accuracy= 0.697\n",
      "Epoch: 2310, Minibatch Loss= 0.5683, Training Accuracy= 0.698\n",
      "Epoch: 2320, Minibatch Loss= 0.5774, Training Accuracy= 0.693\n",
      "Epoch: 2330, Minibatch Loss= 0.6336, Training Accuracy= 0.654\n",
      "Epoch: 2340, Minibatch Loss= 0.5565, Training Accuracy= 0.707\n",
      "Epoch: 2350, Minibatch Loss= 0.5509, Training Accuracy= 0.715\n",
      "Epoch: 2360, Minibatch Loss= 0.5669, Training Accuracy= 0.702\n",
      "Epoch: 2370, Minibatch Loss= 0.6011, Training Accuracy= 0.675\n",
      "Epoch: 2380, Minibatch Loss= 0.5621, Training Accuracy= 0.705\n",
      "Epoch: 2390, Minibatch Loss= 0.5836, Training Accuracy= 0.686\n",
      "Epoch: 2400, Minibatch Loss= 0.5906, Training Accuracy= 0.683\n",
      "Epoch: 2410, Minibatch Loss= 0.6758, Training Accuracy= 0.570\n",
      "Epoch: 2420, Minibatch Loss= 0.6387, Training Accuracy= 0.617\n",
      "Epoch: 2430, Minibatch Loss= 0.5825, Training Accuracy= 0.686\n",
      "Epoch: 2440, Minibatch Loss= 0.5481, Training Accuracy= 0.717\n",
      "Epoch: 2450, Minibatch Loss= 0.5669, Training Accuracy= 0.705\n",
      "Epoch: 2460, Minibatch Loss= 0.5654, Training Accuracy= 0.702\n",
      "Epoch: 2470, Minibatch Loss= 0.5538, Training Accuracy= 0.711\n",
      "Epoch: 2480, Minibatch Loss= 0.5618, Training Accuracy= 0.705\n",
      "Epoch: 2490, Minibatch Loss= 0.5931, Training Accuracy= 0.679\n",
      "Epoch: 2500, Minibatch Loss= 0.6042, Training Accuracy= 0.675\n",
      "Epoch: 2510, Minibatch Loss= 0.5492, Training Accuracy= 0.717\n",
      "Epoch: 2520, Minibatch Loss= 0.5450, Training Accuracy= 0.720\n",
      "Epoch: 2530, Minibatch Loss= 0.6189, Training Accuracy= 0.667\n",
      "Epoch: 2540, Minibatch Loss= 0.5658, Training Accuracy= 0.701\n",
      "Epoch: 2550, Minibatch Loss= 0.5353, Training Accuracy= 0.726\n",
      "Epoch: 2560, Minibatch Loss= 0.5456, Training Accuracy= 0.718\n",
      "Epoch: 2570, Minibatch Loss= 0.5455, Training Accuracy= 0.718\n",
      "Epoch: 2580, Minibatch Loss= 0.6956, Training Accuracy= 0.609\n",
      "Epoch: 2590, Minibatch Loss= 0.5993, Training Accuracy= 0.680\n",
      "Epoch: 2600, Minibatch Loss= 0.5478, Training Accuracy= 0.721\n",
      "Epoch: 2610, Minibatch Loss= 0.5443, Training Accuracy= 0.722\n",
      "Epoch: 2620, Minibatch Loss= 0.6028, Training Accuracy= 0.674\n",
      "Epoch: 2630, Minibatch Loss= 0.5473, Training Accuracy= 0.715\n",
      "Epoch: 2640, Minibatch Loss= 0.6373, Training Accuracy= 0.650\n",
      "Epoch: 2650, Minibatch Loss= 0.5902, Training Accuracy= 0.680\n",
      "Epoch: 2660, Minibatch Loss= 0.5225, Training Accuracy= 0.738\n",
      "Epoch: 2670, Minibatch Loss= 0.5603, Training Accuracy= 0.708\n",
      "Epoch: 2680, Minibatch Loss= 0.5642, Training Accuracy= 0.707\n",
      "Epoch: 2690, Minibatch Loss= 0.6237, Training Accuracy= 0.657\n",
      "Epoch: 2700, Minibatch Loss= 0.6897, Training Accuracy= 0.551\n",
      "Epoch: 2710, Minibatch Loss= 0.6737, Training Accuracy= 0.575\n",
      "Epoch: 2720, Minibatch Loss= 0.6693, Training Accuracy= 0.582\n",
      "Epoch: 2730, Minibatch Loss= 0.6687, Training Accuracy= 0.583\n",
      "Epoch: 2740, Minibatch Loss= 0.6614, Training Accuracy= 0.593\n",
      "Epoch: 2750, Minibatch Loss= 0.6596, Training Accuracy= 0.598\n",
      "Epoch: 2760, Minibatch Loss= 0.6543, Training Accuracy= 0.610\n",
      "Epoch: 2770, Minibatch Loss= 0.6413, Training Accuracy= 0.624\n",
      "Epoch: 2780, Minibatch Loss= 0.6512, Training Accuracy= 0.611\n",
      "Epoch: 2790, Minibatch Loss= 0.6656, Training Accuracy= 0.597\n",
      "Epoch: 2800, Minibatch Loss= 0.6478, Training Accuracy= 0.611\n",
      "Epoch: 2810, Minibatch Loss= 0.6765, Training Accuracy= 0.585\n",
      "Epoch: 2820, Minibatch Loss= 0.6278, Training Accuracy= 0.639\n",
      "Epoch: 2830, Minibatch Loss= 0.6304, Training Accuracy= 0.636\n",
      "Epoch: 2840, Minibatch Loss= 0.6198, Training Accuracy= 0.646\n",
      "Epoch: 2850, Minibatch Loss= 0.6313, Training Accuracy= 0.638\n",
      "Epoch: 2860, Minibatch Loss= 0.6198, Training Accuracy= 0.649\n",
      "Epoch: 2870, Minibatch Loss= 0.6232, Training Accuracy= 0.644\n",
      "Epoch: 2880, Minibatch Loss= 0.6202, Training Accuracy= 0.648\n",
      "Epoch: 2890, Minibatch Loss= 0.6605, Training Accuracy= 0.602\n",
      "Epoch: 2900, Minibatch Loss= 0.6246, Training Accuracy= 0.641\n",
      "Epoch: 2910, Minibatch Loss= 0.6357, Training Accuracy= 0.630\n",
      "Epoch: 2920, Minibatch Loss= 0.6251, Training Accuracy= 0.641\n",
      "Epoch: 2930, Minibatch Loss= 0.6952, Training Accuracy= 0.581\n",
      "Epoch: 2940, Minibatch Loss= 0.6471, Training Accuracy= 0.618\n",
      "Epoch: 2950, Minibatch Loss= 0.6185, Training Accuracy= 0.648\n",
      "Epoch: 2960, Minibatch Loss= 0.6023, Training Accuracy= 0.666\n",
      "Epoch: 2970, Minibatch Loss= 0.6965, Training Accuracy= 0.525\n",
      "Epoch: 2980, Minibatch Loss= 0.6879, Training Accuracy= 0.538\n",
      "Epoch: 2990, Minibatch Loss= 0.6843, Training Accuracy= 0.545\n",
      "Epoch: 3000, Minibatch Loss= 0.6815, Training Accuracy= 0.548\n",
      "Epoch: 3010, Minibatch Loss= 0.6789, Training Accuracy= 0.556\n",
      "Epoch: 3020, Minibatch Loss= 0.6762, Training Accuracy= 0.566\n",
      "Epoch: 3030, Minibatch Loss= 0.6737, Training Accuracy= 0.569\n",
      "Epoch: 3040, Minibatch Loss= 0.6708, Training Accuracy= 0.576\n",
      "Epoch: 3050, Minibatch Loss= 0.6672, Training Accuracy= 0.584\n",
      "Epoch: 3060, Minibatch Loss= 0.6640, Training Accuracy= 0.589\n",
      "Epoch: 3070, Minibatch Loss= 0.6657, Training Accuracy= 0.584\n",
      "Epoch: 3080, Minibatch Loss= 0.6940, Training Accuracy= 0.518\n",
      "Epoch: 3090, Minibatch Loss= 0.6909, Training Accuracy= 0.530\n",
      "Epoch: 3100, Minibatch Loss= 0.6940, Training Accuracy= 0.511\n",
      "Epoch: 3110, Minibatch Loss= 0.6913, Training Accuracy= 0.525\n",
      "Epoch: 3120, Minibatch Loss= 0.6914, Training Accuracy= 0.523\n",
      "Epoch: 3130, Minibatch Loss= 0.6903, Training Accuracy= 0.530\n",
      "Epoch: 3140, Minibatch Loss= 0.6895, Training Accuracy= 0.533\n",
      "Epoch: 3150, Minibatch Loss= 0.6887, Training Accuracy= 0.537\n",
      "Epoch: 3160, Minibatch Loss= 0.6887, Training Accuracy= 0.538\n",
      "Epoch: 3170, Minibatch Loss= 0.6879, Training Accuracy= 0.537\n",
      "Epoch: 3180, Minibatch Loss= 0.6882, Training Accuracy= 0.539\n",
      "Epoch: 3190, Minibatch Loss= 0.6857, Training Accuracy= 0.546\n",
      "Epoch: 3200, Minibatch Loss= 0.6858, Training Accuracy= 0.546\n",
      "Epoch: 3210, Minibatch Loss= 0.6847, Training Accuracy= 0.549\n",
      "Epoch: 3220, Minibatch Loss= 0.6823, Training Accuracy= 0.554\n",
      "Epoch: 3230, Minibatch Loss= 0.6837, Training Accuracy= 0.553\n",
      "Epoch: 3240, Minibatch Loss= 0.6804, Training Accuracy= 0.556\n",
      "Epoch: 3250, Minibatch Loss= 0.6784, Training Accuracy= 0.561\n",
      "Epoch: 3260, Minibatch Loss= 0.6788, Training Accuracy= 0.562\n",
      "Epoch: 3270, Minibatch Loss= 0.6789, Training Accuracy= 0.565\n",
      "Epoch: 3280, Minibatch Loss= 0.6750, Training Accuracy= 0.567\n",
      "Epoch: 3290, Minibatch Loss= 0.6768, Training Accuracy= 0.569\n",
      "Epoch: 3300, Minibatch Loss= 0.6718, Training Accuracy= 0.573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3310, Minibatch Loss= 0.6703, Training Accuracy= 0.575\n",
      "Epoch: 3320, Minibatch Loss= 0.6703, Training Accuracy= 0.581\n",
      "Epoch: 3330, Minibatch Loss= 0.6650, Training Accuracy= 0.585\n",
      "Epoch: 3340, Minibatch Loss= 0.6702, Training Accuracy= 0.576\n",
      "Epoch: 3350, Minibatch Loss= 0.6655, Training Accuracy= 0.586\n",
      "Epoch: 3360, Minibatch Loss= 0.6861, Training Accuracy= 0.555\n",
      "Epoch: 3370, Minibatch Loss= 0.6605, Training Accuracy= 0.598\n",
      "Epoch: 3380, Minibatch Loss= 0.6528, Training Accuracy= 0.611\n",
      "Epoch: 3390, Minibatch Loss= 0.6687, Training Accuracy= 0.587\n",
      "Epoch: 3400, Minibatch Loss= 0.6514, Training Accuracy= 0.617\n",
      "Epoch: 3410, Minibatch Loss= 0.6552, Training Accuracy= 0.606\n",
      "Epoch: 3420, Minibatch Loss= 0.6471, Training Accuracy= 0.617\n",
      "Epoch: 3430, Minibatch Loss= 0.6483, Training Accuracy= 0.617\n",
      "Epoch: 3440, Minibatch Loss= 0.6469, Training Accuracy= 0.618\n",
      "Epoch: 3450, Minibatch Loss= 0.6563, Training Accuracy= 0.603\n",
      "Epoch: 3460, Minibatch Loss= 0.6558, Training Accuracy= 0.609\n",
      "Epoch: 3470, Minibatch Loss= 0.6623, Training Accuracy= 0.596\n",
      "Epoch: 3480, Minibatch Loss= 0.6521, Training Accuracy= 0.611\n",
      "Epoch: 3490, Minibatch Loss= 0.6465, Training Accuracy= 0.618\n",
      "Epoch: 3500, Minibatch Loss= 0.6486, Training Accuracy= 0.616\n",
      "Epoch: 3510, Minibatch Loss= 0.6450, Training Accuracy= 0.620\n",
      "Epoch: 3520, Minibatch Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 3530, Minibatch Loss= 0.6911, Training Accuracy= 0.518\n",
      "Epoch: 3540, Minibatch Loss= 0.6893, Training Accuracy= 0.522\n",
      "Epoch: 3550, Minibatch Loss= 0.6881, Training Accuracy= 0.527\n",
      "Epoch: 3560, Minibatch Loss= 0.6870, Training Accuracy= 0.532\n",
      "Epoch: 3570, Minibatch Loss= 0.6894, Training Accuracy= 0.527\n",
      "Epoch: 3580, Minibatch Loss= 0.6867, Training Accuracy= 0.535\n",
      "Epoch: 3590, Minibatch Loss= 0.6853, Training Accuracy= 0.542\n",
      "Epoch: 3600, Minibatch Loss= 0.6839, Training Accuracy= 0.544\n",
      "Epoch: 3610, Minibatch Loss= 0.6845, Training Accuracy= 0.544\n",
      "Epoch: 3620, Minibatch Loss= 0.7138, Training Accuracy= 0.509\n",
      "Epoch: 3630, Minibatch Loss= 0.6931, Training Accuracy= 0.520\n",
      "Epoch: 3640, Minibatch Loss= 0.6905, Training Accuracy= 0.521\n",
      "Epoch: 3650, Minibatch Loss= 0.6885, Training Accuracy= 0.526\n",
      "Epoch: 3660, Minibatch Loss= 0.6828, Training Accuracy= 0.543\n",
      "Epoch: 3670, Minibatch Loss= 0.6862, Training Accuracy= 0.537\n",
      "Epoch: 3680, Minibatch Loss= 0.6851, Training Accuracy= 0.536\n",
      "Epoch: 3690, Minibatch Loss= 0.6842, Training Accuracy= 0.536\n",
      "Epoch: 3700, Minibatch Loss= 0.6887, Training Accuracy= 0.530\n",
      "Epoch: 3710, Minibatch Loss= 0.6838, Training Accuracy= 0.538\n",
      "Epoch: 3720, Minibatch Loss= 0.6837, Training Accuracy= 0.546\n",
      "Epoch: 3730, Minibatch Loss= 0.6817, Training Accuracy= 0.543\n",
      "Epoch: 3740, Minibatch Loss= 0.6796, Training Accuracy= 0.550\n",
      "Epoch: 3750, Minibatch Loss= 0.6770, Training Accuracy= 0.561\n",
      "Epoch: 3760, Minibatch Loss= 0.6778, Training Accuracy= 0.558\n",
      "Epoch: 3770, Minibatch Loss= 0.6749, Training Accuracy= 0.562\n",
      "Epoch: 3780, Minibatch Loss= 0.6723, Training Accuracy= 0.565\n",
      "Epoch: 3790, Minibatch Loss= 0.6690, Training Accuracy= 0.572\n",
      "Epoch: 3800, Minibatch Loss= 0.6748, Training Accuracy= 0.562\n",
      "Epoch: 3810, Minibatch Loss= 0.6695, Training Accuracy= 0.567\n",
      "Epoch: 3820, Minibatch Loss= 0.6722, Training Accuracy= 0.571\n",
      "Epoch: 3830, Minibatch Loss= 0.6651, Training Accuracy= 0.581\n",
      "Epoch: 3840, Minibatch Loss= 0.6664, Training Accuracy= 0.574\n",
      "Epoch: 3850, Minibatch Loss= 0.6682, Training Accuracy= 0.578\n",
      "Epoch: 3860, Minibatch Loss= 0.6798, Training Accuracy= 0.555\n",
      "Epoch: 3870, Minibatch Loss= 0.6644, Training Accuracy= 0.578\n",
      "Epoch: 3880, Minibatch Loss= 0.6752, Training Accuracy= 0.564\n",
      "Epoch: 3890, Minibatch Loss= 0.6635, Training Accuracy= 0.582\n",
      "Epoch: 3900, Minibatch Loss= 0.6638, Training Accuracy= 0.578\n",
      "Epoch: 3910, Minibatch Loss= 0.6659, Training Accuracy= 0.578\n",
      "Epoch: 3920, Minibatch Loss= 0.6694, Training Accuracy= 0.572\n",
      "Epoch: 3930, Minibatch Loss= 0.6587, Training Accuracy= 0.584\n",
      "Epoch: 3940, Minibatch Loss= 0.6605, Training Accuracy= 0.583\n",
      "Epoch: 3950, Minibatch Loss= 0.6705, Training Accuracy= 0.571\n",
      "Epoch: 3960, Minibatch Loss= 0.6546, Training Accuracy= 0.590\n",
      "Epoch: 3970, Minibatch Loss= 0.6751, Training Accuracy= 0.574\n",
      "Epoch: 3980, Minibatch Loss= 0.6655, Training Accuracy= 0.582\n",
      "Epoch: 3990, Minibatch Loss= 0.6665, Training Accuracy= 0.582\n",
      "Epoch: 4000, Minibatch Loss= 0.6712, Training Accuracy= 0.568\n",
      "Epoch: 4010, Minibatch Loss= 0.6635, Training Accuracy= 0.578\n",
      "Epoch: 4020, Minibatch Loss= 0.6635, Training Accuracy= 0.583\n",
      "Epoch: 4030, Minibatch Loss= 0.6577, Training Accuracy= 0.588\n",
      "Epoch: 4040, Minibatch Loss= 0.6505, Training Accuracy= 0.599\n",
      "Epoch: 4050, Minibatch Loss= 0.6629, Training Accuracy= 0.584\n",
      "Epoch: 4060, Minibatch Loss= 0.6712, Training Accuracy= 0.573\n",
      "Epoch: 4070, Minibatch Loss= 0.6523, Training Accuracy= 0.603\n",
      "Epoch: 4080, Minibatch Loss= 0.6614, Training Accuracy= 0.591\n",
      "Epoch: 4090, Minibatch Loss= 0.6717, Training Accuracy= 0.572\n",
      "Epoch: 4100, Minibatch Loss= 0.6539, Training Accuracy= 0.598\n",
      "Epoch: 4110, Minibatch Loss= 0.6547, Training Accuracy= 0.594\n",
      "Epoch: 4120, Minibatch Loss= 0.6697, Training Accuracy= 0.576\n",
      "Epoch: 4130, Minibatch Loss= 0.6453, Training Accuracy= 0.607\n",
      "Epoch: 4140, Minibatch Loss= 0.6391, Training Accuracy= 0.613\n",
      "Epoch: 4150, Minibatch Loss= 0.6412, Training Accuracy= 0.615\n",
      "Epoch: 4160, Minibatch Loss= 0.6498, Training Accuracy= 0.601\n",
      "Epoch: 4170, Minibatch Loss= 0.6499, Training Accuracy= 0.606\n",
      "Epoch: 4180, Minibatch Loss= 0.6361, Training Accuracy= 0.618\n",
      "Epoch: 4190, Minibatch Loss= 0.6843, Training Accuracy= 0.555\n",
      "Epoch: 4200, Minibatch Loss= 0.6619, Training Accuracy= 0.581\n",
      "Epoch: 4210, Minibatch Loss= 0.6491, Training Accuracy= 0.604\n",
      "Epoch: 4220, Minibatch Loss= 0.6348, Training Accuracy= 0.618\n",
      "Epoch: 4230, Minibatch Loss= 0.6356, Training Accuracy= 0.614\n",
      "Epoch: 4240, Minibatch Loss= 0.6465, Training Accuracy= 0.605\n",
      "Epoch: 4250, Minibatch Loss= 0.6467, Training Accuracy= 0.607\n",
      "Epoch: 4260, Minibatch Loss= 0.6375, Training Accuracy= 0.617\n",
      "Epoch: 4270, Minibatch Loss= 0.6642, Training Accuracy= 0.582\n",
      "Epoch: 4280, Minibatch Loss= 0.6460, Training Accuracy= 0.614\n",
      "Epoch: 4290, Minibatch Loss= 0.6346, Training Accuracy= 0.616\n",
      "Epoch: 4300, Minibatch Loss= 0.6400, Training Accuracy= 0.614\n",
      "Epoch: 4310, Minibatch Loss= 0.6406, Training Accuracy= 0.605\n",
      "Epoch: 4320, Minibatch Loss= 0.6329, Training Accuracy= 0.625\n",
      "Epoch: 4330, Minibatch Loss= 0.6282, Training Accuracy= 0.629\n",
      "Epoch: 4340, Minibatch Loss= 0.6344, Training Accuracy= 0.624\n",
      "Epoch: 4350, Minibatch Loss= 0.6471, Training Accuracy= 0.608\n",
      "Epoch: 4360, Minibatch Loss= 0.6320, Training Accuracy= 0.623\n",
      "Epoch: 4370, Minibatch Loss= 0.6252, Training Accuracy= 0.630\n",
      "Epoch: 4380, Minibatch Loss= 0.6426, Training Accuracy= 0.615\n",
      "Epoch: 4390, Minibatch Loss= 0.6214, Training Accuracy= 0.636\n",
      "Epoch: 4400, Minibatch Loss= 0.6330, Training Accuracy= 0.628\n",
      "Epoch: 4410, Minibatch Loss= 0.6567, Training Accuracy= 0.598\n",
      "Epoch: 4420, Minibatch Loss= 0.6389, Training Accuracy= 0.611\n",
      "Epoch: 4430, Minibatch Loss= 0.6230, Training Accuracy= 0.631\n",
      "Epoch: 4440, Minibatch Loss= 0.6236, Training Accuracy= 0.634\n",
      "Epoch: 4450, Minibatch Loss= 0.6193, Training Accuracy= 0.632\n",
      "Epoch: 4460, Minibatch Loss= 0.6392, Training Accuracy= 0.614\n",
      "Epoch: 4470, Minibatch Loss= 0.6530, Training Accuracy= 0.608\n",
      "Epoch: 4480, Minibatch Loss= 0.6300, Training Accuracy= 0.627\n",
      "Epoch: 4490, Minibatch Loss= 0.6246, Training Accuracy= 0.633\n",
      "Epoch: 4500, Minibatch Loss= 0.6673, Training Accuracy= 0.587\n",
      "Epoch: 4510, Minibatch Loss= 0.6917, Training Accuracy= 0.533\n",
      "Epoch: 4520, Minibatch Loss= 0.6687, Training Accuracy= 0.582\n",
      "Epoch: 4530, Minibatch Loss= 0.6592, Training Accuracy= 0.592\n",
      "Epoch: 4540, Minibatch Loss= 0.6298, Training Accuracy= 0.632\n",
      "Epoch: 4550, Minibatch Loss= 0.6318, Training Accuracy= 0.625\n",
      "Epoch: 4560, Minibatch Loss= 0.6436, Training Accuracy= 0.613\n",
      "Epoch: 4570, Minibatch Loss= 0.6257, Training Accuracy= 0.632\n",
      "Epoch: 4580, Minibatch Loss= 0.6272, Training Accuracy= 0.636\n",
      "Epoch: 4590, Minibatch Loss= 0.6429, Training Accuracy= 0.615\n",
      "Epoch: 4600, Minibatch Loss= 0.6330, Training Accuracy= 0.620\n",
      "Epoch: 4610, Minibatch Loss= 0.6159, Training Accuracy= 0.643\n",
      "Epoch: 4620, Minibatch Loss= 0.6165, Training Accuracy= 0.641\n",
      "Epoch: 4630, Minibatch Loss= 0.6196, Training Accuracy= 0.640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4640, Minibatch Loss= 0.7063, Training Accuracy= 0.554\n",
      "Epoch: 4650, Minibatch Loss= 0.6025, Training Accuracy= 0.652\n",
      "Epoch: 4660, Minibatch Loss= 0.6679, Training Accuracy= 0.580\n",
      "Epoch: 4670, Minibatch Loss= 0.6312, Training Accuracy= 0.628\n",
      "Epoch: 4680, Minibatch Loss= 0.6107, Training Accuracy= 0.647\n",
      "Epoch: 4690, Minibatch Loss= 0.6119, Training Accuracy= 0.643\n",
      "Epoch: 4700, Minibatch Loss= 0.5986, Training Accuracy= 0.658\n",
      "Epoch: 4710, Minibatch Loss= 0.6435, Training Accuracy= 0.612\n",
      "Epoch: 4720, Minibatch Loss= 0.6094, Training Accuracy= 0.649\n",
      "Epoch: 4730, Minibatch Loss= 0.6127, Training Accuracy= 0.649\n",
      "Epoch: 4740, Minibatch Loss= 0.6099, Training Accuracy= 0.647\n",
      "Epoch: 4750, Minibatch Loss= 0.6952, Training Accuracy= 0.538\n",
      "Epoch: 4760, Minibatch Loss= 0.6818, Training Accuracy= 0.588\n",
      "Epoch: 4770, Minibatch Loss= 0.6251, Training Accuracy= 0.632\n",
      "Epoch: 4780, Minibatch Loss= 0.6084, Training Accuracy= 0.653\n",
      "Epoch: 4790, Minibatch Loss= 0.6359, Training Accuracy= 0.620\n",
      "Epoch: 4800, Minibatch Loss= 0.6132, Training Accuracy= 0.646\n",
      "Epoch: 4810, Minibatch Loss= 0.6162, Training Accuracy= 0.643\n",
      "Epoch: 4820, Minibatch Loss= 0.5987, Training Accuracy= 0.658\n",
      "Epoch: 4830, Minibatch Loss= 0.6167, Training Accuracy= 0.640\n",
      "Epoch: 4840, Minibatch Loss= 0.6028, Training Accuracy= 0.656\n",
      "Epoch: 4850, Minibatch Loss= 0.6107, Training Accuracy= 0.645\n",
      "Epoch: 4860, Minibatch Loss= 0.6012, Training Accuracy= 0.653\n",
      "Epoch: 4870, Minibatch Loss= 0.6194, Training Accuracy= 0.638\n",
      "Epoch: 4880, Minibatch Loss= 0.5956, Training Accuracy= 0.661\n",
      "Epoch: 4890, Minibatch Loss= 0.6288, Training Accuracy= 0.635\n",
      "Epoch: 4900, Minibatch Loss= 0.5922, Training Accuracy= 0.664\n",
      "Epoch: 4910, Minibatch Loss= 0.6932, Training Accuracy= 0.531\n",
      "Epoch: 4920, Minibatch Loss= 0.6836, Training Accuracy= 0.554\n",
      "Epoch: 4930, Minibatch Loss= 0.6789, Training Accuracy= 0.564\n",
      "Epoch: 4940, Minibatch Loss= 0.6737, Training Accuracy= 0.571\n",
      "Epoch: 4950, Minibatch Loss= 0.6715, Training Accuracy= 0.572\n",
      "Epoch: 4960, Minibatch Loss= 0.6683, Training Accuracy= 0.580\n",
      "Epoch: 4970, Minibatch Loss= 0.6668, Training Accuracy= 0.579\n",
      "Epoch: 4980, Minibatch Loss= 0.6641, Training Accuracy= 0.587\n",
      "Epoch: 4990, Minibatch Loss= 0.6632, Training Accuracy= 0.588\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.5043\n",
      "Replication: 3: \n",
      "Epoch: 0, Minibatch Loss= 0.6986, Training Accuracy= 0.507\n",
      "Epoch: 10, Minibatch Loss= 0.6983, Training Accuracy= 0.507\n",
      "Epoch: 20, Minibatch Loss= 0.6979, Training Accuracy= 0.507\n",
      "Epoch: 30, Minibatch Loss= 0.6975, Training Accuracy= 0.507\n",
      "Epoch: 40, Minibatch Loss= 0.6972, Training Accuracy= 0.507\n",
      "Epoch: 50, Minibatch Loss= 0.6969, Training Accuracy= 0.507\n",
      "Epoch: 60, Minibatch Loss= 0.6967, Training Accuracy= 0.507\n",
      "Epoch: 70, Minibatch Loss= 0.6965, Training Accuracy= 0.507\n",
      "Epoch: 80, Minibatch Loss= 0.6963, Training Accuracy= 0.507\n",
      "Epoch: 90, Minibatch Loss= 0.6961, Training Accuracy= 0.507\n",
      "Epoch: 100, Minibatch Loss= 0.6960, Training Accuracy= 0.507\n",
      "Epoch: 110, Minibatch Loss= 0.6959, Training Accuracy= 0.507\n",
      "Epoch: 120, Minibatch Loss= 0.6957, Training Accuracy= 0.507\n",
      "Epoch: 130, Minibatch Loss= 0.6956, Training Accuracy= 0.507\n",
      "Epoch: 140, Minibatch Loss= 0.6955, Training Accuracy= 0.507\n",
      "Epoch: 150, Minibatch Loss= 0.6954, Training Accuracy= 0.507\n",
      "Epoch: 160, Minibatch Loss= 0.6953, Training Accuracy= 0.507\n",
      "Epoch: 170, Minibatch Loss= 0.6952, Training Accuracy= 0.507\n",
      "Epoch: 180, Minibatch Loss= 0.6951, Training Accuracy= 0.507\n",
      "Epoch: 190, Minibatch Loss= 0.6951, Training Accuracy= 0.507\n",
      "Epoch: 200, Minibatch Loss= 0.6950, Training Accuracy= 0.507\n",
      "Epoch: 210, Minibatch Loss= 0.6949, Training Accuracy= 0.507\n",
      "Epoch: 220, Minibatch Loss= 0.6949, Training Accuracy= 0.507\n",
      "Epoch: 230, Minibatch Loss= 0.6948, Training Accuracy= 0.507\n",
      "Epoch: 240, Minibatch Loss= 0.6947, Training Accuracy= 0.508\n",
      "Epoch: 250, Minibatch Loss= 0.6947, Training Accuracy= 0.508\n",
      "Epoch: 260, Minibatch Loss= 0.6946, Training Accuracy= 0.508\n",
      "Epoch: 270, Minibatch Loss= 0.6946, Training Accuracy= 0.508\n",
      "Epoch: 280, Minibatch Loss= 0.6946, Training Accuracy= 0.508\n",
      "Epoch: 290, Minibatch Loss= 0.6945, Training Accuracy= 0.508\n",
      "Epoch: 300, Minibatch Loss= 0.6945, Training Accuracy= 0.508\n",
      "Epoch: 310, Minibatch Loss= 0.6944, Training Accuracy= 0.508\n",
      "Epoch: 320, Minibatch Loss= 0.6944, Training Accuracy= 0.509\n",
      "Epoch: 330, Minibatch Loss= 0.6944, Training Accuracy= 0.509\n",
      "Epoch: 340, Minibatch Loss= 0.6943, Training Accuracy= 0.508\n",
      "Epoch: 350, Minibatch Loss= 0.6943, Training Accuracy= 0.509\n",
      "Epoch: 360, Minibatch Loss= 0.6943, Training Accuracy= 0.510\n",
      "Epoch: 370, Minibatch Loss= 0.6943, Training Accuracy= 0.510\n",
      "Epoch: 380, Minibatch Loss= 0.6943, Training Accuracy= 0.510\n",
      "Epoch: 390, Minibatch Loss= 0.6943, Training Accuracy= 0.509\n",
      "Epoch: 400, Minibatch Loss= 0.6942, Training Accuracy= 0.509\n",
      "Epoch: 410, Minibatch Loss= 0.6940, Training Accuracy= 0.510\n",
      "Epoch: 420, Minibatch Loss= 0.6937, Training Accuracy= 0.510\n",
      "Epoch: 430, Minibatch Loss= 0.6936, Training Accuracy= 0.509\n",
      "Epoch: 440, Minibatch Loss= 0.6935, Training Accuracy= 0.510\n",
      "Epoch: 450, Minibatch Loss= 0.6936, Training Accuracy= 0.510\n",
      "Epoch: 460, Minibatch Loss= 0.6937, Training Accuracy= 0.509\n",
      "Epoch: 470, Minibatch Loss= 0.6936, Training Accuracy= 0.510\n",
      "Epoch: 480, Minibatch Loss= 0.6936, Training Accuracy= 0.511\n",
      "Epoch: 490, Minibatch Loss= 0.6936, Training Accuracy= 0.512\n",
      "Epoch: 500, Minibatch Loss= 0.6936, Training Accuracy= 0.513\n",
      "Epoch: 510, Minibatch Loss= 0.6938, Training Accuracy= 0.513\n",
      "Epoch: 520, Minibatch Loss= 0.6940, Training Accuracy= 0.514\n",
      "Epoch: 530, Minibatch Loss= 0.6941, Training Accuracy= 0.514\n",
      "Epoch: 540, Minibatch Loss= 0.6951, Training Accuracy= 0.513\n",
      "Epoch: 550, Minibatch Loss= 0.6951, Training Accuracy= 0.514\n",
      "Epoch: 560, Minibatch Loss= 0.6938, Training Accuracy= 0.521\n",
      "Epoch: 570, Minibatch Loss= 0.6940, Training Accuracy= 0.516\n",
      "Epoch: 580, Minibatch Loss= 0.6936, Training Accuracy= 0.522\n",
      "Epoch: 590, Minibatch Loss= 0.6949, Training Accuracy= 0.524\n",
      "Epoch: 600, Minibatch Loss= 0.6933, Training Accuracy= 0.520\n",
      "Epoch: 610, Minibatch Loss= 0.6943, Training Accuracy= 0.518\n",
      "Epoch: 620, Minibatch Loss= 0.6974, Training Accuracy= 0.507\n",
      "Epoch: 630, Minibatch Loss= 0.6961, Training Accuracy= 0.513\n",
      "Epoch: 640, Minibatch Loss= 0.6992, Training Accuracy= 0.516\n",
      "Epoch: 650, Minibatch Loss= 0.6940, Training Accuracy= 0.526\n",
      "Epoch: 660, Minibatch Loss= 0.6950, Training Accuracy= 0.521\n",
      "Epoch: 670, Minibatch Loss= 0.6951, Training Accuracy= 0.507\n",
      "Epoch: 680, Minibatch Loss= 0.6944, Training Accuracy= 0.508\n",
      "Epoch: 690, Minibatch Loss= 0.6936, Training Accuracy= 0.512\n",
      "Epoch: 700, Minibatch Loss= 0.6931, Training Accuracy= 0.516\n",
      "Epoch: 710, Minibatch Loss= 0.6923, Training Accuracy= 0.520\n",
      "Epoch: 720, Minibatch Loss= 0.6921, Training Accuracy= 0.520\n",
      "Epoch: 730, Minibatch Loss= 0.6921, Training Accuracy= 0.522\n",
      "Epoch: 740, Minibatch Loss= 0.6916, Training Accuracy= 0.525\n",
      "Epoch: 750, Minibatch Loss= 0.6912, Training Accuracy= 0.527\n",
      "Epoch: 760, Minibatch Loss= 0.6906, Training Accuracy= 0.526\n",
      "Epoch: 770, Minibatch Loss= 0.6946, Training Accuracy= 0.521\n",
      "Epoch: 780, Minibatch Loss= 0.6925, Training Accuracy= 0.526\n",
      "Epoch: 790, Minibatch Loss= 0.6885, Training Accuracy= 0.535\n",
      "Epoch: 800, Minibatch Loss= 0.6969, Training Accuracy= 0.511\n",
      "Epoch: 810, Minibatch Loss= 0.6949, Training Accuracy= 0.516\n",
      "Epoch: 820, Minibatch Loss= 0.6936, Training Accuracy= 0.524\n",
      "Epoch: 830, Minibatch Loss= 0.6925, Training Accuracy= 0.526\n",
      "Epoch: 840, Minibatch Loss= 0.6951, Training Accuracy= 0.521\n",
      "Epoch: 850, Minibatch Loss= 0.6887, Training Accuracy= 0.540\n",
      "Epoch: 860, Minibatch Loss= 0.6954, Training Accuracy= 0.528\n",
      "Epoch: 870, Minibatch Loss= 0.6956, Training Accuracy= 0.527\n",
      "Epoch: 880, Minibatch Loss= 0.6872, Training Accuracy= 0.544\n",
      "Epoch: 890, Minibatch Loss= 0.6916, Training Accuracy= 0.541\n",
      "Epoch: 900, Minibatch Loss= 0.6911, Training Accuracy= 0.545\n",
      "Epoch: 910, Minibatch Loss= 0.6816, Training Accuracy= 0.565\n",
      "Epoch: 920, Minibatch Loss= 0.6994, Training Accuracy= 0.507\n",
      "Epoch: 930, Minibatch Loss= 0.6970, Training Accuracy= 0.510\n",
      "Epoch: 940, Minibatch Loss= 0.6926, Training Accuracy= 0.523\n",
      "Epoch: 950, Minibatch Loss= 0.6937, Training Accuracy= 0.524\n",
      "Epoch: 960, Minibatch Loss= 0.6923, Training Accuracy= 0.530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 970, Minibatch Loss= 0.6900, Training Accuracy= 0.538\n",
      "Epoch: 980, Minibatch Loss= 0.6939, Training Accuracy= 0.533\n",
      "Epoch: 990, Minibatch Loss= 0.6833, Training Accuracy= 0.554\n",
      "Epoch: 1000, Minibatch Loss= 0.6903, Training Accuracy= 0.541\n",
      "Epoch: 1010, Minibatch Loss= 0.6819, Training Accuracy= 0.562\n",
      "Epoch: 1020, Minibatch Loss= 0.6974, Training Accuracy= 0.507\n",
      "Epoch: 1030, Minibatch Loss= 0.6963, Training Accuracy= 0.510\n",
      "Epoch: 1040, Minibatch Loss= 0.6964, Training Accuracy= 0.509\n",
      "Epoch: 1050, Minibatch Loss= 0.6960, Training Accuracy= 0.510\n",
      "Epoch: 1060, Minibatch Loss= 0.6948, Training Accuracy= 0.516\n",
      "Epoch: 1070, Minibatch Loss= 0.6941, Training Accuracy= 0.517\n",
      "Epoch: 1080, Minibatch Loss= 0.6941, Training Accuracy= 0.519\n",
      "Epoch: 1090, Minibatch Loss= 0.6942, Training Accuracy= 0.521\n",
      "Epoch: 1100, Minibatch Loss= 0.6933, Training Accuracy= 0.525\n",
      "Epoch: 1110, Minibatch Loss= 0.6923, Training Accuracy= 0.523\n",
      "Epoch: 1120, Minibatch Loss= 0.6930, Training Accuracy= 0.522\n",
      "Epoch: 1130, Minibatch Loss= 0.6920, Training Accuracy= 0.527\n",
      "Epoch: 1140, Minibatch Loss= 0.6925, Training Accuracy= 0.528\n",
      "Epoch: 1150, Minibatch Loss= 0.6930, Training Accuracy= 0.530\n",
      "Epoch: 1160, Minibatch Loss= 0.6975, Training Accuracy= 0.509\n",
      "Epoch: 1170, Minibatch Loss= 0.6971, Training Accuracy= 0.510\n",
      "Epoch: 1180, Minibatch Loss= 0.6966, Training Accuracy= 0.510\n",
      "Epoch: 1190, Minibatch Loss= 0.6959, Training Accuracy= 0.512\n",
      "Epoch: 1200, Minibatch Loss= 0.6956, Training Accuracy= 0.512\n",
      "Epoch: 1210, Minibatch Loss= 0.6953, Training Accuracy= 0.516\n",
      "Epoch: 1220, Minibatch Loss= 0.6941, Training Accuracy= 0.518\n",
      "Epoch: 1230, Minibatch Loss= 0.6943, Training Accuracy= 0.516\n",
      "Epoch: 1240, Minibatch Loss= 0.6955, Training Accuracy= 0.514\n",
      "Epoch: 1250, Minibatch Loss= 0.6938, Training Accuracy= 0.521\n",
      "Epoch: 1260, Minibatch Loss= 0.6941, Training Accuracy= 0.520\n",
      "Epoch: 1270, Minibatch Loss= 0.6944, Training Accuracy= 0.523\n",
      "Epoch: 1280, Minibatch Loss= 0.6939, Training Accuracy= 0.521\n",
      "Epoch: 1290, Minibatch Loss= 0.6931, Training Accuracy= 0.525\n",
      "Epoch: 1300, Minibatch Loss= 0.6957, Training Accuracy= 0.520\n",
      "Epoch: 1310, Minibatch Loss= 0.6921, Training Accuracy= 0.528\n",
      "Epoch: 1320, Minibatch Loss= 0.6918, Training Accuracy= 0.525\n",
      "Epoch: 1330, Minibatch Loss= 0.6914, Training Accuracy= 0.530\n",
      "Epoch: 1340, Minibatch Loss= 0.6927, Training Accuracy= 0.526\n",
      "Epoch: 1350, Minibatch Loss= 0.6918, Training Accuracy= 0.530\n",
      "Epoch: 1360, Minibatch Loss= 0.6900, Training Accuracy= 0.535\n",
      "Epoch: 1370, Minibatch Loss= 0.6965, Training Accuracy= 0.529\n",
      "Epoch: 1380, Minibatch Loss= 0.6947, Training Accuracy= 0.526\n",
      "Epoch: 1390, Minibatch Loss= 0.6906, Training Accuracy= 0.529\n",
      "Epoch: 1400, Minibatch Loss= 0.6883, Training Accuracy= 0.536\n",
      "Epoch: 1410, Minibatch Loss= 0.6904, Training Accuracy= 0.533\n",
      "Epoch: 1420, Minibatch Loss= 0.6964, Training Accuracy= 0.529\n",
      "Epoch: 1430, Minibatch Loss= 0.6994, Training Accuracy= 0.524\n",
      "Epoch: 1440, Minibatch Loss= 0.6923, Training Accuracy= 0.530\n",
      "Epoch: 1450, Minibatch Loss= 0.6897, Training Accuracy= 0.537\n",
      "Epoch: 1460, Minibatch Loss= 0.7012, Training Accuracy= 0.524\n",
      "Epoch: 1470, Minibatch Loss= 0.6965, Training Accuracy= 0.531\n",
      "Epoch: 1480, Minibatch Loss= 0.6897, Training Accuracy= 0.540\n",
      "Epoch: 1490, Minibatch Loss= 0.6991, Training Accuracy= 0.530\n",
      "Epoch: 1500, Minibatch Loss= 0.6931, Training Accuracy= 0.530\n",
      "Epoch: 1510, Minibatch Loss= 0.6931, Training Accuracy= 0.534\n",
      "Epoch: 1520, Minibatch Loss= 0.6924, Training Accuracy= 0.538\n",
      "Epoch: 1530, Minibatch Loss= 0.6912, Training Accuracy= 0.540\n",
      "Epoch: 1540, Minibatch Loss= 0.6909, Training Accuracy= 0.541\n",
      "Epoch: 1550, Minibatch Loss= 0.6891, Training Accuracy= 0.542\n",
      "Epoch: 1560, Minibatch Loss= 0.6922, Training Accuracy= 0.542\n",
      "Epoch: 1570, Minibatch Loss= 0.6895, Training Accuracy= 0.549\n",
      "Epoch: 1580, Minibatch Loss= 0.6908, Training Accuracy= 0.545\n",
      "Epoch: 1590, Minibatch Loss= 0.6863, Training Accuracy= 0.559\n",
      "Epoch: 1600, Minibatch Loss= 0.6896, Training Accuracy= 0.548\n",
      "Epoch: 1610, Minibatch Loss= 0.6850, Training Accuracy= 0.556\n",
      "Epoch: 1620, Minibatch Loss= 0.6873, Training Accuracy= 0.555\n",
      "Epoch: 1630, Minibatch Loss= 0.6776, Training Accuracy= 0.571\n",
      "Epoch: 1640, Minibatch Loss= 0.6857, Training Accuracy= 0.563\n",
      "Epoch: 1650, Minibatch Loss= 0.6817, Training Accuracy= 0.568\n",
      "Epoch: 1660, Minibatch Loss= 0.6796, Training Accuracy= 0.572\n",
      "Epoch: 1670, Minibatch Loss= 0.6841, Training Accuracy= 0.561\n",
      "Epoch: 1680, Minibatch Loss= 0.6768, Training Accuracy= 0.572\n",
      "Epoch: 1690, Minibatch Loss= 0.6806, Training Accuracy= 0.567\n",
      "Epoch: 1700, Minibatch Loss= 0.6778, Training Accuracy= 0.572\n",
      "Epoch: 1710, Minibatch Loss= 0.6799, Training Accuracy= 0.573\n",
      "Epoch: 1720, Minibatch Loss= 0.6817, Training Accuracy= 0.570\n",
      "Epoch: 1730, Minibatch Loss= 0.6715, Training Accuracy= 0.584\n",
      "Epoch: 1740, Minibatch Loss= 0.6765, Training Accuracy= 0.572\n",
      "Epoch: 1750, Minibatch Loss= 0.6720, Training Accuracy= 0.583\n",
      "Epoch: 1760, Minibatch Loss= 0.6706, Training Accuracy= 0.584\n",
      "Epoch: 1770, Minibatch Loss= 0.6628, Training Accuracy= 0.595\n",
      "Epoch: 1780, Minibatch Loss= 0.6622, Training Accuracy= 0.596\n",
      "Epoch: 1790, Minibatch Loss= 0.6998, Training Accuracy= 0.508\n",
      "Epoch: 1800, Minibatch Loss= 0.6999, Training Accuracy= 0.507\n",
      "Epoch: 1810, Minibatch Loss= 0.7002, Training Accuracy= 0.507\n",
      "Epoch: 1820, Minibatch Loss= 0.6998, Training Accuracy= 0.507\n",
      "Epoch: 1830, Minibatch Loss= 0.6995, Training Accuracy= 0.507\n",
      "Epoch: 1840, Minibatch Loss= 0.6993, Training Accuracy= 0.507\n",
      "Epoch: 1850, Minibatch Loss= 0.6993, Training Accuracy= 0.507\n",
      "Epoch: 1860, Minibatch Loss= 0.6992, Training Accuracy= 0.509\n",
      "Epoch: 1870, Minibatch Loss= 0.6989, Training Accuracy= 0.510\n",
      "Epoch: 1880, Minibatch Loss= 0.6983, Training Accuracy= 0.512\n",
      "Epoch: 1890, Minibatch Loss= 0.6978, Training Accuracy= 0.514\n",
      "Epoch: 1900, Minibatch Loss= 0.6969, Training Accuracy= 0.516\n",
      "Epoch: 1910, Minibatch Loss= 0.6960, Training Accuracy= 0.517\n",
      "Epoch: 1920, Minibatch Loss= 0.6948, Training Accuracy= 0.522\n",
      "Epoch: 1930, Minibatch Loss= 0.6959, Training Accuracy= 0.516\n",
      "Epoch: 1940, Minibatch Loss= 0.6922, Training Accuracy= 0.526\n",
      "Epoch: 1950, Minibatch Loss= 0.6914, Training Accuracy= 0.529\n",
      "Epoch: 1960, Minibatch Loss= 0.6932, Training Accuracy= 0.525\n",
      "Epoch: 1970, Minibatch Loss= 0.6896, Training Accuracy= 0.534\n",
      "Epoch: 1980, Minibatch Loss= 0.6899, Training Accuracy= 0.534\n",
      "Epoch: 1990, Minibatch Loss= 0.6890, Training Accuracy= 0.539\n",
      "Epoch: 2000, Minibatch Loss= 0.6891, Training Accuracy= 0.537\n",
      "Epoch: 2010, Minibatch Loss= 0.6891, Training Accuracy= 0.540\n",
      "Epoch: 2020, Minibatch Loss= 0.6891, Training Accuracy= 0.543\n",
      "Epoch: 2030, Minibatch Loss= 0.6892, Training Accuracy= 0.539\n",
      "Epoch: 2040, Minibatch Loss= 0.6955, Training Accuracy= 0.532\n",
      "Epoch: 2050, Minibatch Loss= 0.6870, Training Accuracy= 0.546\n",
      "Epoch: 2060, Minibatch Loss= 0.6871, Training Accuracy= 0.553\n",
      "Epoch: 2070, Minibatch Loss= 0.6881, Training Accuracy= 0.539\n",
      "Epoch: 2080, Minibatch Loss= 0.6841, Training Accuracy= 0.551\n",
      "Epoch: 2090, Minibatch Loss= 0.6821, Training Accuracy= 0.559\n",
      "Epoch: 2100, Minibatch Loss= 0.7053, Training Accuracy= 0.518\n",
      "Epoch: 2110, Minibatch Loss= 0.6803, Training Accuracy= 0.563\n",
      "Epoch: 2120, Minibatch Loss= 0.6825, Training Accuracy= 0.558\n",
      "Epoch: 2130, Minibatch Loss= 0.6799, Training Accuracy= 0.566\n",
      "Epoch: 2140, Minibatch Loss= 0.6773, Training Accuracy= 0.572\n",
      "Epoch: 2150, Minibatch Loss= 0.6939, Training Accuracy= 0.534\n",
      "Epoch: 2160, Minibatch Loss= 0.6784, Training Accuracy= 0.564\n",
      "Epoch: 2170, Minibatch Loss= 0.6762, Training Accuracy= 0.572\n",
      "Epoch: 2180, Minibatch Loss= 0.6768, Training Accuracy= 0.570\n",
      "Epoch: 2190, Minibatch Loss= 0.6752, Training Accuracy= 0.576\n",
      "Epoch: 2200, Minibatch Loss= 0.6838, Training Accuracy= 0.557\n",
      "Epoch: 2210, Minibatch Loss= 0.6769, Training Accuracy= 0.569\n",
      "Epoch: 2220, Minibatch Loss= 0.6778, Training Accuracy= 0.567\n",
      "Epoch: 2230, Minibatch Loss= 0.6745, Training Accuracy= 0.575\n",
      "Epoch: 2240, Minibatch Loss= 0.6690, Training Accuracy= 0.582\n",
      "Epoch: 2250, Minibatch Loss= 0.6745, Training Accuracy= 0.575\n",
      "Epoch: 2260, Minibatch Loss= 0.6726, Training Accuracy= 0.577\n",
      "Epoch: 2270, Minibatch Loss= 0.6810, Training Accuracy= 0.570\n",
      "Epoch: 2280, Minibatch Loss= 0.6735, Training Accuracy= 0.586\n",
      "Epoch: 2290, Minibatch Loss= 0.6730, Training Accuracy= 0.589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2300, Minibatch Loss= 0.6439, Training Accuracy= 0.599\n",
      "Epoch: 2310, Minibatch Loss= 0.6429, Training Accuracy= 0.610\n",
      "Epoch: 2320, Minibatch Loss= 0.6104, Training Accuracy= 0.631\n",
      "Epoch: 2330, Minibatch Loss= 0.5924, Training Accuracy= 0.644\n",
      "Epoch: 2340, Minibatch Loss= 0.5808, Training Accuracy= 0.657\n",
      "Epoch: 2350, Minibatch Loss= 0.5696, Training Accuracy= 0.661\n",
      "Epoch: 2360, Minibatch Loss= 0.5392, Training Accuracy= 0.687\n",
      "Epoch: 2370, Minibatch Loss= 0.5668, Training Accuracy= 0.678\n",
      "Epoch: 2380, Minibatch Loss= 0.5054, Training Accuracy= 0.701\n",
      "Epoch: 2390, Minibatch Loss= 0.4533, Training Accuracy= 0.743\n",
      "Epoch: 2400, Minibatch Loss= 0.3333, Training Accuracy= 0.817\n",
      "Epoch: 2410, Minibatch Loss= 0.4679, Training Accuracy= 0.750\n",
      "Epoch: 2420, Minibatch Loss= 0.2691, Training Accuracy= 0.841\n",
      "Epoch: 2430, Minibatch Loss= 0.3972, Training Accuracy= 0.759\n",
      "Epoch: 2440, Minibatch Loss= 0.3950, Training Accuracy= 0.770\n",
      "Epoch: 2450, Minibatch Loss= 0.3354, Training Accuracy= 0.833\n",
      "Epoch: 2460, Minibatch Loss= 0.7909, Training Accuracy= 0.603\n",
      "Epoch: 2470, Minibatch Loss= 0.5501, Training Accuracy= 0.661\n",
      "Epoch: 2480, Minibatch Loss= 0.4458, Training Accuracy= 0.727\n",
      "Epoch: 2490, Minibatch Loss= 0.4170, Training Accuracy= 0.764\n",
      "Epoch: 2500, Minibatch Loss= 0.4318, Training Accuracy= 0.746\n",
      "Epoch: 2510, Minibatch Loss= 0.3478, Training Accuracy= 0.797\n",
      "Epoch: 2520, Minibatch Loss= 0.2991, Training Accuracy= 0.836\n",
      "Epoch: 2530, Minibatch Loss= 0.2762, Training Accuracy= 0.846\n",
      "Epoch: 2540, Minibatch Loss= 0.3280, Training Accuracy= 0.822\n",
      "Epoch: 2550, Minibatch Loss= 0.2785, Training Accuracy= 0.850\n",
      "Epoch: 2560, Minibatch Loss= 0.9017, Training Accuracy= 0.530\n",
      "Epoch: 2570, Minibatch Loss= 0.7033, Training Accuracy= 0.506\n",
      "Epoch: 2580, Minibatch Loss= 0.7023, Training Accuracy= 0.507\n",
      "Epoch: 2590, Minibatch Loss= 0.7021, Training Accuracy= 0.507\n",
      "Epoch: 2600, Minibatch Loss= 0.7022, Training Accuracy= 0.507\n",
      "Epoch: 2610, Minibatch Loss= 0.7022, Training Accuracy= 0.507\n",
      "Epoch: 2620, Minibatch Loss= 0.7021, Training Accuracy= 0.507\n",
      "Epoch: 2630, Minibatch Loss= 0.7020, Training Accuracy= 0.507\n",
      "Epoch: 2640, Minibatch Loss= 0.7019, Training Accuracy= 0.507\n",
      "Epoch: 2650, Minibatch Loss= 0.7018, Training Accuracy= 0.507\n",
      "Epoch: 2660, Minibatch Loss= 0.7017, Training Accuracy= 0.507\n",
      "Epoch: 2670, Minibatch Loss= 0.7016, Training Accuracy= 0.507\n",
      "Epoch: 2680, Minibatch Loss= 0.7015, Training Accuracy= 0.507\n",
      "Epoch: 2690, Minibatch Loss= 0.7014, Training Accuracy= 0.507\n",
      "Epoch: 2700, Minibatch Loss= 0.7013, Training Accuracy= 0.507\n",
      "Epoch: 2710, Minibatch Loss= 0.7013, Training Accuracy= 0.507\n",
      "Epoch: 2720, Minibatch Loss= 0.7012, Training Accuracy= 0.507\n",
      "Epoch: 2730, Minibatch Loss= 0.7011, Training Accuracy= 0.507\n",
      "Epoch: 2740, Minibatch Loss= 0.7010, Training Accuracy= 0.507\n",
      "Epoch: 2750, Minibatch Loss= 0.7009, Training Accuracy= 0.507\n",
      "Epoch: 2760, Minibatch Loss= 0.7009, Training Accuracy= 0.507\n",
      "Epoch: 2770, Minibatch Loss= 0.7008, Training Accuracy= 0.507\n",
      "Epoch: 2780, Minibatch Loss= 0.7007, Training Accuracy= 0.507\n",
      "Epoch: 2790, Minibatch Loss= 0.7007, Training Accuracy= 0.507\n",
      "Epoch: 2800, Minibatch Loss= 0.7006, Training Accuracy= 0.507\n",
      "Epoch: 2810, Minibatch Loss= 0.7005, Training Accuracy= 0.507\n",
      "Epoch: 2820, Minibatch Loss= 0.7004, Training Accuracy= 0.507\n",
      "Epoch: 2830, Minibatch Loss= 0.7004, Training Accuracy= 0.507\n",
      "Epoch: 2840, Minibatch Loss= 0.7003, Training Accuracy= 0.507\n",
      "Epoch: 2850, Minibatch Loss= 0.7002, Training Accuracy= 0.507\n",
      "Epoch: 2860, Minibatch Loss= 0.7001, Training Accuracy= 0.507\n",
      "Epoch: 2870, Minibatch Loss= 0.7001, Training Accuracy= 0.507\n",
      "Epoch: 2880, Minibatch Loss= 0.7001, Training Accuracy= 0.507\n",
      "Epoch: 2890, Minibatch Loss= 0.7001, Training Accuracy= 0.507\n",
      "Epoch: 2900, Minibatch Loss= 0.7001, Training Accuracy= 0.507\n",
      "Epoch: 2910, Minibatch Loss= 0.7001, Training Accuracy= 0.507\n",
      "Epoch: 2920, Minibatch Loss= 0.7001, Training Accuracy= 0.507\n",
      "Epoch: 2930, Minibatch Loss= 0.7002, Training Accuracy= 0.507\n",
      "Epoch: 2940, Minibatch Loss= 0.7002, Training Accuracy= 0.507\n",
      "Epoch: 2950, Minibatch Loss= 0.7003, Training Accuracy= 0.507\n",
      "Epoch: 2960, Minibatch Loss= 0.7003, Training Accuracy= 0.506\n",
      "Epoch: 2970, Minibatch Loss= 0.7003, Training Accuracy= 0.506\n",
      "Epoch: 2980, Minibatch Loss= 0.7004, Training Accuracy= 0.507\n",
      "Epoch: 2990, Minibatch Loss= 0.7004, Training Accuracy= 0.507\n",
      "Epoch: 3000, Minibatch Loss= 0.7005, Training Accuracy= 0.507\n",
      "Epoch: 3010, Minibatch Loss= 0.7005, Training Accuracy= 0.507\n",
      "Epoch: 3020, Minibatch Loss= 0.7006, Training Accuracy= 0.507\n",
      "Epoch: 3030, Minibatch Loss= 0.7006, Training Accuracy= 0.507\n",
      "Epoch: 3040, Minibatch Loss= 0.7006, Training Accuracy= 0.507\n",
      "Epoch: 3050, Minibatch Loss= 0.7007, Training Accuracy= 0.507\n",
      "Epoch: 3060, Minibatch Loss= 0.7007, Training Accuracy= 0.507\n",
      "Epoch: 3070, Minibatch Loss= 0.7007, Training Accuracy= 0.507\n",
      "Epoch: 3080, Minibatch Loss= 0.7007, Training Accuracy= 0.507\n",
      "Epoch: 3090, Minibatch Loss= 0.7008, Training Accuracy= 0.508\n",
      "Epoch: 3100, Minibatch Loss= 0.7008, Training Accuracy= 0.508\n",
      "Epoch: 3110, Minibatch Loss= 0.7008, Training Accuracy= 0.508\n",
      "Epoch: 3120, Minibatch Loss= 0.7007, Training Accuracy= 0.508\n",
      "Epoch: 3130, Minibatch Loss= 0.7007, Training Accuracy= 0.507\n",
      "Epoch: 3140, Minibatch Loss= 0.7007, Training Accuracy= 0.507\n",
      "Epoch: 3150, Minibatch Loss= 0.7007, Training Accuracy= 0.508\n",
      "Epoch: 3160, Minibatch Loss= 0.7007, Training Accuracy= 0.507\n",
      "Epoch: 3170, Minibatch Loss= 0.7007, Training Accuracy= 0.509\n",
      "Epoch: 3180, Minibatch Loss= 0.7007, Training Accuracy= 0.510\n",
      "Epoch: 3190, Minibatch Loss= 0.7007, Training Accuracy= 0.510\n",
      "Epoch: 3200, Minibatch Loss= 0.7007, Training Accuracy= 0.511\n",
      "Epoch: 3210, Minibatch Loss= 0.7006, Training Accuracy= 0.511\n",
      "Epoch: 3220, Minibatch Loss= 0.7006, Training Accuracy= 0.510\n",
      "Epoch: 3230, Minibatch Loss= 0.7006, Training Accuracy= 0.511\n",
      "Epoch: 3240, Minibatch Loss= 0.7006, Training Accuracy= 0.512\n",
      "Epoch: 3250, Minibatch Loss= 0.7006, Training Accuracy= 0.513\n",
      "Epoch: 3260, Minibatch Loss= 0.7005, Training Accuracy= 0.513\n",
      "Epoch: 3270, Minibatch Loss= 0.7005, Training Accuracy= 0.512\n",
      "Epoch: 3280, Minibatch Loss= 0.7006, Training Accuracy= 0.512\n",
      "Epoch: 3290, Minibatch Loss= 0.7007, Training Accuracy= 0.512\n",
      "Epoch: 3300, Minibatch Loss= 0.7008, Training Accuracy= 0.512\n",
      "Epoch: 3310, Minibatch Loss= 0.7008, Training Accuracy= 0.512\n",
      "Epoch: 3320, Minibatch Loss= 0.7007, Training Accuracy= 0.512\n",
      "Epoch: 3330, Minibatch Loss= 0.7007, Training Accuracy= 0.512\n",
      "Epoch: 3340, Minibatch Loss= 0.7006, Training Accuracy= 0.512\n",
      "Epoch: 3350, Minibatch Loss= 0.7005, Training Accuracy= 0.514\n",
      "Epoch: 3360, Minibatch Loss= 0.7006, Training Accuracy= 0.515\n",
      "Epoch: 3370, Minibatch Loss= 0.7001, Training Accuracy= 0.516\n",
      "Epoch: 3380, Minibatch Loss= 0.7005, Training Accuracy= 0.517\n",
      "Epoch: 3390, Minibatch Loss= 0.7017, Training Accuracy= 0.516\n",
      "Epoch: 3400, Minibatch Loss= 0.6991, Training Accuracy= 0.520\n",
      "Epoch: 3410, Minibatch Loss= 0.6988, Training Accuracy= 0.518\n",
      "Epoch: 3420, Minibatch Loss= 0.6983, Training Accuracy= 0.518\n",
      "Epoch: 3430, Minibatch Loss= 0.6998, Training Accuracy= 0.519\n",
      "Epoch: 3440, Minibatch Loss= 0.6983, Training Accuracy= 0.520\n",
      "Epoch: 3450, Minibatch Loss= 0.7050, Training Accuracy= 0.512\n",
      "Epoch: 3460, Minibatch Loss= 0.7014, Training Accuracy= 0.516\n",
      "Epoch: 3470, Minibatch Loss= 0.6999, Training Accuracy= 0.515\n",
      "Epoch: 3480, Minibatch Loss= 0.7000, Training Accuracy= 0.516\n",
      "Epoch: 3490, Minibatch Loss= 0.7023, Training Accuracy= 0.514\n",
      "Epoch: 3500, Minibatch Loss= 0.6989, Training Accuracy= 0.522\n",
      "Epoch: 3510, Minibatch Loss= 0.7043, Training Accuracy= 0.509\n",
      "Epoch: 3520, Minibatch Loss= 0.6979, Training Accuracy= 0.521\n",
      "Epoch: 3530, Minibatch Loss= 0.6988, Training Accuracy= 0.518\n",
      "Epoch: 3540, Minibatch Loss= 0.7011, Training Accuracy= 0.513\n",
      "Epoch: 3550, Minibatch Loss= 0.6994, Training Accuracy= 0.520\n",
      "Epoch: 3560, Minibatch Loss= 0.6980, Training Accuracy= 0.521\n",
      "Epoch: 3570, Minibatch Loss= 0.7024, Training Accuracy= 0.512\n",
      "Epoch: 3580, Minibatch Loss= 0.7009, Training Accuracy= 0.515\n",
      "Epoch: 3590, Minibatch Loss= 0.7006, Training Accuracy= 0.515\n",
      "Epoch: 3600, Minibatch Loss= 0.6982, Training Accuracy= 0.518\n",
      "Epoch: 3610, Minibatch Loss= 0.6980, Training Accuracy= 0.521\n",
      "Epoch: 3620, Minibatch Loss= 0.6976, Training Accuracy= 0.521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3630, Minibatch Loss= 0.6984, Training Accuracy= 0.514\n",
      "Epoch: 3640, Minibatch Loss= 0.6973, Training Accuracy= 0.519\n",
      "Epoch: 3650, Minibatch Loss= 0.6975, Training Accuracy= 0.523\n",
      "Epoch: 3660, Minibatch Loss= 0.6993, Training Accuracy= 0.507\n",
      "Epoch: 3670, Minibatch Loss= 0.6987, Training Accuracy= 0.507\n",
      "Epoch: 3680, Minibatch Loss= 0.6985, Training Accuracy= 0.507\n",
      "Epoch: 3690, Minibatch Loss= 0.6983, Training Accuracy= 0.507\n",
      "Epoch: 3700, Minibatch Loss= 0.6983, Training Accuracy= 0.507\n",
      "Epoch: 3710, Minibatch Loss= 0.6983, Training Accuracy= 0.507\n",
      "Epoch: 3720, Minibatch Loss= 0.6983, Training Accuracy= 0.507\n",
      "Epoch: 3730, Minibatch Loss= 0.6983, Training Accuracy= 0.507\n",
      "Epoch: 3740, Minibatch Loss= 0.6983, Training Accuracy= 0.507\n",
      "Epoch: 3750, Minibatch Loss= 0.6983, Training Accuracy= 0.507\n",
      "Epoch: 3760, Minibatch Loss= 0.6983, Training Accuracy= 0.507\n",
      "Epoch: 3770, Minibatch Loss= 0.6983, Training Accuracy= 0.507\n",
      "Epoch: 3780, Minibatch Loss= 0.6984, Training Accuracy= 0.507\n",
      "Epoch: 3790, Minibatch Loss= 0.6985, Training Accuracy= 0.507\n",
      "Epoch: 3800, Minibatch Loss= 0.6986, Training Accuracy= 0.507\n",
      "Epoch: 3810, Minibatch Loss= 0.6986, Training Accuracy= 0.507\n",
      "Epoch: 3820, Minibatch Loss= 0.6986, Training Accuracy= 0.507\n",
      "Epoch: 3830, Minibatch Loss= 0.6986, Training Accuracy= 0.507\n",
      "Epoch: 3840, Minibatch Loss= 0.6986, Training Accuracy= 0.507\n",
      "Epoch: 3850, Minibatch Loss= 0.6988, Training Accuracy= 0.507\n",
      "Epoch: 3860, Minibatch Loss= 0.6987, Training Accuracy= 0.507\n",
      "Epoch: 3870, Minibatch Loss= 0.6987, Training Accuracy= 0.507\n",
      "Epoch: 3880, Minibatch Loss= 0.6986, Training Accuracy= 0.507\n",
      "Epoch: 3890, Minibatch Loss= 0.6986, Training Accuracy= 0.507\n",
      "Epoch: 3900, Minibatch Loss= 0.6986, Training Accuracy= 0.507\n",
      "Epoch: 3910, Minibatch Loss= 0.6986, Training Accuracy= 0.506\n",
      "Epoch: 3920, Minibatch Loss= 0.6986, Training Accuracy= 0.506\n",
      "Epoch: 3930, Minibatch Loss= 0.6985, Training Accuracy= 0.507\n",
      "Epoch: 3940, Minibatch Loss= 0.6984, Training Accuracy= 0.507\n",
      "Epoch: 3950, Minibatch Loss= 0.6984, Training Accuracy= 0.507\n",
      "Epoch: 3960, Minibatch Loss= 0.6983, Training Accuracy= 0.506\n",
      "Epoch: 3970, Minibatch Loss= 0.6983, Training Accuracy= 0.506\n",
      "Epoch: 3980, Minibatch Loss= 0.6983, Training Accuracy= 0.506\n",
      "Epoch: 3990, Minibatch Loss= 0.6983, Training Accuracy= 0.507\n",
      "Epoch: 4000, Minibatch Loss= 0.6984, Training Accuracy= 0.508\n",
      "Epoch: 4010, Minibatch Loss= 0.6985, Training Accuracy= 0.508\n",
      "Epoch: 4020, Minibatch Loss= 0.6986, Training Accuracy= 0.509\n",
      "Epoch: 4030, Minibatch Loss= 0.6987, Training Accuracy= 0.510\n",
      "Epoch: 4040, Minibatch Loss= 0.6987, Training Accuracy= 0.511\n",
      "Epoch: 4050, Minibatch Loss= 0.6996, Training Accuracy= 0.511\n",
      "Epoch: 4060, Minibatch Loss= 0.6993, Training Accuracy= 0.512\n",
      "Epoch: 4070, Minibatch Loss= 0.6996, Training Accuracy= 0.513\n",
      "Epoch: 4080, Minibatch Loss= 0.6996, Training Accuracy= 0.514\n",
      "Epoch: 4090, Minibatch Loss= 0.6997, Training Accuracy= 0.515\n",
      "Epoch: 4100, Minibatch Loss= 0.6997, Training Accuracy= 0.515\n",
      "Epoch: 4110, Minibatch Loss= 0.6988, Training Accuracy= 0.516\n",
      "Epoch: 4120, Minibatch Loss= 0.6982, Training Accuracy= 0.513\n",
      "Epoch: 4130, Minibatch Loss= 0.6987, Training Accuracy= 0.514\n",
      "Epoch: 4140, Minibatch Loss= 0.6978, Training Accuracy= 0.515\n",
      "Epoch: 4150, Minibatch Loss= 0.6959, Training Accuracy= 0.520\n",
      "Epoch: 4160, Minibatch Loss= 0.6959, Training Accuracy= 0.520\n",
      "Epoch: 4170, Minibatch Loss= 0.6961, Training Accuracy= 0.521\n",
      "Epoch: 4180, Minibatch Loss= 0.6961, Training Accuracy= 0.521\n",
      "Epoch: 4190, Minibatch Loss= 0.6959, Training Accuracy= 0.521\n",
      "Epoch: 4200, Minibatch Loss= 0.6957, Training Accuracy= 0.523\n",
      "Epoch: 4210, Minibatch Loss= 0.6958, Training Accuracy= 0.523\n",
      "Epoch: 4220, Minibatch Loss= 0.6963, Training Accuracy= 0.524\n",
      "Epoch: 4230, Minibatch Loss= 0.6955, Training Accuracy= 0.526\n",
      "Epoch: 4240, Minibatch Loss= 0.6949, Training Accuracy= 0.528\n",
      "Epoch: 4250, Minibatch Loss= 0.6948, Training Accuracy= 0.529\n",
      "Epoch: 4260, Minibatch Loss= 0.6943, Training Accuracy= 0.530\n",
      "Epoch: 4270, Minibatch Loss= 0.6943, Training Accuracy= 0.529\n",
      "Epoch: 4280, Minibatch Loss= 0.6940, Training Accuracy= 0.531\n",
      "Epoch: 4290, Minibatch Loss= 0.6951, Training Accuracy= 0.527\n",
      "Epoch: 4300, Minibatch Loss= 0.6951, Training Accuracy= 0.528\n",
      "Epoch: 4310, Minibatch Loss= 0.6949, Training Accuracy= 0.530\n",
      "Epoch: 4320, Minibatch Loss= 0.6935, Training Accuracy= 0.532\n",
      "Epoch: 4330, Minibatch Loss= 0.6953, Training Accuracy= 0.527\n",
      "Epoch: 4340, Minibatch Loss= 0.6932, Training Accuracy= 0.533\n",
      "Epoch: 4350, Minibatch Loss= 0.6921, Training Accuracy= 0.537\n",
      "Epoch: 4360, Minibatch Loss= 0.6928, Training Accuracy= 0.536\n",
      "Epoch: 4370, Minibatch Loss= 0.6920, Training Accuracy= 0.538\n",
      "Epoch: 4380, Minibatch Loss= 0.6947, Training Accuracy= 0.535\n",
      "Epoch: 4390, Minibatch Loss= 0.6950, Training Accuracy= 0.534\n",
      "Epoch: 4400, Minibatch Loss= 0.6954, Training Accuracy= 0.536\n",
      "Epoch: 4410, Minibatch Loss= 0.6930, Training Accuracy= 0.539\n",
      "Epoch: 4420, Minibatch Loss= 0.6940, Training Accuracy= 0.538\n",
      "Epoch: 4430, Minibatch Loss= 0.6949, Training Accuracy= 0.529\n",
      "Epoch: 4440, Minibatch Loss= 0.6919, Training Accuracy= 0.536\n",
      "Epoch: 4450, Minibatch Loss= 0.6934, Training Accuracy= 0.540\n",
      "Epoch: 4460, Minibatch Loss= 0.6925, Training Accuracy= 0.538\n",
      "Epoch: 4470, Minibatch Loss= 0.6929, Training Accuracy= 0.540\n",
      "Epoch: 4480, Minibatch Loss= 0.6944, Training Accuracy= 0.535\n",
      "Epoch: 4490, Minibatch Loss= 0.7058, Training Accuracy= 0.505\n",
      "Epoch: 4500, Minibatch Loss= 0.7013, Training Accuracy= 0.507\n",
      "Epoch: 4510, Minibatch Loss= 0.7007, Training Accuracy= 0.509\n",
      "Epoch: 4520, Minibatch Loss= 0.7003, Training Accuracy= 0.510\n",
      "Epoch: 4530, Minibatch Loss= 0.7000, Training Accuracy= 0.509\n",
      "Epoch: 4540, Minibatch Loss= 0.6998, Training Accuracy= 0.510\n",
      "Epoch: 4550, Minibatch Loss= 0.6996, Training Accuracy= 0.510\n",
      "Epoch: 4560, Minibatch Loss= 0.6994, Training Accuracy= 0.510\n",
      "Epoch: 4570, Minibatch Loss= 0.6993, Training Accuracy= 0.510\n",
      "Epoch: 4580, Minibatch Loss= 0.6991, Training Accuracy= 0.511\n",
      "Epoch: 4590, Minibatch Loss= 0.6990, Training Accuracy= 0.511\n",
      "Epoch: 4600, Minibatch Loss= 0.6989, Training Accuracy= 0.512\n",
      "Epoch: 4610, Minibatch Loss= 0.6988, Training Accuracy= 0.511\n",
      "Epoch: 4620, Minibatch Loss= 0.6987, Training Accuracy= 0.510\n",
      "Epoch: 4630, Minibatch Loss= 0.6987, Training Accuracy= 0.511\n",
      "Epoch: 4640, Minibatch Loss= 0.6986, Training Accuracy= 0.511\n",
      "Epoch: 4650, Minibatch Loss= 0.6985, Training Accuracy= 0.511\n",
      "Epoch: 4660, Minibatch Loss= 0.6985, Training Accuracy= 0.511\n",
      "Epoch: 4670, Minibatch Loss= 0.6985, Training Accuracy= 0.511\n",
      "Epoch: 4680, Minibatch Loss= 0.6985, Training Accuracy= 0.513\n",
      "Epoch: 4690, Minibatch Loss= 0.6984, Training Accuracy= 0.512\n",
      "Epoch: 4700, Minibatch Loss= 0.6984, Training Accuracy= 0.512\n",
      "Epoch: 4710, Minibatch Loss= 0.6984, Training Accuracy= 0.513\n",
      "Epoch: 4720, Minibatch Loss= 0.6984, Training Accuracy= 0.513\n",
      "Epoch: 4730, Minibatch Loss= 0.6984, Training Accuracy= 0.513\n",
      "Epoch: 4740, Minibatch Loss= 0.6984, Training Accuracy= 0.512\n",
      "Epoch: 4750, Minibatch Loss= 0.6983, Training Accuracy= 0.513\n",
      "Epoch: 4760, Minibatch Loss= 0.6983, Training Accuracy= 0.514\n",
      "Epoch: 4770, Minibatch Loss= 0.6982, Training Accuracy= 0.515\n",
      "Epoch: 4780, Minibatch Loss= 0.6982, Training Accuracy= 0.514\n",
      "Epoch: 4790, Minibatch Loss= 0.6983, Training Accuracy= 0.514\n",
      "Epoch: 4800, Minibatch Loss= 0.6986, Training Accuracy= 0.515\n",
      "Epoch: 4810, Minibatch Loss= 0.6989, Training Accuracy= 0.516\n",
      "Epoch: 4820, Minibatch Loss= 0.6989, Training Accuracy= 0.517\n",
      "Epoch: 4830, Minibatch Loss= 0.6983, Training Accuracy= 0.519\n",
      "Epoch: 4840, Minibatch Loss= 0.6973, Training Accuracy= 0.523\n",
      "Epoch: 4850, Minibatch Loss= 0.6956, Training Accuracy= 0.527\n",
      "Epoch: 4860, Minibatch Loss= 0.6957, Training Accuracy= 0.526\n",
      "Epoch: 4870, Minibatch Loss= 0.6961, Training Accuracy= 0.527\n",
      "Epoch: 4880, Minibatch Loss= 0.6974, Training Accuracy= 0.527\n",
      "Epoch: 4890, Minibatch Loss= 0.6966, Training Accuracy= 0.529\n",
      "Epoch: 4900, Minibatch Loss= 0.6971, Training Accuracy= 0.529\n",
      "Epoch: 4910, Minibatch Loss= 0.6981, Training Accuracy= 0.526\n",
      "Epoch: 4920, Minibatch Loss= 0.7034, Training Accuracy= 0.521\n",
      "Epoch: 4930, Minibatch Loss= 0.6994, Training Accuracy= 0.528\n",
      "Epoch: 4940, Minibatch Loss= 0.6929, Training Accuracy= 0.537\n",
      "Epoch: 4950, Minibatch Loss= 0.6948, Training Accuracy= 0.535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4960, Minibatch Loss= 0.6989, Training Accuracy= 0.531\n",
      "Epoch: 4970, Minibatch Loss= 0.6950, Training Accuracy= 0.538\n",
      "Epoch: 4980, Minibatch Loss= 0.6979, Training Accuracy= 0.533\n",
      "Epoch: 4990, Minibatch Loss= 0.7059, Training Accuracy= 0.507\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4998\n",
      "Replication: 4: \n",
      "Epoch: 0, Minibatch Loss= 0.6932, Training Accuracy= 0.503\n",
      "Epoch: 10, Minibatch Loss= 0.6931, Training Accuracy= 0.502\n",
      "Epoch: 20, Minibatch Loss= 0.6930, Training Accuracy= 0.504\n",
      "Epoch: 30, Minibatch Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 40, Minibatch Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 50, Minibatch Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 60, Minibatch Loss= 0.6930, Training Accuracy= 0.505\n",
      "Epoch: 70, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 80, Minibatch Loss= 0.6930, Training Accuracy= 0.506\n",
      "Epoch: 90, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 100, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 110, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 120, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 130, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 140, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 150, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 160, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 170, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 180, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 190, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 200, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 210, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 220, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 230, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 240, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 250, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 260, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 270, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 280, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 290, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 300, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 310, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 320, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 330, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 340, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 350, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 360, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 370, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 380, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 390, Minibatch Loss= 0.6931, Training Accuracy= 0.506\n",
      "Epoch: 400, Minibatch Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 410, Minibatch Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 420, Minibatch Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 430, Minibatch Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 440, Minibatch Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 450, Minibatch Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 460, Minibatch Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 470, Minibatch Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 480, Minibatch Loss= 0.6931, Training Accuracy= 0.507\n",
      "Epoch: 490, Minibatch Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 500, Minibatch Loss= 0.6931, Training Accuracy= 0.508\n",
      "Epoch: 510, Minibatch Loss= 0.6931, Training Accuracy= 0.509\n",
      "Epoch: 520, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 530, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 540, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 550, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 560, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 570, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 580, Minibatch Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 590, Minibatch Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 600, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 610, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 620, Minibatch Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 630, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 640, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 650, Minibatch Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 660, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 670, Minibatch Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 680, Minibatch Loss= 0.6929, Training Accuracy= 0.509\n",
      "Epoch: 690, Minibatch Loss= 0.6929, Training Accuracy= 0.510\n",
      "Epoch: 700, Minibatch Loss= 0.6929, Training Accuracy= 0.510\n",
      "Epoch: 710, Minibatch Loss= 0.6929, Training Accuracy= 0.509\n",
      "Epoch: 720, Minibatch Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 730, Minibatch Loss= 0.6927, Training Accuracy= 0.513\n",
      "Epoch: 740, Minibatch Loss= 0.6924, Training Accuracy= 0.518\n",
      "Epoch: 750, Minibatch Loss= 0.6929, Training Accuracy= 0.510\n",
      "Epoch: 760, Minibatch Loss= 0.6924, Training Accuracy= 0.512\n",
      "Epoch: 770, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 780, Minibatch Loss= 0.6920, Training Accuracy= 0.519\n",
      "Epoch: 790, Minibatch Loss= 0.6926, Training Accuracy= 0.508\n",
      "Epoch: 800, Minibatch Loss= 0.6927, Training Accuracy= 0.508\n",
      "Epoch: 810, Minibatch Loss= 0.6926, Training Accuracy= 0.507\n",
      "Epoch: 820, Minibatch Loss= 0.6926, Training Accuracy= 0.509\n",
      "Epoch: 830, Minibatch Loss= 0.6925, Training Accuracy= 0.511\n",
      "Epoch: 840, Minibatch Loss= 0.6926, Training Accuracy= 0.513\n",
      "Epoch: 850, Minibatch Loss= 0.6930, Training Accuracy= 0.509\n",
      "Epoch: 860, Minibatch Loss= 0.6929, Training Accuracy= 0.510\n",
      "Epoch: 870, Minibatch Loss= 0.6929, Training Accuracy= 0.510\n",
      "Epoch: 880, Minibatch Loss= 0.6929, Training Accuracy= 0.510\n",
      "Epoch: 890, Minibatch Loss= 0.6929, Training Accuracy= 0.510\n",
      "Epoch: 900, Minibatch Loss= 0.6928, Training Accuracy= 0.510\n",
      "Epoch: 910, Minibatch Loss= 0.6928, Training Accuracy= 0.510\n",
      "Epoch: 920, Minibatch Loss= 0.6928, Training Accuracy= 0.509\n",
      "Epoch: 930, Minibatch Loss= 0.6928, Training Accuracy= 0.510\n",
      "Epoch: 940, Minibatch Loss= 0.6927, Training Accuracy= 0.511\n",
      "Epoch: 950, Minibatch Loss= 0.6927, Training Accuracy= 0.512\n",
      "Epoch: 960, Minibatch Loss= 0.6928, Training Accuracy= 0.508\n",
      "Epoch: 970, Minibatch Loss= 0.6927, Training Accuracy= 0.514\n",
      "Epoch: 980, Minibatch Loss= 0.6926, Training Accuracy= 0.512\n",
      "Epoch: 990, Minibatch Loss= 0.6926, Training Accuracy= 0.513\n",
      "Epoch: 1000, Minibatch Loss= 0.6924, Training Accuracy= 0.512\n",
      "Epoch: 1010, Minibatch Loss= 0.6924, Training Accuracy= 0.516\n",
      "Epoch: 1020, Minibatch Loss= 0.6925, Training Accuracy= 0.513\n",
      "Epoch: 1030, Minibatch Loss= 0.6924, Training Accuracy= 0.516\n",
      "Epoch: 1040, Minibatch Loss= 0.6920, Training Accuracy= 0.517\n",
      "Epoch: 1050, Minibatch Loss= 0.6915, Training Accuracy= 0.522\n",
      "Epoch: 1060, Minibatch Loss= 0.6915, Training Accuracy= 0.521\n",
      "Epoch: 1070, Minibatch Loss= 0.6928, Training Accuracy= 0.516\n",
      "Epoch: 1080, Minibatch Loss= 0.6916, Training Accuracy= 0.521\n",
      "Epoch: 1090, Minibatch Loss= 0.6930, Training Accuracy= 0.507\n",
      "Epoch: 1100, Minibatch Loss= 0.6926, Training Accuracy= 0.518\n",
      "Epoch: 1110, Minibatch Loss= 0.6923, Training Accuracy= 0.517\n",
      "Epoch: 1120, Minibatch Loss= 0.6922, Training Accuracy= 0.520\n",
      "Epoch: 1130, Minibatch Loss= 0.6933, Training Accuracy= 0.512\n",
      "Epoch: 1140, Minibatch Loss= 0.6928, Training Accuracy= 0.509\n",
      "Epoch: 1150, Minibatch Loss= 0.6927, Training Accuracy= 0.511\n",
      "Epoch: 1160, Minibatch Loss= 0.6927, Training Accuracy= 0.511\n",
      "Epoch: 1170, Minibatch Loss= 0.6927, Training Accuracy= 0.511\n",
      "Epoch: 1180, Minibatch Loss= 0.6926, Training Accuracy= 0.511\n",
      "Epoch: 1190, Minibatch Loss= 0.6923, Training Accuracy= 0.513\n",
      "Epoch: 1200, Minibatch Loss= 0.6915, Training Accuracy= 0.522\n",
      "Epoch: 1210, Minibatch Loss= 0.6917, Training Accuracy= 0.518\n",
      "Epoch: 1220, Minibatch Loss= 0.6924, Training Accuracy= 0.519\n",
      "Epoch: 1230, Minibatch Loss= 0.6947, Training Accuracy= 0.512\n",
      "Epoch: 1240, Minibatch Loss= 0.6923, Training Accuracy= 0.518\n",
      "Epoch: 1250, Minibatch Loss= 0.6918, Training Accuracy= 0.521\n",
      "Epoch: 1260, Minibatch Loss= 0.6920, Training Accuracy= 0.523\n",
      "Epoch: 1270, Minibatch Loss= 0.6914, Training Accuracy= 0.527\n",
      "Epoch: 1280, Minibatch Loss= 0.6912, Training Accuracy= 0.523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1290, Minibatch Loss= 0.6916, Training Accuracy= 0.519\n",
      "Epoch: 1300, Minibatch Loss= 0.6914, Training Accuracy= 0.522\n",
      "Epoch: 1310, Minibatch Loss= 0.6913, Training Accuracy= 0.526\n",
      "Epoch: 1320, Minibatch Loss= 0.6908, Training Accuracy= 0.529\n",
      "Epoch: 1330, Minibatch Loss= 0.6904, Training Accuracy= 0.528\n",
      "Epoch: 1340, Minibatch Loss= 0.6913, Training Accuracy= 0.529\n",
      "Epoch: 1350, Minibatch Loss= 0.6936, Training Accuracy= 0.522\n",
      "Epoch: 1360, Minibatch Loss= 0.6923, Training Accuracy= 0.529\n",
      "Epoch: 1370, Minibatch Loss= 0.6915, Training Accuracy= 0.527\n",
      "Epoch: 1380, Minibatch Loss= 0.6891, Training Accuracy= 0.533\n",
      "Epoch: 1390, Minibatch Loss= 0.6891, Training Accuracy= 0.534\n",
      "Epoch: 1400, Minibatch Loss= 0.6918, Training Accuracy= 0.522\n",
      "Epoch: 1410, Minibatch Loss= 0.6929, Training Accuracy= 0.529\n",
      "Epoch: 1420, Minibatch Loss= 0.6885, Training Accuracy= 0.534\n",
      "Epoch: 1430, Minibatch Loss= 0.6930, Training Accuracy= 0.518\n",
      "Epoch: 1440, Minibatch Loss= 0.6925, Training Accuracy= 0.508\n",
      "Epoch: 1450, Minibatch Loss= 0.6922, Training Accuracy= 0.513\n",
      "Epoch: 1460, Minibatch Loss= 0.6924, Training Accuracy= 0.510\n",
      "Epoch: 1470, Minibatch Loss= 0.6922, Training Accuracy= 0.515\n",
      "Epoch: 1480, Minibatch Loss= 0.6920, Training Accuracy= 0.517\n",
      "Epoch: 1490, Minibatch Loss= 0.6920, Training Accuracy= 0.515\n",
      "Epoch: 1500, Minibatch Loss= 0.6919, Training Accuracy= 0.519\n",
      "Epoch: 1510, Minibatch Loss= 0.6916, Training Accuracy= 0.518\n",
      "Epoch: 1520, Minibatch Loss= 0.6915, Training Accuracy= 0.519\n",
      "Epoch: 1530, Minibatch Loss= 0.6918, Training Accuracy= 0.516\n",
      "Epoch: 1540, Minibatch Loss= 0.6919, Training Accuracy= 0.517\n",
      "Epoch: 1550, Minibatch Loss= 0.6909, Training Accuracy= 0.522\n",
      "Epoch: 1560, Minibatch Loss= 0.6905, Training Accuracy= 0.524\n",
      "Epoch: 1570, Minibatch Loss= 0.6915, Training Accuracy= 0.522\n",
      "Epoch: 1580, Minibatch Loss= 0.6910, Training Accuracy= 0.525\n",
      "Epoch: 1590, Minibatch Loss= 0.6902, Training Accuracy= 0.530\n",
      "Epoch: 1600, Minibatch Loss= 0.6920, Training Accuracy= 0.515\n",
      "Epoch: 1610, Minibatch Loss= 0.6902, Training Accuracy= 0.524\n",
      "Epoch: 1620, Minibatch Loss= 0.6908, Training Accuracy= 0.527\n",
      "Epoch: 1630, Minibatch Loss= 0.6891, Training Accuracy= 0.530\n",
      "Epoch: 1640, Minibatch Loss= 0.6891, Training Accuracy= 0.534\n",
      "Epoch: 1650, Minibatch Loss= 0.6887, Training Accuracy= 0.535\n",
      "Epoch: 1660, Minibatch Loss= 0.7066, Training Accuracy= 0.505\n",
      "Epoch: 1670, Minibatch Loss= 0.6934, Training Accuracy= 0.529\n",
      "Epoch: 1680, Minibatch Loss= 0.6893, Training Accuracy= 0.537\n",
      "Epoch: 1690, Minibatch Loss= 0.6906, Training Accuracy= 0.529\n",
      "Epoch: 1700, Minibatch Loss= 0.6887, Training Accuracy= 0.536\n",
      "Epoch: 1710, Minibatch Loss= 0.6877, Training Accuracy= 0.541\n",
      "Epoch: 1720, Minibatch Loss= 0.6885, Training Accuracy= 0.537\n",
      "Epoch: 1730, Minibatch Loss= 0.6852, Training Accuracy= 0.551\n",
      "Epoch: 1740, Minibatch Loss= 0.6927, Training Accuracy= 0.534\n",
      "Epoch: 1750, Minibatch Loss= 0.6907, Training Accuracy= 0.532\n",
      "Epoch: 1760, Minibatch Loss= 0.6837, Training Accuracy= 0.553\n",
      "Epoch: 1770, Minibatch Loss= 0.6856, Training Accuracy= 0.544\n",
      "Epoch: 1780, Minibatch Loss= 0.6871, Training Accuracy= 0.542\n",
      "Epoch: 1790, Minibatch Loss= 0.6865, Training Accuracy= 0.544\n",
      "Epoch: 1800, Minibatch Loss= 0.6864, Training Accuracy= 0.545\n",
      "Epoch: 1810, Minibatch Loss= 0.6922, Training Accuracy= 0.531\n",
      "Epoch: 1820, Minibatch Loss= 0.6846, Training Accuracy= 0.548\n",
      "Epoch: 1830, Minibatch Loss= 0.6827, Training Accuracy= 0.557\n",
      "Epoch: 1840, Minibatch Loss= 0.6777, Training Accuracy= 0.566\n",
      "Epoch: 1850, Minibatch Loss= 0.6810, Training Accuracy= 0.560\n",
      "Epoch: 1860, Minibatch Loss= 0.6887, Training Accuracy= 0.547\n",
      "Epoch: 1870, Minibatch Loss= 0.6870, Training Accuracy= 0.547\n",
      "Epoch: 1880, Minibatch Loss= 0.6737, Training Accuracy= 0.575\n",
      "Epoch: 1890, Minibatch Loss= 0.6769, Training Accuracy= 0.571\n",
      "Epoch: 1900, Minibatch Loss= 0.6756, Training Accuracy= 0.571\n",
      "Epoch: 1910, Minibatch Loss= 0.6912, Training Accuracy= 0.545\n",
      "Epoch: 1920, Minibatch Loss= 0.6780, Training Accuracy= 0.574\n",
      "Epoch: 1930, Minibatch Loss= 0.6961, Training Accuracy= 0.525\n",
      "Epoch: 1940, Minibatch Loss= 0.6793, Training Accuracy= 0.556\n",
      "Epoch: 1950, Minibatch Loss= 0.6791, Training Accuracy= 0.563\n",
      "Epoch: 1960, Minibatch Loss= 0.6749, Training Accuracy= 0.573\n",
      "Epoch: 1970, Minibatch Loss= 0.6775, Training Accuracy= 0.576\n",
      "Epoch: 1980, Minibatch Loss= 0.6790, Training Accuracy= 0.571\n",
      "Epoch: 1990, Minibatch Loss= 0.7089, Training Accuracy= 0.518\n",
      "Epoch: 2000, Minibatch Loss= 0.6695, Training Accuracy= 0.587\n",
      "Epoch: 2010, Minibatch Loss= 0.6837, Training Accuracy= 0.567\n",
      "Epoch: 2020, Minibatch Loss= 0.6530, Training Accuracy= 0.607\n",
      "Epoch: 2030, Minibatch Loss= 0.6543, Training Accuracy= 0.605\n",
      "Epoch: 2040, Minibatch Loss= 0.6549, Training Accuracy= 0.604\n",
      "Epoch: 2050, Minibatch Loss= 0.6599, Training Accuracy= 0.602\n",
      "Epoch: 2060, Minibatch Loss= 0.6635, Training Accuracy= 0.595\n",
      "Epoch: 2070, Minibatch Loss= 0.6574, Training Accuracy= 0.609\n",
      "Epoch: 2080, Minibatch Loss= 0.6410, Training Accuracy= 0.623\n",
      "Epoch: 2090, Minibatch Loss= 0.6482, Training Accuracy= 0.615\n",
      "Epoch: 2100, Minibatch Loss= 0.7107, Training Accuracy= 0.559\n",
      "Epoch: 2110, Minibatch Loss= 0.6527, Training Accuracy= 0.613\n",
      "Epoch: 2120, Minibatch Loss= 0.6458, Training Accuracy= 0.615\n",
      "Epoch: 2130, Minibatch Loss= 0.6425, Training Accuracy= 0.624\n",
      "Epoch: 2140, Minibatch Loss= 0.6482, Training Accuracy= 0.612\n",
      "Epoch: 2150, Minibatch Loss= 0.6858, Training Accuracy= 0.585\n",
      "Epoch: 2160, Minibatch Loss= 0.6591, Training Accuracy= 0.610\n",
      "Epoch: 2170, Minibatch Loss= 0.6391, Training Accuracy= 0.628\n",
      "Epoch: 2180, Minibatch Loss= 0.6273, Training Accuracy= 0.638\n",
      "Epoch: 2190, Minibatch Loss= 0.6298, Training Accuracy= 0.642\n",
      "Epoch: 2200, Minibatch Loss= 0.6318, Training Accuracy= 0.632\n",
      "Epoch: 2210, Minibatch Loss= 0.6430, Training Accuracy= 0.625\n",
      "Epoch: 2220, Minibatch Loss= 0.6153, Training Accuracy= 0.657\n",
      "Epoch: 2230, Minibatch Loss= 0.6104, Training Accuracy= 0.662\n",
      "Epoch: 2240, Minibatch Loss= 0.6430, Training Accuracy= 0.628\n",
      "Epoch: 2250, Minibatch Loss= 0.6197, Training Accuracy= 0.646\n",
      "Epoch: 2260, Minibatch Loss= 0.6917, Training Accuracy= 0.559\n",
      "Epoch: 2270, Minibatch Loss= 0.6825, Training Accuracy= 0.591\n",
      "Epoch: 2280, Minibatch Loss= 0.6042, Training Accuracy= 0.665\n",
      "Epoch: 2290, Minibatch Loss= 0.5990, Training Accuracy= 0.671\n",
      "Epoch: 2300, Minibatch Loss= 0.5993, Training Accuracy= 0.668\n",
      "Epoch: 2310, Minibatch Loss= 0.6349, Training Accuracy= 0.634\n",
      "Epoch: 2320, Minibatch Loss= 0.6326, Training Accuracy= 0.639\n",
      "Epoch: 2330, Minibatch Loss= 0.6245, Training Accuracy= 0.641\n",
      "Epoch: 2340, Minibatch Loss= 0.5868, Training Accuracy= 0.684\n",
      "Epoch: 2350, Minibatch Loss= 0.6414, Training Accuracy= 0.636\n",
      "Epoch: 2360, Minibatch Loss= 0.5968, Training Accuracy= 0.674\n",
      "Epoch: 2370, Minibatch Loss= 0.6077, Training Accuracy= 0.664\n",
      "Epoch: 2380, Minibatch Loss= 0.6420, Training Accuracy= 0.630\n",
      "Epoch: 2390, Minibatch Loss= 0.6051, Training Accuracy= 0.669\n",
      "Epoch: 2400, Minibatch Loss= 0.5949, Training Accuracy= 0.682\n",
      "Epoch: 2410, Minibatch Loss= 0.5896, Training Accuracy= 0.684\n",
      "Epoch: 2420, Minibatch Loss= 0.5867, Training Accuracy= 0.682\n",
      "Epoch: 2430, Minibatch Loss= 0.5800, Training Accuracy= 0.690\n",
      "Epoch: 2440, Minibatch Loss= 0.5911, Training Accuracy= 0.680\n",
      "Epoch: 2450, Minibatch Loss= 0.5848, Training Accuracy= 0.683\n",
      "Epoch: 2460, Minibatch Loss= 0.6028, Training Accuracy= 0.671\n",
      "Epoch: 2470, Minibatch Loss= 0.5921, Training Accuracy= 0.678\n",
      "Epoch: 2480, Minibatch Loss= 0.6070, Training Accuracy= 0.662\n",
      "Epoch: 2490, Minibatch Loss= 0.6894, Training Accuracy= 0.547\n",
      "Epoch: 2500, Minibatch Loss= 0.6232, Training Accuracy= 0.648\n",
      "Epoch: 2510, Minibatch Loss= 0.5824, Training Accuracy= 0.687\n",
      "Epoch: 2520, Minibatch Loss= 0.5753, Training Accuracy= 0.692\n",
      "Epoch: 2530, Minibatch Loss= 0.5799, Training Accuracy= 0.690\n",
      "Epoch: 2540, Minibatch Loss= 0.5866, Training Accuracy= 0.684\n",
      "Epoch: 2550, Minibatch Loss= 0.5836, Training Accuracy= 0.688\n",
      "Epoch: 2560, Minibatch Loss= 0.7333, Training Accuracy= 0.546\n",
      "Epoch: 2570, Minibatch Loss= 0.5817, Training Accuracy= 0.687\n",
      "Epoch: 2580, Minibatch Loss= 0.5994, Training Accuracy= 0.669\n",
      "Epoch: 2590, Minibatch Loss= 0.6595, Training Accuracy= 0.607\n",
      "Epoch: 2600, Minibatch Loss= 0.5711, Training Accuracy= 0.697\n",
      "Epoch: 2610, Minibatch Loss= 0.6346, Training Accuracy= 0.644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2620, Minibatch Loss= 0.6203, Training Accuracy= 0.650\n",
      "Epoch: 2630, Minibatch Loss= 0.6127, Training Accuracy= 0.664\n",
      "Epoch: 2640, Minibatch Loss= 0.6159, Training Accuracy= 0.655\n",
      "Epoch: 2650, Minibatch Loss= 0.6219, Training Accuracy= 0.652\n",
      "Epoch: 2660, Minibatch Loss= 0.5844, Training Accuracy= 0.684\n",
      "Epoch: 2670, Minibatch Loss= 0.5781, Training Accuracy= 0.690\n",
      "Epoch: 2680, Minibatch Loss= 0.6002, Training Accuracy= 0.675\n",
      "Epoch: 2690, Minibatch Loss= 0.6121, Training Accuracy= 0.662\n",
      "Epoch: 2700, Minibatch Loss= 0.5780, Training Accuracy= 0.692\n",
      "Epoch: 2710, Minibatch Loss= 0.6240, Training Accuracy= 0.645\n",
      "Epoch: 2720, Minibatch Loss= 0.5885, Training Accuracy= 0.681\n",
      "Epoch: 2730, Minibatch Loss= 0.5803, Training Accuracy= 0.689\n",
      "Epoch: 2740, Minibatch Loss= 0.6636, Training Accuracy= 0.612\n",
      "Epoch: 2750, Minibatch Loss= 0.5601, Training Accuracy= 0.707\n",
      "Epoch: 2760, Minibatch Loss= 0.5907, Training Accuracy= 0.676\n",
      "Epoch: 2770, Minibatch Loss= 0.5913, Training Accuracy= 0.682\n",
      "Epoch: 2780, Minibatch Loss= 0.5747, Training Accuracy= 0.697\n",
      "Epoch: 2790, Minibatch Loss= 0.7477, Training Accuracy= 0.506\n",
      "Epoch: 2800, Minibatch Loss= 0.6844, Training Accuracy= 0.557\n",
      "Epoch: 2810, Minibatch Loss= 0.6758, Training Accuracy= 0.566\n",
      "Epoch: 2820, Minibatch Loss= 0.6700, Training Accuracy= 0.577\n",
      "Epoch: 2830, Minibatch Loss= 0.6647, Training Accuracy= 0.582\n",
      "Epoch: 2840, Minibatch Loss= 0.6601, Training Accuracy= 0.593\n",
      "Epoch: 2850, Minibatch Loss= 0.6613, Training Accuracy= 0.592\n",
      "Epoch: 2860, Minibatch Loss= 0.6531, Training Accuracy= 0.604\n",
      "Epoch: 2870, Minibatch Loss= 0.6575, Training Accuracy= 0.599\n",
      "Epoch: 2880, Minibatch Loss= 0.6524, Training Accuracy= 0.604\n",
      "Epoch: 2890, Minibatch Loss= 0.6486, Training Accuracy= 0.611\n",
      "Epoch: 2900, Minibatch Loss= 0.6574, Training Accuracy= 0.599\n",
      "Epoch: 2910, Minibatch Loss= 0.6589, Training Accuracy= 0.601\n",
      "Epoch: 2920, Minibatch Loss= 0.6608, Training Accuracy= 0.600\n",
      "Epoch: 2930, Minibatch Loss= 0.6387, Training Accuracy= 0.621\n",
      "Epoch: 2940, Minibatch Loss= 0.6968, Training Accuracy= 0.500\n",
      "Epoch: 2950, Minibatch Loss= 0.6930, Training Accuracy= 0.514\n",
      "Epoch: 2960, Minibatch Loss= 0.6923, Training Accuracy= 0.519\n",
      "Epoch: 2970, Minibatch Loss= 0.6918, Training Accuracy= 0.523\n",
      "Epoch: 2980, Minibatch Loss= 0.6914, Training Accuracy= 0.526\n",
      "Epoch: 2990, Minibatch Loss= 0.6911, Training Accuracy= 0.527\n",
      "Epoch: 3000, Minibatch Loss= 0.6912, Training Accuracy= 0.530\n",
      "Epoch: 3010, Minibatch Loss= 0.6905, Training Accuracy= 0.529\n",
      "Epoch: 3020, Minibatch Loss= 0.6900, Training Accuracy= 0.527\n",
      "Epoch: 3030, Minibatch Loss= 0.6897, Training Accuracy= 0.530\n",
      "Epoch: 3040, Minibatch Loss= 0.6892, Training Accuracy= 0.532\n",
      "Epoch: 3050, Minibatch Loss= 0.6892, Training Accuracy= 0.534\n",
      "Epoch: 3060, Minibatch Loss= 0.6890, Training Accuracy= 0.531\n",
      "Epoch: 3070, Minibatch Loss= 0.6887, Training Accuracy= 0.532\n",
      "Epoch: 3080, Minibatch Loss= 0.6962, Training Accuracy= 0.510\n",
      "Epoch: 3090, Minibatch Loss= 0.6926, Training Accuracy= 0.515\n",
      "Epoch: 3100, Minibatch Loss= 0.6918, Training Accuracy= 0.520\n",
      "Epoch: 3110, Minibatch Loss= 0.6914, Training Accuracy= 0.520\n",
      "Epoch: 3120, Minibatch Loss= 0.6910, Training Accuracy= 0.522\n",
      "Epoch: 3130, Minibatch Loss= 0.6906, Training Accuracy= 0.521\n",
      "Epoch: 3140, Minibatch Loss= 0.6903, Training Accuracy= 0.521\n",
      "Epoch: 3150, Minibatch Loss= 0.6899, Training Accuracy= 0.522\n",
      "Epoch: 3160, Minibatch Loss= 0.6903, Training Accuracy= 0.521\n",
      "Epoch: 3170, Minibatch Loss= 0.6894, Training Accuracy= 0.522\n",
      "Epoch: 3180, Minibatch Loss= 0.6887, Training Accuracy= 0.523\n",
      "Epoch: 3190, Minibatch Loss= 0.6884, Training Accuracy= 0.525\n",
      "Epoch: 3200, Minibatch Loss= 0.6886, Training Accuracy= 0.527\n",
      "Epoch: 3210, Minibatch Loss= 0.6878, Training Accuracy= 0.529\n",
      "Epoch: 3220, Minibatch Loss= 0.6878, Training Accuracy= 0.529\n",
      "Epoch: 3230, Minibatch Loss= 0.6882, Training Accuracy= 0.533\n",
      "Epoch: 3240, Minibatch Loss= 0.6870, Training Accuracy= 0.537\n",
      "Epoch: 3250, Minibatch Loss= 0.6881, Training Accuracy= 0.533\n",
      "Epoch: 3260, Minibatch Loss= 0.6885, Training Accuracy= 0.537\n",
      "Epoch: 3270, Minibatch Loss= 0.6874, Training Accuracy= 0.538\n",
      "Epoch: 3280, Minibatch Loss= 0.6867, Training Accuracy= 0.540\n",
      "Epoch: 3290, Minibatch Loss= 0.6887, Training Accuracy= 0.537\n",
      "Epoch: 3300, Minibatch Loss= 0.6871, Training Accuracy= 0.542\n",
      "Epoch: 3310, Minibatch Loss= 0.6859, Training Accuracy= 0.547\n",
      "Epoch: 3320, Minibatch Loss= 0.6851, Training Accuracy= 0.547\n",
      "Epoch: 3330, Minibatch Loss= 0.6843, Training Accuracy= 0.547\n",
      "Epoch: 3340, Minibatch Loss= 0.6917, Training Accuracy= 0.520\n",
      "Epoch: 3350, Minibatch Loss= 0.6871, Training Accuracy= 0.539\n",
      "Epoch: 3360, Minibatch Loss= 0.6841, Training Accuracy= 0.549\n",
      "Epoch: 3370, Minibatch Loss= 0.6825, Training Accuracy= 0.550\n",
      "Epoch: 3380, Minibatch Loss= 0.6855, Training Accuracy= 0.551\n",
      "Epoch: 3390, Minibatch Loss= 0.6891, Training Accuracy= 0.532\n",
      "Epoch: 3400, Minibatch Loss= 0.6881, Training Accuracy= 0.536\n",
      "Epoch: 3410, Minibatch Loss= 0.6881, Training Accuracy= 0.535\n",
      "Epoch: 3420, Minibatch Loss= 0.6857, Training Accuracy= 0.544\n",
      "Epoch: 3430, Minibatch Loss= 0.6864, Training Accuracy= 0.541\n",
      "Epoch: 3440, Minibatch Loss= 0.6851, Training Accuracy= 0.547\n",
      "Epoch: 3450, Minibatch Loss= 0.6838, Training Accuracy= 0.547\n",
      "Epoch: 3460, Minibatch Loss= 0.6840, Training Accuracy= 0.556\n",
      "Epoch: 3470, Minibatch Loss= 0.6814, Training Accuracy= 0.560\n",
      "Epoch: 3480, Minibatch Loss= 0.6815, Training Accuracy= 0.561\n",
      "Epoch: 3490, Minibatch Loss= 0.6899, Training Accuracy= 0.533\n",
      "Epoch: 3500, Minibatch Loss= 0.6851, Training Accuracy= 0.551\n",
      "Epoch: 3510, Minibatch Loss= 0.6895, Training Accuracy= 0.533\n",
      "Epoch: 3520, Minibatch Loss= 0.6879, Training Accuracy= 0.538\n",
      "Epoch: 3530, Minibatch Loss= 0.6872, Training Accuracy= 0.541\n",
      "Epoch: 3540, Minibatch Loss= 0.6863, Training Accuracy= 0.542\n",
      "Epoch: 3550, Minibatch Loss= 0.6857, Training Accuracy= 0.546\n",
      "Epoch: 3560, Minibatch Loss= 0.6848, Training Accuracy= 0.549\n",
      "Epoch: 3570, Minibatch Loss= 0.6968, Training Accuracy= 0.506\n",
      "Epoch: 3580, Minibatch Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 3590, Minibatch Loss= 0.6924, Training Accuracy= 0.512\n",
      "Epoch: 3600, Minibatch Loss= 0.6922, Training Accuracy= 0.516\n",
      "Epoch: 3610, Minibatch Loss= 0.6920, Training Accuracy= 0.518\n",
      "Epoch: 3620, Minibatch Loss= 0.6918, Training Accuracy= 0.520\n",
      "Epoch: 3630, Minibatch Loss= 0.6916, Training Accuracy= 0.519\n",
      "Epoch: 3640, Minibatch Loss= 0.6914, Training Accuracy= 0.518\n",
      "Epoch: 3650, Minibatch Loss= 0.6912, Training Accuracy= 0.521\n",
      "Epoch: 3660, Minibatch Loss= 0.6910, Training Accuracy= 0.521\n",
      "Epoch: 3670, Minibatch Loss= 0.6909, Training Accuracy= 0.523\n",
      "Epoch: 3680, Minibatch Loss= 0.6908, Training Accuracy= 0.525\n",
      "Epoch: 3690, Minibatch Loss= 0.6907, Training Accuracy= 0.524\n",
      "Epoch: 3700, Minibatch Loss= 0.6906, Training Accuracy= 0.523\n",
      "Epoch: 3710, Minibatch Loss= 0.6905, Training Accuracy= 0.525\n",
      "Epoch: 3720, Minibatch Loss= 0.6904, Training Accuracy= 0.524\n",
      "Epoch: 3730, Minibatch Loss= 0.6903, Training Accuracy= 0.525\n",
      "Epoch: 3740, Minibatch Loss= 0.6902, Training Accuracy= 0.526\n",
      "Epoch: 3750, Minibatch Loss= 0.6902, Training Accuracy= 0.528\n",
      "Epoch: 3760, Minibatch Loss= 0.6901, Training Accuracy= 0.527\n",
      "Epoch: 3770, Minibatch Loss= 0.6900, Training Accuracy= 0.527\n",
      "Epoch: 3780, Minibatch Loss= 0.6899, Training Accuracy= 0.529\n",
      "Epoch: 3790, Minibatch Loss= 0.6899, Training Accuracy= 0.530\n",
      "Epoch: 3800, Minibatch Loss= 0.6898, Training Accuracy= 0.531\n",
      "Epoch: 3810, Minibatch Loss= 0.6897, Training Accuracy= 0.530\n",
      "Epoch: 3820, Minibatch Loss= 0.6896, Training Accuracy= 0.531\n",
      "Epoch: 3830, Minibatch Loss= 0.6895, Training Accuracy= 0.532\n",
      "Epoch: 3840, Minibatch Loss= 0.6895, Training Accuracy= 0.531\n",
      "Epoch: 3850, Minibatch Loss= 0.6894, Training Accuracy= 0.532\n",
      "Epoch: 3860, Minibatch Loss= 0.6893, Training Accuracy= 0.532\n",
      "Epoch: 3870, Minibatch Loss= 0.6892, Training Accuracy= 0.532\n",
      "Epoch: 3880, Minibatch Loss= 0.6892, Training Accuracy= 0.532\n",
      "Epoch: 3890, Minibatch Loss= 0.6891, Training Accuracy= 0.532\n",
      "Epoch: 3900, Minibatch Loss= 0.6890, Training Accuracy= 0.532\n",
      "Epoch: 3910, Minibatch Loss= 0.6889, Training Accuracy= 0.531\n",
      "Epoch: 3920, Minibatch Loss= 0.6888, Training Accuracy= 0.533\n",
      "Epoch: 3930, Minibatch Loss= 0.6888, Training Accuracy= 0.533\n",
      "Epoch: 3940, Minibatch Loss= 0.6887, Training Accuracy= 0.532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3950, Minibatch Loss= 0.6886, Training Accuracy= 0.532\n",
      "Epoch: 3960, Minibatch Loss= 0.6885, Training Accuracy= 0.533\n",
      "Epoch: 3970, Minibatch Loss= 0.6884, Training Accuracy= 0.532\n",
      "Epoch: 3980, Minibatch Loss= 0.6882, Training Accuracy= 0.534\n",
      "Epoch: 3990, Minibatch Loss= 0.6881, Training Accuracy= 0.534\n",
      "Epoch: 4000, Minibatch Loss= 0.6880, Training Accuracy= 0.535\n",
      "Epoch: 4010, Minibatch Loss= 0.6879, Training Accuracy= 0.534\n",
      "Epoch: 4020, Minibatch Loss= 0.6877, Training Accuracy= 0.536\n",
      "Epoch: 4030, Minibatch Loss= 0.6875, Training Accuracy= 0.537\n",
      "Epoch: 4040, Minibatch Loss= 0.6873, Training Accuracy= 0.539\n",
      "Epoch: 4050, Minibatch Loss= 0.6872, Training Accuracy= 0.540\n",
      "Epoch: 4060, Minibatch Loss= 0.6870, Training Accuracy= 0.542\n",
      "Epoch: 4070, Minibatch Loss= 0.6868, Training Accuracy= 0.542\n",
      "Epoch: 4080, Minibatch Loss= 0.6866, Training Accuracy= 0.544\n",
      "Epoch: 4090, Minibatch Loss= 0.6865, Training Accuracy= 0.543\n",
      "Epoch: 4100, Minibatch Loss= 0.6863, Training Accuracy= 0.544\n",
      "Epoch: 4110, Minibatch Loss= 0.6862, Training Accuracy= 0.544\n",
      "Epoch: 4120, Minibatch Loss= 0.6860, Training Accuracy= 0.544\n",
      "Epoch: 4130, Minibatch Loss= 0.6859, Training Accuracy= 0.543\n",
      "Epoch: 4140, Minibatch Loss= 0.6857, Training Accuracy= 0.543\n",
      "Epoch: 4150, Minibatch Loss= 0.6855, Training Accuracy= 0.545\n",
      "Epoch: 4160, Minibatch Loss= 0.6854, Training Accuracy= 0.546\n",
      "Epoch: 4170, Minibatch Loss= 0.6852, Training Accuracy= 0.547\n",
      "Epoch: 4180, Minibatch Loss= 0.6851, Training Accuracy= 0.547\n",
      "Epoch: 4190, Minibatch Loss= 0.6849, Training Accuracy= 0.549\n",
      "Epoch: 4200, Minibatch Loss= 0.6847, Training Accuracy= 0.548\n",
      "Epoch: 4210, Minibatch Loss= 0.6846, Training Accuracy= 0.549\n",
      "Epoch: 4220, Minibatch Loss= 0.6845, Training Accuracy= 0.548\n",
      "Epoch: 4230, Minibatch Loss= 0.6844, Training Accuracy= 0.548\n",
      "Epoch: 4240, Minibatch Loss= 0.6843, Training Accuracy= 0.548\n",
      "Epoch: 4250, Minibatch Loss= 0.6842, Training Accuracy= 0.549\n",
      "Epoch: 4260, Minibatch Loss= 0.6840, Training Accuracy= 0.551\n",
      "Epoch: 4270, Minibatch Loss= 0.6838, Training Accuracy= 0.552\n",
      "Epoch: 4280, Minibatch Loss= 0.6836, Training Accuracy= 0.551\n",
      "Epoch: 4290, Minibatch Loss= 0.6835, Training Accuracy= 0.552\n",
      "Epoch: 4300, Minibatch Loss= 0.6835, Training Accuracy= 0.554\n",
      "Epoch: 4310, Minibatch Loss= 0.6832, Training Accuracy= 0.556\n",
      "Epoch: 4320, Minibatch Loss= 0.6830, Training Accuracy= 0.558\n",
      "Epoch: 4330, Minibatch Loss= 0.6827, Training Accuracy= 0.557\n",
      "Epoch: 4340, Minibatch Loss= 0.6826, Training Accuracy= 0.558\n",
      "Epoch: 4350, Minibatch Loss= 0.6824, Training Accuracy= 0.558\n",
      "Epoch: 4360, Minibatch Loss= 0.6822, Training Accuracy= 0.558\n",
      "Epoch: 4370, Minibatch Loss= 0.6816, Training Accuracy= 0.559\n",
      "Epoch: 4380, Minibatch Loss= 0.6823, Training Accuracy= 0.558\n",
      "Epoch: 4390, Minibatch Loss= 0.6808, Training Accuracy= 0.558\n",
      "Epoch: 4400, Minibatch Loss= 0.6802, Training Accuracy= 0.561\n",
      "Epoch: 4410, Minibatch Loss= 0.6804, Training Accuracy= 0.560\n",
      "Epoch: 4420, Minibatch Loss= 0.6812, Training Accuracy= 0.560\n",
      "Epoch: 4430, Minibatch Loss= 0.6808, Training Accuracy= 0.561\n",
      "Epoch: 4440, Minibatch Loss= 0.6799, Training Accuracy= 0.558\n",
      "Epoch: 4450, Minibatch Loss= 0.6807, Training Accuracy= 0.561\n",
      "Epoch: 4460, Minibatch Loss= 0.6790, Training Accuracy= 0.561\n",
      "Epoch: 4470, Minibatch Loss= 0.6780, Training Accuracy= 0.563\n",
      "Epoch: 4480, Minibatch Loss= 0.6799, Training Accuracy= 0.560\n",
      "Epoch: 4490, Minibatch Loss= 0.6789, Training Accuracy= 0.562\n",
      "Epoch: 4500, Minibatch Loss= 0.6787, Training Accuracy= 0.563\n",
      "Epoch: 4510, Minibatch Loss= 0.6806, Training Accuracy= 0.553\n",
      "Epoch: 4520, Minibatch Loss= 0.6784, Training Accuracy= 0.561\n",
      "Epoch: 4530, Minibatch Loss= 0.6769, Training Accuracy= 0.567\n",
      "Epoch: 4540, Minibatch Loss= 0.6815, Training Accuracy= 0.560\n",
      "Epoch: 4550, Minibatch Loss= 0.6785, Training Accuracy= 0.560\n",
      "Epoch: 4560, Minibatch Loss= 0.6774, Training Accuracy= 0.563\n",
      "Epoch: 4570, Minibatch Loss= 0.6755, Training Accuracy= 0.566\n",
      "Epoch: 4580, Minibatch Loss= 0.6744, Training Accuracy= 0.568\n",
      "Epoch: 4590, Minibatch Loss= 0.6761, Training Accuracy= 0.566\n",
      "Epoch: 4600, Minibatch Loss= 0.6749, Training Accuracy= 0.569\n",
      "Epoch: 4610, Minibatch Loss= 0.6894, Training Accuracy= 0.544\n",
      "Epoch: 4620, Minibatch Loss= 0.6771, Training Accuracy= 0.561\n",
      "Epoch: 4630, Minibatch Loss= 0.6739, Training Accuracy= 0.567\n",
      "Epoch: 4640, Minibatch Loss= 0.6755, Training Accuracy= 0.568\n",
      "Epoch: 4650, Minibatch Loss= 0.6969, Training Accuracy= 0.513\n",
      "Epoch: 4660, Minibatch Loss= 0.6943, Training Accuracy= 0.497\n",
      "Epoch: 4670, Minibatch Loss= 0.6931, Training Accuracy= 0.505\n",
      "Epoch: 4680, Minibatch Loss= 0.6921, Training Accuracy= 0.507\n",
      "Epoch: 4690, Minibatch Loss= 0.6915, Training Accuracy= 0.512\n",
      "Epoch: 4700, Minibatch Loss= 0.6911, Training Accuracy= 0.524\n",
      "Epoch: 4710, Minibatch Loss= 0.6912, Training Accuracy= 0.512\n",
      "Epoch: 4720, Minibatch Loss= 0.6970, Training Accuracy= 0.500\n",
      "Epoch: 4730, Minibatch Loss= 0.6952, Training Accuracy= 0.509\n",
      "Epoch: 4740, Minibatch Loss= 0.6939, Training Accuracy= 0.513\n",
      "Epoch: 4750, Minibatch Loss= 0.6932, Training Accuracy= 0.514\n",
      "Epoch: 4760, Minibatch Loss= 0.6937, Training Accuracy= 0.515\n",
      "Epoch: 4770, Minibatch Loss= 0.6929, Training Accuracy= 0.520\n",
      "Epoch: 4780, Minibatch Loss= 0.6923, Training Accuracy= 0.521\n",
      "Epoch: 4790, Minibatch Loss= 0.6918, Training Accuracy= 0.522\n",
      "Epoch: 4800, Minibatch Loss= 0.6916, Training Accuracy= 0.521\n",
      "Epoch: 4810, Minibatch Loss= 0.6917, Training Accuracy= 0.516\n",
      "Epoch: 4820, Minibatch Loss= 0.6911, Training Accuracy= 0.520\n",
      "Epoch: 4830, Minibatch Loss= 0.6917, Training Accuracy= 0.522\n",
      "Epoch: 4840, Minibatch Loss= 0.6911, Training Accuracy= 0.520\n",
      "Epoch: 4850, Minibatch Loss= 0.6941, Training Accuracy= 0.513\n",
      "Epoch: 4860, Minibatch Loss= 0.6899, Training Accuracy= 0.521\n",
      "Epoch: 4870, Minibatch Loss= 0.6905, Training Accuracy= 0.518\n",
      "Epoch: 4880, Minibatch Loss= 0.6900, Training Accuracy= 0.522\n",
      "Epoch: 4890, Minibatch Loss= 0.6899, Training Accuracy= 0.522\n",
      "Epoch: 4900, Minibatch Loss= 0.6899, Training Accuracy= 0.525\n",
      "Epoch: 4910, Minibatch Loss= 0.6949, Training Accuracy= 0.507\n",
      "Epoch: 4920, Minibatch Loss= 0.6902, Training Accuracy= 0.524\n",
      "Epoch: 4930, Minibatch Loss= 0.6907, Training Accuracy= 0.522\n",
      "Epoch: 4940, Minibatch Loss= 0.6907, Training Accuracy= 0.526\n",
      "Epoch: 4950, Minibatch Loss= 0.6884, Training Accuracy= 0.534\n",
      "Epoch: 4960, Minibatch Loss= 0.6950, Training Accuracy= 0.522\n",
      "Epoch: 4970, Minibatch Loss= 0.6915, Training Accuracy= 0.526\n",
      "Epoch: 4980, Minibatch Loss= 0.6904, Training Accuracy= 0.529\n",
      "Epoch: 4990, Minibatch Loss= 0.6886, Training Accuracy= 0.532\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4999\n",
      "Replication: 5: \n",
      "Epoch: 0, Minibatch Loss= 0.7313, Training Accuracy= 0.498\n",
      "Epoch: 10, Minibatch Loss= 0.7058, Training Accuracy= 0.498\n",
      "Epoch: 20, Minibatch Loss= 0.7011, Training Accuracy= 0.498\n",
      "Epoch: 30, Minibatch Loss= 0.6991, Training Accuracy= 0.498\n",
      "Epoch: 40, Minibatch Loss= 0.6979, Training Accuracy= 0.498\n",
      "Epoch: 50, Minibatch Loss= 0.6972, Training Accuracy= 0.498\n",
      "Epoch: 60, Minibatch Loss= 0.6966, Training Accuracy= 0.498\n",
      "Epoch: 70, Minibatch Loss= 0.6962, Training Accuracy= 0.498\n",
      "Epoch: 80, Minibatch Loss= 0.6959, Training Accuracy= 0.498\n",
      "Epoch: 90, Minibatch Loss= 0.6957, Training Accuracy= 0.498\n",
      "Epoch: 100, Minibatch Loss= 0.6955, Training Accuracy= 0.498\n",
      "Epoch: 110, Minibatch Loss= 0.6954, Training Accuracy= 0.498\n",
      "Epoch: 120, Minibatch Loss= 0.6952, Training Accuracy= 0.498\n",
      "Epoch: 130, Minibatch Loss= 0.6951, Training Accuracy= 0.498\n",
      "Epoch: 140, Minibatch Loss= 0.6950, Training Accuracy= 0.498\n",
      "Epoch: 150, Minibatch Loss= 0.6949, Training Accuracy= 0.498\n",
      "Epoch: 160, Minibatch Loss= 0.6948, Training Accuracy= 0.498\n",
      "Epoch: 170, Minibatch Loss= 0.6948, Training Accuracy= 0.498\n",
      "Epoch: 180, Minibatch Loss= 0.6947, Training Accuracy= 0.498\n",
      "Epoch: 190, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 200, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 210, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 220, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 230, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 240, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 250, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n",
      "Epoch: 260, Minibatch Loss= 0.6944, Training Accuracy= 0.498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 270, Minibatch Loss= 0.6943, Training Accuracy= 0.498\n",
      "Epoch: 280, Minibatch Loss= 0.6943, Training Accuracy= 0.498\n",
      "Epoch: 290, Minibatch Loss= 0.6943, Training Accuracy= 0.498\n",
      "Epoch: 300, Minibatch Loss= 0.6943, Training Accuracy= 0.498\n",
      "Epoch: 310, Minibatch Loss= 0.6942, Training Accuracy= 0.498\n",
      "Epoch: 320, Minibatch Loss= 0.6942, Training Accuracy= 0.498\n",
      "Epoch: 330, Minibatch Loss= 0.6942, Training Accuracy= 0.498\n",
      "Epoch: 340, Minibatch Loss= 0.6942, Training Accuracy= 0.498\n",
      "Epoch: 350, Minibatch Loss= 0.6942, Training Accuracy= 0.498\n",
      "Epoch: 360, Minibatch Loss= 0.6941, Training Accuracy= 0.498\n",
      "Epoch: 370, Minibatch Loss= 0.6941, Training Accuracy= 0.498\n",
      "Epoch: 380, Minibatch Loss= 0.6942, Training Accuracy= 0.498\n",
      "Epoch: 390, Minibatch Loss= 0.6943, Training Accuracy= 0.498\n",
      "Epoch: 400, Minibatch Loss= 0.6945, Training Accuracy= 0.498\n",
      "Epoch: 410, Minibatch Loss= 0.6946, Training Accuracy= 0.499\n",
      "Epoch: 420, Minibatch Loss= 0.6946, Training Accuracy= 0.499\n",
      "Epoch: 430, Minibatch Loss= 0.6946, Training Accuracy= 0.499\n",
      "Epoch: 440, Minibatch Loss= 0.6945, Training Accuracy= 0.499\n",
      "Epoch: 450, Minibatch Loss= 0.6945, Training Accuracy= 0.499\n",
      "Epoch: 460, Minibatch Loss= 0.6944, Training Accuracy= 0.500\n",
      "Epoch: 470, Minibatch Loss= 0.6944, Training Accuracy= 0.501\n",
      "Epoch: 480, Minibatch Loss= 0.6943, Training Accuracy= 0.501\n",
      "Epoch: 490, Minibatch Loss= 0.6943, Training Accuracy= 0.501\n",
      "Epoch: 500, Minibatch Loss= 0.6942, Training Accuracy= 0.501\n",
      "Epoch: 510, Minibatch Loss= 0.6942, Training Accuracy= 0.501\n",
      "Epoch: 520, Minibatch Loss= 0.6942, Training Accuracy= 0.500\n",
      "Epoch: 530, Minibatch Loss= 0.6942, Training Accuracy= 0.500\n",
      "Epoch: 540, Minibatch Loss= 0.6942, Training Accuracy= 0.500\n",
      "Epoch: 550, Minibatch Loss= 0.6943, Training Accuracy= 0.501\n",
      "Epoch: 560, Minibatch Loss= 0.6944, Training Accuracy= 0.501\n",
      "Epoch: 570, Minibatch Loss= 0.6947, Training Accuracy= 0.501\n",
      "Epoch: 580, Minibatch Loss= 0.6947, Training Accuracy= 0.499\n",
      "Epoch: 590, Minibatch Loss= 0.6942, Training Accuracy= 0.501\n",
      "Epoch: 600, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 610, Minibatch Loss= 0.6943, Training Accuracy= 0.505\n",
      "Epoch: 620, Minibatch Loss= 0.6943, Training Accuracy= 0.509\n",
      "Epoch: 630, Minibatch Loss= 0.6942, Training Accuracy= 0.512\n",
      "Epoch: 640, Minibatch Loss= 0.6945, Training Accuracy= 0.512\n",
      "Epoch: 650, Minibatch Loss= 0.6946, Training Accuracy= 0.513\n",
      "Epoch: 660, Minibatch Loss= 0.6948, Training Accuracy= 0.514\n",
      "Epoch: 670, Minibatch Loss= 0.6947, Training Accuracy= 0.515\n",
      "Epoch: 680, Minibatch Loss= 0.6944, Training Accuracy= 0.513\n",
      "Epoch: 690, Minibatch Loss= 0.6943, Training Accuracy= 0.510\n",
      "Epoch: 700, Minibatch Loss= 0.6941, Training Accuracy= 0.510\n",
      "Epoch: 710, Minibatch Loss= 0.6939, Training Accuracy= 0.508\n",
      "Epoch: 720, Minibatch Loss= 0.6939, Training Accuracy= 0.511\n",
      "Epoch: 730, Minibatch Loss= 0.6940, Training Accuracy= 0.512\n",
      "Epoch: 740, Minibatch Loss= 0.6945, Training Accuracy= 0.511\n",
      "Epoch: 750, Minibatch Loss= 0.6944, Training Accuracy= 0.513\n",
      "Epoch: 760, Minibatch Loss= 0.6947, Training Accuracy= 0.512\n",
      "Epoch: 770, Minibatch Loss= 0.6950, Training Accuracy= 0.507\n",
      "Epoch: 780, Minibatch Loss= 0.6934, Training Accuracy= 0.519\n",
      "Epoch: 790, Minibatch Loss= 0.6955, Training Accuracy= 0.499\n",
      "Epoch: 800, Minibatch Loss= 0.6952, Training Accuracy= 0.499\n",
      "Epoch: 810, Minibatch Loss= 0.6949, Training Accuracy= 0.499\n",
      "Epoch: 820, Minibatch Loss= 0.6947, Training Accuracy= 0.499\n",
      "Epoch: 830, Minibatch Loss= 0.6946, Training Accuracy= 0.498\n",
      "Epoch: 840, Minibatch Loss= 0.6945, Training Accuracy= 0.499\n",
      "Epoch: 850, Minibatch Loss= 0.6945, Training Accuracy= 0.499\n",
      "Epoch: 860, Minibatch Loss= 0.6946, Training Accuracy= 0.500\n",
      "Epoch: 870, Minibatch Loss= 0.6948, Training Accuracy= 0.500\n",
      "Epoch: 880, Minibatch Loss= 0.6945, Training Accuracy= 0.502\n",
      "Epoch: 890, Minibatch Loss= 0.6946, Training Accuracy= 0.500\n",
      "Epoch: 900, Minibatch Loss= 0.6947, Training Accuracy= 0.500\n",
      "Epoch: 910, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 920, Minibatch Loss= 0.6949, Training Accuracy= 0.500\n",
      "Epoch: 930, Minibatch Loss= 0.7003, Training Accuracy= 0.498\n",
      "Epoch: 940, Minibatch Loss= 0.6984, Training Accuracy= 0.498\n",
      "Epoch: 950, Minibatch Loss= 0.6972, Training Accuracy= 0.498\n",
      "Epoch: 960, Minibatch Loss= 0.6964, Training Accuracy= 0.498\n",
      "Epoch: 970, Minibatch Loss= 0.6959, Training Accuracy= 0.498\n",
      "Epoch: 980, Minibatch Loss= 0.6955, Training Accuracy= 0.498\n",
      "Epoch: 990, Minibatch Loss= 0.6953, Training Accuracy= 0.498\n",
      "Epoch: 1000, Minibatch Loss= 0.6951, Training Accuracy= 0.498\n",
      "Epoch: 1010, Minibatch Loss= 0.6949, Training Accuracy= 0.498\n",
      "Epoch: 1020, Minibatch Loss= 0.6948, Training Accuracy= 0.498\n",
      "Epoch: 1030, Minibatch Loss= 0.6946, Training Accuracy= 0.499\n",
      "Epoch: 1040, Minibatch Loss= 0.6945, Training Accuracy= 0.501\n",
      "Epoch: 1050, Minibatch Loss= 0.6943, Training Accuracy= 0.503\n",
      "Epoch: 1060, Minibatch Loss= 0.6941, Training Accuracy= 0.505\n",
      "Epoch: 1070, Minibatch Loss= 0.6940, Training Accuracy= 0.507\n",
      "Epoch: 1080, Minibatch Loss= 0.6938, Training Accuracy= 0.510\n",
      "Epoch: 1090, Minibatch Loss= 0.6936, Training Accuracy= 0.510\n",
      "Epoch: 1100, Minibatch Loss= 0.6934, Training Accuracy= 0.513\n",
      "Epoch: 1110, Minibatch Loss= 0.6932, Training Accuracy= 0.512\n",
      "Epoch: 1120, Minibatch Loss= 0.6931, Training Accuracy= 0.512\n",
      "Epoch: 1130, Minibatch Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 1140, Minibatch Loss= 0.6932, Training Accuracy= 0.513\n",
      "Epoch: 1150, Minibatch Loss= 0.6932, Training Accuracy= 0.514\n",
      "Epoch: 1160, Minibatch Loss= 0.6932, Training Accuracy= 0.516\n",
      "Epoch: 1170, Minibatch Loss= 0.6933, Training Accuracy= 0.516\n",
      "Epoch: 1180, Minibatch Loss= 0.6934, Training Accuracy= 0.518\n",
      "Epoch: 1190, Minibatch Loss= 0.6934, Training Accuracy= 0.520\n",
      "Epoch: 1200, Minibatch Loss= 0.6942, Training Accuracy= 0.516\n",
      "Epoch: 1210, Minibatch Loss= 0.6925, Training Accuracy= 0.527\n",
      "Epoch: 1220, Minibatch Loss= 0.6916, Training Accuracy= 0.527\n",
      "Epoch: 1230, Minibatch Loss= 0.6916, Training Accuracy= 0.527\n",
      "Epoch: 1240, Minibatch Loss= 0.6925, Training Accuracy= 0.522\n",
      "Epoch: 1250, Minibatch Loss= 0.6904, Training Accuracy= 0.529\n",
      "Epoch: 1260, Minibatch Loss= 0.6924, Training Accuracy= 0.522\n",
      "Epoch: 1270, Minibatch Loss= 0.6902, Training Accuracy= 0.528\n",
      "Epoch: 1280, Minibatch Loss= 0.6934, Training Accuracy= 0.522\n",
      "Epoch: 1290, Minibatch Loss= 0.6896, Training Accuracy= 0.534\n",
      "Epoch: 1300, Minibatch Loss= 0.7086, Training Accuracy= 0.499\n",
      "Epoch: 1310, Minibatch Loss= 0.7051, Training Accuracy= 0.499\n",
      "Epoch: 1320, Minibatch Loss= 0.7031, Training Accuracy= 0.499\n",
      "Epoch: 1330, Minibatch Loss= 0.7017, Training Accuracy= 0.499\n",
      "Epoch: 1340, Minibatch Loss= 0.7006, Training Accuracy= 0.499\n",
      "Epoch: 1350, Minibatch Loss= 0.6997, Training Accuracy= 0.499\n",
      "Epoch: 1360, Minibatch Loss= 0.6990, Training Accuracy= 0.499\n",
      "Epoch: 1370, Minibatch Loss= 0.6983, Training Accuracy= 0.500\n",
      "Epoch: 1380, Minibatch Loss= 0.6977, Training Accuracy= 0.499\n",
      "Epoch: 1390, Minibatch Loss= 0.6975, Training Accuracy= 0.499\n",
      "Epoch: 1400, Minibatch Loss= 0.6969, Training Accuracy= 0.502\n",
      "Epoch: 1410, Minibatch Loss= 0.6964, Training Accuracy= 0.501\n",
      "Epoch: 1420, Minibatch Loss= 0.6962, Training Accuracy= 0.500\n",
      "Epoch: 1430, Minibatch Loss= 0.6961, Training Accuracy= 0.501\n",
      "Epoch: 1440, Minibatch Loss= 0.6957, Training Accuracy= 0.502\n",
      "Epoch: 1450, Minibatch Loss= 0.6956, Training Accuracy= 0.503\n",
      "Epoch: 1460, Minibatch Loss= 0.6956, Training Accuracy= 0.504\n",
      "Epoch: 1470, Minibatch Loss= 0.6960, Training Accuracy= 0.502\n",
      "Epoch: 1480, Minibatch Loss= 0.6979, Training Accuracy= 0.507\n",
      "Epoch: 1490, Minibatch Loss= 0.6957, Training Accuracy= 0.503\n",
      "Epoch: 1500, Minibatch Loss= 0.6956, Training Accuracy= 0.504\n",
      "Epoch: 1510, Minibatch Loss= 0.6950, Training Accuracy= 0.504\n",
      "Epoch: 1520, Minibatch Loss= 0.7017, Training Accuracy= 0.498\n",
      "Epoch: 1530, Minibatch Loss= 0.7000, Training Accuracy= 0.498\n",
      "Epoch: 1540, Minibatch Loss= 0.6990, Training Accuracy= 0.498\n",
      "Epoch: 1550, Minibatch Loss= 0.6981, Training Accuracy= 0.498\n",
      "Epoch: 1560, Minibatch Loss= 0.6976, Training Accuracy= 0.499\n",
      "Epoch: 1570, Minibatch Loss= 0.6943, Training Accuracy= 0.505\n",
      "Epoch: 1580, Minibatch Loss= 0.6941, Training Accuracy= 0.506\n",
      "Epoch: 1590, Minibatch Loss= 0.6940, Training Accuracy= 0.511\n",
      "Epoch: 1600, Minibatch Loss= 0.6942, Training Accuracy= 0.510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1610, Minibatch Loss= 0.6942, Training Accuracy= 0.510\n",
      "Epoch: 1620, Minibatch Loss= 0.6939, Training Accuracy= 0.513\n",
      "Epoch: 1630, Minibatch Loss= 0.6941, Training Accuracy= 0.512\n",
      "Epoch: 1640, Minibatch Loss= 0.6934, Training Accuracy= 0.514\n",
      "Epoch: 1650, Minibatch Loss= 0.6935, Training Accuracy= 0.514\n",
      "Epoch: 1660, Minibatch Loss= 0.6936, Training Accuracy= 0.514\n",
      "Epoch: 1670, Minibatch Loss= 0.6931, Training Accuracy= 0.515\n",
      "Epoch: 1680, Minibatch Loss= 0.6936, Training Accuracy= 0.515\n",
      "Epoch: 1690, Minibatch Loss= 0.6926, Training Accuracy= 0.516\n",
      "Epoch: 1700, Minibatch Loss= 0.6934, Training Accuracy= 0.514\n",
      "Epoch: 1710, Minibatch Loss= 0.6944, Training Accuracy= 0.515\n",
      "Epoch: 1720, Minibatch Loss= 0.6977, Training Accuracy= 0.502\n",
      "Epoch: 1730, Minibatch Loss= 0.6954, Training Accuracy= 0.509\n",
      "Epoch: 1740, Minibatch Loss= 0.6944, Training Accuracy= 0.518\n",
      "Epoch: 1750, Minibatch Loss= 0.6940, Training Accuracy= 0.520\n",
      "Epoch: 1760, Minibatch Loss= 0.6937, Training Accuracy= 0.520\n",
      "Epoch: 1770, Minibatch Loss= 0.6930, Training Accuracy= 0.525\n",
      "Epoch: 1780, Minibatch Loss= 0.6934, Training Accuracy= 0.528\n",
      "Epoch: 1790, Minibatch Loss= 0.6940, Training Accuracy= 0.527\n",
      "Epoch: 1800, Minibatch Loss= 0.6942, Training Accuracy= 0.525\n",
      "Epoch: 1810, Minibatch Loss= 0.6909, Training Accuracy= 0.531\n",
      "Epoch: 1820, Minibatch Loss= 0.6881, Training Accuracy= 0.539\n",
      "Epoch: 1830, Minibatch Loss= 0.6893, Training Accuracy= 0.533\n",
      "Epoch: 1840, Minibatch Loss= 0.6892, Training Accuracy= 0.537\n",
      "Epoch: 1850, Minibatch Loss= 0.6937, Training Accuracy= 0.526\n",
      "Epoch: 1860, Minibatch Loss= 0.6854, Training Accuracy= 0.547\n",
      "Epoch: 1870, Minibatch Loss= 0.6883, Training Accuracy= 0.534\n",
      "Epoch: 1880, Minibatch Loss= 0.6838, Training Accuracy= 0.550\n",
      "Epoch: 1890, Minibatch Loss= 0.6934, Training Accuracy= 0.516\n",
      "Epoch: 1900, Minibatch Loss= 0.6942, Training Accuracy= 0.522\n",
      "Epoch: 1910, Minibatch Loss= 0.6860, Training Accuracy= 0.547\n",
      "Epoch: 1920, Minibatch Loss= 0.6980, Training Accuracy= 0.514\n",
      "Epoch: 1930, Minibatch Loss= 0.6816, Training Accuracy= 0.560\n",
      "Epoch: 1940, Minibatch Loss= 0.6851, Training Accuracy= 0.555\n",
      "Epoch: 1950, Minibatch Loss= 0.6902, Training Accuracy= 0.539\n",
      "Epoch: 1960, Minibatch Loss= 0.6815, Training Accuracy= 0.558\n",
      "Epoch: 1970, Minibatch Loss= 0.6775, Training Accuracy= 0.567\n",
      "Epoch: 1980, Minibatch Loss= 0.7026, Training Accuracy= 0.534\n",
      "Epoch: 1990, Minibatch Loss= 0.6822, Training Accuracy= 0.558\n",
      "Epoch: 2000, Minibatch Loss= 0.6919, Training Accuracy= 0.543\n",
      "Epoch: 2010, Minibatch Loss= 0.6665, Training Accuracy= 0.585\n",
      "Epoch: 2020, Minibatch Loss= 0.6747, Training Accuracy= 0.575\n",
      "Epoch: 2030, Minibatch Loss= 0.6723, Training Accuracy= 0.575\n",
      "Epoch: 2040, Minibatch Loss= 0.6655, Training Accuracy= 0.586\n",
      "Epoch: 2050, Minibatch Loss= 0.6890, Training Accuracy= 0.530\n",
      "Epoch: 2060, Minibatch Loss= 0.6772, Training Accuracy= 0.562\n",
      "Epoch: 2070, Minibatch Loss= 0.6681, Training Accuracy= 0.579\n",
      "Epoch: 2080, Minibatch Loss= 0.6612, Training Accuracy= 0.594\n",
      "Epoch: 2090, Minibatch Loss= 0.6583, Training Accuracy= 0.593\n",
      "Epoch: 2100, Minibatch Loss= 0.6560, Training Accuracy= 0.597\n",
      "Epoch: 2110, Minibatch Loss= 0.6663, Training Accuracy= 0.585\n",
      "Epoch: 2120, Minibatch Loss= 0.6685, Training Accuracy= 0.585\n",
      "Epoch: 2130, Minibatch Loss= 0.6880, Training Accuracy= 0.536\n",
      "Epoch: 2140, Minibatch Loss= 0.6848, Training Accuracy= 0.538\n",
      "Epoch: 2150, Minibatch Loss= 0.6808, Training Accuracy= 0.549\n",
      "Epoch: 2160, Minibatch Loss= 0.6801, Training Accuracy= 0.555\n",
      "Epoch: 2170, Minibatch Loss= 0.6738, Training Accuracy= 0.562\n",
      "Epoch: 2180, Minibatch Loss= 0.6744, Training Accuracy= 0.568\n",
      "Epoch: 2190, Minibatch Loss= 0.6754, Training Accuracy= 0.567\n",
      "Epoch: 2200, Minibatch Loss= 0.6871, Training Accuracy= 0.545\n",
      "Epoch: 2210, Minibatch Loss= 0.6703, Training Accuracy= 0.580\n",
      "Epoch: 2220, Minibatch Loss= 0.6689, Training Accuracy= 0.579\n",
      "Epoch: 2230, Minibatch Loss= 0.6652, Training Accuracy= 0.581\n",
      "Epoch: 2240, Minibatch Loss= 0.6674, Training Accuracy= 0.576\n",
      "Epoch: 2250, Minibatch Loss= 0.6740, Training Accuracy= 0.576\n",
      "Epoch: 2260, Minibatch Loss= 0.6684, Training Accuracy= 0.580\n",
      "Epoch: 2270, Minibatch Loss= 0.6596, Training Accuracy= 0.600\n",
      "Epoch: 2280, Minibatch Loss= 0.6611, Training Accuracy= 0.596\n",
      "Epoch: 2290, Minibatch Loss= 0.6584, Training Accuracy= 0.594\n",
      "Epoch: 2300, Minibatch Loss= 0.6640, Training Accuracy= 0.589\n",
      "Epoch: 2310, Minibatch Loss= 0.6709, Training Accuracy= 0.586\n",
      "Epoch: 2320, Minibatch Loss= 0.6658, Training Accuracy= 0.588\n",
      "Epoch: 2330, Minibatch Loss= 0.6554, Training Accuracy= 0.603\n",
      "Epoch: 2340, Minibatch Loss= 0.6535, Training Accuracy= 0.611\n",
      "Epoch: 2350, Minibatch Loss= 0.6425, Training Accuracy= 0.623\n",
      "Epoch: 2360, Minibatch Loss= 0.6382, Training Accuracy= 0.625\n",
      "Epoch: 2370, Minibatch Loss= 0.6789, Training Accuracy= 0.577\n",
      "Epoch: 2380, Minibatch Loss= 0.7038, Training Accuracy= 0.504\n",
      "Epoch: 2390, Minibatch Loss= 0.7028, Training Accuracy= 0.504\n",
      "Epoch: 2400, Minibatch Loss= 0.7016, Training Accuracy= 0.507\n",
      "Epoch: 2410, Minibatch Loss= 0.7006, Training Accuracy= 0.509\n",
      "Epoch: 2420, Minibatch Loss= 0.6996, Training Accuracy= 0.510\n",
      "Epoch: 2430, Minibatch Loss= 0.6987, Training Accuracy= 0.511\n",
      "Epoch: 2440, Minibatch Loss= 0.6980, Training Accuracy= 0.515\n",
      "Epoch: 2450, Minibatch Loss= 0.6970, Training Accuracy= 0.517\n",
      "Epoch: 2460, Minibatch Loss= 0.6963, Training Accuracy= 0.519\n",
      "Epoch: 2470, Minibatch Loss= 0.6972, Training Accuracy= 0.520\n",
      "Epoch: 2480, Minibatch Loss= 0.6962, Training Accuracy= 0.523\n",
      "Epoch: 2490, Minibatch Loss= 0.6930, Training Accuracy= 0.531\n",
      "Epoch: 2500, Minibatch Loss= 0.6907, Training Accuracy= 0.537\n",
      "Epoch: 2510, Minibatch Loss= 0.6892, Training Accuracy= 0.536\n",
      "Epoch: 2520, Minibatch Loss= 0.6936, Training Accuracy= 0.529\n",
      "Epoch: 2530, Minibatch Loss= 0.6889, Training Accuracy= 0.542\n",
      "Epoch: 2540, Minibatch Loss= 0.6903, Training Accuracy= 0.544\n",
      "Epoch: 2550, Minibatch Loss= 0.6933, Training Accuracy= 0.536\n",
      "Epoch: 2560, Minibatch Loss= 0.6914, Training Accuracy= 0.536\n",
      "Epoch: 2570, Minibatch Loss= 0.7086, Training Accuracy= 0.511\n",
      "Epoch: 2580, Minibatch Loss= 0.6846, Training Accuracy= 0.558\n",
      "Epoch: 2590, Minibatch Loss= 0.6833, Training Accuracy= 0.556\n",
      "Epoch: 2600, Minibatch Loss= 0.6908, Training Accuracy= 0.544\n",
      "Epoch: 2610, Minibatch Loss= 0.6985, Training Accuracy= 0.519\n",
      "Epoch: 2620, Minibatch Loss= 0.6887, Training Accuracy= 0.545\n",
      "Epoch: 2630, Minibatch Loss= 0.6855, Training Accuracy= 0.554\n",
      "Epoch: 2640, Minibatch Loss= 0.6830, Training Accuracy= 0.559\n",
      "Epoch: 2650, Minibatch Loss= 0.6818, Training Accuracy= 0.564\n",
      "Epoch: 2660, Minibatch Loss= 0.6834, Training Accuracy= 0.561\n",
      "Epoch: 2670, Minibatch Loss= 0.6873, Training Accuracy= 0.556\n",
      "Epoch: 2680, Minibatch Loss= 0.6809, Training Accuracy= 0.565\n",
      "Epoch: 2690, Minibatch Loss= 0.6780, Training Accuracy= 0.572\n",
      "Epoch: 2700, Minibatch Loss= 0.6836, Training Accuracy= 0.565\n",
      "Epoch: 2710, Minibatch Loss= 0.6792, Training Accuracy= 0.572\n",
      "Epoch: 2720, Minibatch Loss= 0.6743, Training Accuracy= 0.580\n",
      "Epoch: 2730, Minibatch Loss= 0.6796, Training Accuracy= 0.573\n",
      "Epoch: 2740, Minibatch Loss= 0.6878, Training Accuracy= 0.560\n",
      "Epoch: 2750, Minibatch Loss= 0.6791, Training Accuracy= 0.575\n",
      "Epoch: 2760, Minibatch Loss= 0.6763, Training Accuracy= 0.578\n",
      "Epoch: 2770, Minibatch Loss= 0.6669, Training Accuracy= 0.591\n",
      "Epoch: 2780, Minibatch Loss= 0.6687, Training Accuracy= 0.590\n",
      "Epoch: 2790, Minibatch Loss= 0.6660, Training Accuracy= 0.588\n",
      "Epoch: 2800, Minibatch Loss= 0.6704, Training Accuracy= 0.588\n",
      "Epoch: 2810, Minibatch Loss= 0.6643, Training Accuracy= 0.597\n",
      "Epoch: 2820, Minibatch Loss= 0.6526, Training Accuracy= 0.615\n",
      "Epoch: 2830, Minibatch Loss= 0.6761, Training Accuracy= 0.572\n",
      "Epoch: 2840, Minibatch Loss= 0.6484, Training Accuracy= 0.618\n",
      "Epoch: 2850, Minibatch Loss= 0.6419, Training Accuracy= 0.619\n",
      "Epoch: 2860, Minibatch Loss= 0.6620, Training Accuracy= 0.602\n",
      "Epoch: 2870, Minibatch Loss= 0.6721, Training Accuracy= 0.588\n",
      "Epoch: 2880, Minibatch Loss= 0.6416, Training Accuracy= 0.625\n",
      "Epoch: 2890, Minibatch Loss= 0.6437, Training Accuracy= 0.622\n",
      "Epoch: 2900, Minibatch Loss= 0.6448, Training Accuracy= 0.623\n",
      "Epoch: 2910, Minibatch Loss= 0.6391, Training Accuracy= 0.627\n",
      "Epoch: 2920, Minibatch Loss= 0.6357, Training Accuracy= 0.632\n",
      "Epoch: 2930, Minibatch Loss= 0.6740, Training Accuracy= 0.576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2940, Minibatch Loss= 0.6917, Training Accuracy= 0.565\n",
      "Epoch: 2950, Minibatch Loss= 0.6413, Training Accuracy= 0.625\n",
      "Epoch: 2960, Minibatch Loss= 0.7253, Training Accuracy= 0.498\n",
      "Epoch: 2970, Minibatch Loss= 0.7233, Training Accuracy= 0.498\n",
      "Epoch: 2980, Minibatch Loss= 0.7221, Training Accuracy= 0.498\n",
      "Epoch: 2990, Minibatch Loss= 0.7202, Training Accuracy= 0.498\n",
      "Epoch: 3000, Minibatch Loss= 0.7184, Training Accuracy= 0.499\n",
      "Epoch: 3010, Minibatch Loss= 0.7168, Training Accuracy= 0.500\n",
      "Epoch: 3020, Minibatch Loss= 0.7152, Training Accuracy= 0.500\n",
      "Epoch: 3030, Minibatch Loss= 0.7137, Training Accuracy= 0.500\n",
      "Epoch: 3040, Minibatch Loss= 0.7123, Training Accuracy= 0.501\n",
      "Epoch: 3050, Minibatch Loss= 0.7108, Training Accuracy= 0.502\n",
      "Epoch: 3060, Minibatch Loss= 0.7092, Training Accuracy= 0.502\n",
      "Epoch: 3070, Minibatch Loss= 0.7077, Training Accuracy= 0.503\n",
      "Epoch: 3080, Minibatch Loss= 0.7065, Training Accuracy= 0.507\n",
      "Epoch: 3090, Minibatch Loss= 0.7051, Training Accuracy= 0.506\n",
      "Epoch: 3100, Minibatch Loss= 0.7039, Training Accuracy= 0.508\n",
      "Epoch: 3110, Minibatch Loss= 0.7080, Training Accuracy= 0.500\n",
      "Epoch: 3120, Minibatch Loss= 0.7037, Training Accuracy= 0.504\n",
      "Epoch: 3130, Minibatch Loss= 0.7043, Training Accuracy= 0.502\n",
      "Epoch: 3140, Minibatch Loss= 0.7012, Training Accuracy= 0.504\n",
      "Epoch: 3150, Minibatch Loss= 0.7010, Training Accuracy= 0.506\n",
      "Epoch: 3160, Minibatch Loss= 0.6969, Training Accuracy= 0.512\n",
      "Epoch: 3170, Minibatch Loss= 0.6966, Training Accuracy= 0.514\n",
      "Epoch: 3180, Minibatch Loss= 0.6930, Training Accuracy= 0.520\n",
      "Epoch: 3190, Minibatch Loss= 0.6927, Training Accuracy= 0.521\n",
      "Epoch: 3200, Minibatch Loss= 0.6908, Training Accuracy= 0.524\n",
      "Epoch: 3210, Minibatch Loss= 0.7004, Training Accuracy= 0.510\n",
      "Epoch: 3220, Minibatch Loss= 0.7038, Training Accuracy= 0.498\n",
      "Epoch: 3230, Minibatch Loss= 0.7028, Training Accuracy= 0.498\n",
      "Epoch: 3240, Minibatch Loss= 0.7023, Training Accuracy= 0.498\n",
      "Epoch: 3250, Minibatch Loss= 0.7019, Training Accuracy= 0.498\n",
      "Epoch: 3260, Minibatch Loss= 0.7015, Training Accuracy= 0.498\n",
      "Epoch: 3270, Minibatch Loss= 0.7012, Training Accuracy= 0.498\n",
      "Epoch: 3280, Minibatch Loss= 0.7009, Training Accuracy= 0.498\n",
      "Epoch: 3290, Minibatch Loss= 0.7006, Training Accuracy= 0.498\n",
      "Epoch: 3300, Minibatch Loss= 0.7004, Training Accuracy= 0.498\n",
      "Epoch: 3310, Minibatch Loss= 0.7002, Training Accuracy= 0.499\n",
      "Epoch: 3320, Minibatch Loss= 0.7000, Training Accuracy= 0.499\n",
      "Epoch: 3330, Minibatch Loss= 0.6998, Training Accuracy= 0.499\n",
      "Epoch: 3340, Minibatch Loss= 0.6997, Training Accuracy= 0.500\n",
      "Epoch: 3350, Minibatch Loss= 0.6995, Training Accuracy= 0.499\n",
      "Epoch: 3360, Minibatch Loss= 0.6994, Training Accuracy= 0.500\n",
      "Epoch: 3370, Minibatch Loss= 0.6992, Training Accuracy= 0.500\n",
      "Epoch: 3380, Minibatch Loss= 0.6990, Training Accuracy= 0.500\n",
      "Epoch: 3390, Minibatch Loss= 0.6989, Training Accuracy= 0.499\n",
      "Epoch: 3400, Minibatch Loss= 0.6988, Training Accuracy= 0.500\n",
      "Epoch: 3410, Minibatch Loss= 0.6986, Training Accuracy= 0.500\n",
      "Epoch: 3420, Minibatch Loss= 0.6985, Training Accuracy= 0.501\n",
      "Epoch: 3430, Minibatch Loss= 0.6983, Training Accuracy= 0.502\n",
      "Epoch: 3440, Minibatch Loss= 0.6982, Training Accuracy= 0.502\n",
      "Epoch: 3450, Minibatch Loss= 0.6980, Training Accuracy= 0.503\n",
      "Epoch: 3460, Minibatch Loss= 0.6978, Training Accuracy= 0.504\n",
      "Epoch: 3470, Minibatch Loss= 0.6976, Training Accuracy= 0.506\n",
      "Epoch: 3480, Minibatch Loss= 0.6973, Training Accuracy= 0.507\n",
      "Epoch: 3490, Minibatch Loss= 0.6971, Training Accuracy= 0.508\n",
      "Epoch: 3500, Minibatch Loss= 0.6968, Training Accuracy= 0.508\n",
      "Epoch: 3510, Minibatch Loss= 0.6965, Training Accuracy= 0.508\n",
      "Epoch: 3520, Minibatch Loss= 0.6962, Training Accuracy= 0.509\n",
      "Epoch: 3530, Minibatch Loss= 0.6959, Training Accuracy= 0.512\n",
      "Epoch: 3540, Minibatch Loss= 0.6955, Training Accuracy= 0.512\n",
      "Epoch: 3550, Minibatch Loss= 0.6950, Training Accuracy= 0.515\n",
      "Epoch: 3560, Minibatch Loss= 0.6946, Training Accuracy= 0.516\n",
      "Epoch: 3570, Minibatch Loss= 0.6942, Training Accuracy= 0.518\n",
      "Epoch: 3580, Minibatch Loss= 0.6938, Training Accuracy= 0.521\n",
      "Epoch: 3590, Minibatch Loss= 0.6933, Training Accuracy= 0.522\n",
      "Epoch: 3600, Minibatch Loss= 0.6929, Training Accuracy= 0.521\n",
      "Epoch: 3610, Minibatch Loss= 0.6925, Training Accuracy= 0.524\n",
      "Epoch: 3620, Minibatch Loss= 0.6921, Training Accuracy= 0.526\n",
      "Epoch: 3630, Minibatch Loss= 0.6916, Training Accuracy= 0.528\n",
      "Epoch: 3640, Minibatch Loss= 0.6912, Training Accuracy= 0.529\n",
      "Epoch: 3650, Minibatch Loss= 0.6907, Training Accuracy= 0.531\n",
      "Epoch: 3660, Minibatch Loss= 0.6905, Training Accuracy= 0.530\n",
      "Epoch: 3670, Minibatch Loss= 0.6898, Training Accuracy= 0.533\n",
      "Epoch: 3680, Minibatch Loss= 0.6893, Training Accuracy= 0.536\n",
      "Epoch: 3690, Minibatch Loss= 0.6889, Training Accuracy= 0.537\n",
      "Epoch: 3700, Minibatch Loss= 0.6884, Training Accuracy= 0.538\n",
      "Epoch: 3710, Minibatch Loss= 0.6881, Training Accuracy= 0.538\n",
      "Epoch: 3720, Minibatch Loss= 0.6878, Training Accuracy= 0.542\n",
      "Epoch: 3730, Minibatch Loss= 0.6875, Training Accuracy= 0.541\n",
      "Epoch: 3740, Minibatch Loss= 0.6872, Training Accuracy= 0.545\n",
      "Epoch: 3750, Minibatch Loss= 0.6873, Training Accuracy= 0.546\n",
      "Epoch: 3760, Minibatch Loss= 0.6871, Training Accuracy= 0.547\n",
      "Epoch: 3770, Minibatch Loss= 0.6867, Training Accuracy= 0.548\n",
      "Epoch: 3780, Minibatch Loss= 0.6870, Training Accuracy= 0.546\n",
      "Epoch: 3790, Minibatch Loss= 0.6852, Training Accuracy= 0.552\n",
      "Epoch: 3800, Minibatch Loss= 0.6849, Training Accuracy= 0.553\n",
      "Epoch: 3810, Minibatch Loss= 0.6842, Training Accuracy= 0.554\n",
      "Epoch: 3820, Minibatch Loss= 0.6846, Training Accuracy= 0.554\n",
      "Epoch: 3830, Minibatch Loss= 0.6844, Training Accuracy= 0.558\n",
      "Epoch: 3840, Minibatch Loss= 0.6842, Training Accuracy= 0.557\n",
      "Epoch: 3850, Minibatch Loss= 0.6862, Training Accuracy= 0.552\n",
      "Epoch: 3860, Minibatch Loss= 0.6892, Training Accuracy= 0.551\n",
      "Epoch: 3870, Minibatch Loss= 0.6885, Training Accuracy= 0.553\n",
      "Epoch: 3880, Minibatch Loss= 0.6866, Training Accuracy= 0.556\n",
      "Epoch: 3890, Minibatch Loss= 0.6828, Training Accuracy= 0.563\n",
      "Epoch: 3900, Minibatch Loss= 0.6793, Training Accuracy= 0.568\n",
      "Epoch: 3910, Minibatch Loss= 0.6866, Training Accuracy= 0.554\n",
      "Epoch: 3920, Minibatch Loss= 0.6834, Training Accuracy= 0.558\n",
      "Epoch: 3930, Minibatch Loss= 0.6776, Training Accuracy= 0.571\n",
      "Epoch: 3940, Minibatch Loss= 0.6750, Training Accuracy= 0.576\n",
      "Epoch: 3950, Minibatch Loss= 0.6838, Training Accuracy= 0.564\n",
      "Epoch: 3960, Minibatch Loss= 0.6783, Training Accuracy= 0.574\n",
      "Epoch: 3970, Minibatch Loss= 0.6797, Training Accuracy= 0.569\n",
      "Epoch: 3980, Minibatch Loss= 0.7189, Training Accuracy= 0.497\n",
      "Epoch: 3990, Minibatch Loss= 0.7139, Training Accuracy= 0.500\n",
      "Epoch: 4000, Minibatch Loss= 0.7123, Training Accuracy= 0.498\n",
      "Epoch: 4010, Minibatch Loss= 0.7105, Training Accuracy= 0.498\n",
      "Epoch: 4020, Minibatch Loss= 0.7092, Training Accuracy= 0.498\n",
      "Epoch: 4030, Minibatch Loss= 0.7080, Training Accuracy= 0.501\n",
      "Epoch: 4040, Minibatch Loss= 0.7072, Training Accuracy= 0.502\n",
      "Epoch: 4050, Minibatch Loss= 0.7065, Training Accuracy= 0.502\n",
      "Epoch: 4060, Minibatch Loss= 0.7059, Training Accuracy= 0.502\n",
      "Epoch: 4070, Minibatch Loss= 0.7054, Training Accuracy= 0.502\n",
      "Epoch: 4080, Minibatch Loss= 0.7048, Training Accuracy= 0.504\n",
      "Epoch: 4090, Minibatch Loss= 0.7043, Training Accuracy= 0.505\n",
      "Epoch: 4100, Minibatch Loss= 0.7039, Training Accuracy= 0.505\n",
      "Epoch: 4110, Minibatch Loss= 0.7035, Training Accuracy= 0.505\n",
      "Epoch: 4120, Minibatch Loss= 0.7030, Training Accuracy= 0.507\n",
      "Epoch: 4130, Minibatch Loss= 0.7025, Training Accuracy= 0.508\n",
      "Epoch: 4140, Minibatch Loss= 0.7020, Training Accuracy= 0.510\n",
      "Epoch: 4150, Minibatch Loss= 0.7015, Training Accuracy= 0.512\n",
      "Epoch: 4160, Minibatch Loss= 0.7009, Training Accuracy= 0.514\n",
      "Epoch: 4170, Minibatch Loss= 0.7002, Training Accuracy= 0.514\n",
      "Epoch: 4180, Minibatch Loss= 0.6995, Training Accuracy= 0.515\n",
      "Epoch: 4190, Minibatch Loss= 0.6988, Training Accuracy= 0.517\n",
      "Epoch: 4200, Minibatch Loss= 0.6981, Training Accuracy= 0.518\n",
      "Epoch: 4210, Minibatch Loss= 0.6973, Training Accuracy= 0.518\n",
      "Epoch: 4220, Minibatch Loss= 0.6966, Training Accuracy= 0.519\n",
      "Epoch: 4230, Minibatch Loss= 0.6960, Training Accuracy= 0.522\n",
      "Epoch: 4240, Minibatch Loss= 0.6955, Training Accuracy= 0.524\n",
      "Epoch: 4250, Minibatch Loss= 0.6950, Training Accuracy= 0.525\n",
      "Epoch: 4260, Minibatch Loss= 0.6949, Training Accuracy= 0.525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4270, Minibatch Loss= 0.6940, Training Accuracy= 0.525\n",
      "Epoch: 4280, Minibatch Loss= 0.6933, Training Accuracy= 0.529\n",
      "Epoch: 4290, Minibatch Loss= 0.6927, Training Accuracy= 0.530\n",
      "Epoch: 4300, Minibatch Loss= 0.6922, Training Accuracy= 0.533\n",
      "Epoch: 4310, Minibatch Loss= 0.6918, Training Accuracy= 0.533\n",
      "Epoch: 4320, Minibatch Loss= 0.6913, Training Accuracy= 0.537\n",
      "Epoch: 4330, Minibatch Loss= 0.6912, Training Accuracy= 0.537\n",
      "Epoch: 4340, Minibatch Loss= 0.6903, Training Accuracy= 0.540\n",
      "Epoch: 4350, Minibatch Loss= 0.6906, Training Accuracy= 0.539\n",
      "Epoch: 4360, Minibatch Loss= 0.6909, Training Accuracy= 0.537\n",
      "Epoch: 4370, Minibatch Loss= 0.6901, Training Accuracy= 0.540\n",
      "Epoch: 4380, Minibatch Loss= 0.6900, Training Accuracy= 0.538\n",
      "Epoch: 4390, Minibatch Loss= 0.6884, Training Accuracy= 0.548\n",
      "Epoch: 4400, Minibatch Loss= 0.6887, Training Accuracy= 0.545\n",
      "Epoch: 4410, Minibatch Loss= 0.6895, Training Accuracy= 0.542\n",
      "Epoch: 4420, Minibatch Loss= 0.7240, Training Accuracy= 0.505\n",
      "Epoch: 4430, Minibatch Loss= 0.6923, Training Accuracy= 0.536\n",
      "Epoch: 4440, Minibatch Loss= 0.6905, Training Accuracy= 0.540\n",
      "Epoch: 4450, Minibatch Loss= 0.6920, Training Accuracy= 0.538\n",
      "Epoch: 4460, Minibatch Loss= 0.6865, Training Accuracy= 0.546\n",
      "Epoch: 4470, Minibatch Loss= 0.6852, Training Accuracy= 0.551\n",
      "Epoch: 4480, Minibatch Loss= 0.7180, Training Accuracy= 0.502\n",
      "Epoch: 4490, Minibatch Loss= 0.7124, Training Accuracy= 0.507\n",
      "Epoch: 4500, Minibatch Loss= 0.7083, Training Accuracy= 0.508\n",
      "Epoch: 4510, Minibatch Loss= 0.7072, Training Accuracy= 0.508\n",
      "Epoch: 4520, Minibatch Loss= 0.7067, Training Accuracy= 0.512\n",
      "Epoch: 4530, Minibatch Loss= 0.7045, Training Accuracy= 0.512\n",
      "Epoch: 4540, Minibatch Loss= 0.7026, Training Accuracy= 0.517\n",
      "Epoch: 4550, Minibatch Loss= 0.7010, Training Accuracy= 0.516\n",
      "Epoch: 4560, Minibatch Loss= 0.6994, Training Accuracy= 0.516\n",
      "Epoch: 4570, Minibatch Loss= 0.6989, Training Accuracy= 0.520\n",
      "Epoch: 4580, Minibatch Loss= 0.6987, Training Accuracy= 0.521\n",
      "Epoch: 4590, Minibatch Loss= 0.6974, Training Accuracy= 0.520\n",
      "Epoch: 4600, Minibatch Loss= 0.6962, Training Accuracy= 0.525\n",
      "Epoch: 4610, Minibatch Loss= 0.6966, Training Accuracy= 0.524\n",
      "Epoch: 4620, Minibatch Loss= 0.6937, Training Accuracy= 0.531\n",
      "Epoch: 4630, Minibatch Loss= 0.6973, Training Accuracy= 0.525\n",
      "Epoch: 4640, Minibatch Loss= 0.6969, Training Accuracy= 0.519\n",
      "Epoch: 4650, Minibatch Loss= 0.6953, Training Accuracy= 0.527\n",
      "Epoch: 4660, Minibatch Loss= 0.6943, Training Accuracy= 0.527\n",
      "Epoch: 4670, Minibatch Loss= 0.6939, Training Accuracy= 0.534\n",
      "Epoch: 4680, Minibatch Loss= 0.6926, Training Accuracy= 0.539\n",
      "Epoch: 4690, Minibatch Loss= 0.6889, Training Accuracy= 0.540\n",
      "Epoch: 4700, Minibatch Loss= 0.7215, Training Accuracy= 0.500\n",
      "Epoch: 4710, Minibatch Loss= 0.7109, Training Accuracy= 0.500\n",
      "Epoch: 4720, Minibatch Loss= 0.7102, Training Accuracy= 0.499\n",
      "Epoch: 4730, Minibatch Loss= 0.7096, Training Accuracy= 0.500\n",
      "Epoch: 4740, Minibatch Loss= 0.7090, Training Accuracy= 0.500\n",
      "Epoch: 4750, Minibatch Loss= 0.7084, Training Accuracy= 0.501\n",
      "Epoch: 4760, Minibatch Loss= 0.7076, Training Accuracy= 0.501\n",
      "Epoch: 4770, Minibatch Loss= 0.7069, Training Accuracy= 0.503\n",
      "Epoch: 4780, Minibatch Loss= 0.7062, Training Accuracy= 0.503\n",
      "Epoch: 4790, Minibatch Loss= 0.7056, Training Accuracy= 0.505\n",
      "Epoch: 4800, Minibatch Loss= 0.7048, Training Accuracy= 0.507\n",
      "Epoch: 4810, Minibatch Loss= 0.7039, Training Accuracy= 0.508\n",
      "Epoch: 4820, Minibatch Loss= 0.7027, Training Accuracy= 0.511\n",
      "Epoch: 4830, Minibatch Loss= 0.7012, Training Accuracy= 0.514\n",
      "Epoch: 4840, Minibatch Loss= 0.6998, Training Accuracy= 0.517\n",
      "Epoch: 4850, Minibatch Loss= 0.6983, Training Accuracy= 0.520\n",
      "Epoch: 4860, Minibatch Loss= 0.6970, Training Accuracy= 0.524\n",
      "Epoch: 4870, Minibatch Loss= 0.6959, Training Accuracy= 0.530\n",
      "Epoch: 4880, Minibatch Loss= 0.6949, Training Accuracy= 0.532\n",
      "Epoch: 4890, Minibatch Loss= 0.6940, Training Accuracy= 0.533\n",
      "Epoch: 4900, Minibatch Loss= 0.6931, Training Accuracy= 0.535\n",
      "Epoch: 4910, Minibatch Loss= 0.6920, Training Accuracy= 0.538\n",
      "Epoch: 4920, Minibatch Loss= 0.6908, Training Accuracy= 0.545\n",
      "Epoch: 4930, Minibatch Loss= 0.6894, Training Accuracy= 0.549\n",
      "Epoch: 4940, Minibatch Loss= 0.6877, Training Accuracy= 0.552\n",
      "Epoch: 4950, Minibatch Loss= 0.6862, Training Accuracy= 0.555\n",
      "Epoch: 4960, Minibatch Loss= 0.6836, Training Accuracy= 0.557\n",
      "Epoch: 4970, Minibatch Loss= 0.6821, Training Accuracy= 0.562\n",
      "Epoch: 4980, Minibatch Loss= 0.6829, Training Accuracy= 0.562\n",
      "Epoch: 4990, Minibatch Loss= 0.6806, Training Accuracy= 0.567\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.496\n",
      "Replication: 6: \n",
      "Epoch: 0, Minibatch Loss= 0.6946, Training Accuracy= 0.497\n",
      "Epoch: 10, Minibatch Loss= 0.6930, Training Accuracy= 0.510\n",
      "Epoch: 20, Minibatch Loss= 0.6930, Training Accuracy= 0.511\n",
      "Epoch: 30, Minibatch Loss= 0.6930, Training Accuracy= 0.512\n",
      "Epoch: 40, Minibatch Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 50, Minibatch Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 60, Minibatch Loss= 0.6929, Training Accuracy= 0.512\n",
      "Epoch: 70, Minibatch Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 80, Minibatch Loss= 0.6929, Training Accuracy= 0.514\n",
      "Epoch: 90, Minibatch Loss= 0.6929, Training Accuracy= 0.514\n",
      "Epoch: 100, Minibatch Loss= 0.6929, Training Accuracy= 0.512\n",
      "Epoch: 110, Minibatch Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 120, Minibatch Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 130, Minibatch Loss= 0.6928, Training Accuracy= 0.512\n",
      "Epoch: 140, Minibatch Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 150, Minibatch Loss= 0.6928, Training Accuracy= 0.510\n",
      "Epoch: 160, Minibatch Loss= 0.6928, Training Accuracy= 0.510\n",
      "Epoch: 170, Minibatch Loss= 0.6928, Training Accuracy= 0.512\n",
      "Epoch: 180, Minibatch Loss= 0.6928, Training Accuracy= 0.512\n",
      "Epoch: 190, Minibatch Loss= 0.6928, Training Accuracy= 0.512\n",
      "Epoch: 200, Minibatch Loss= 0.6927, Training Accuracy= 0.510\n",
      "Epoch: 210, Minibatch Loss= 0.6927, Training Accuracy= 0.510\n",
      "Epoch: 220, Minibatch Loss= 0.6927, Training Accuracy= 0.508\n",
      "Epoch: 230, Minibatch Loss= 0.6927, Training Accuracy= 0.511\n",
      "Epoch: 240, Minibatch Loss= 0.6926, Training Accuracy= 0.512\n",
      "Epoch: 250, Minibatch Loss= 0.6926, Training Accuracy= 0.515\n",
      "Epoch: 260, Minibatch Loss= 0.6925, Training Accuracy= 0.516\n",
      "Epoch: 270, Minibatch Loss= 0.6925, Training Accuracy= 0.514\n",
      "Epoch: 280, Minibatch Loss= 0.6925, Training Accuracy= 0.515\n",
      "Epoch: 290, Minibatch Loss= 0.6924, Training Accuracy= 0.514\n",
      "Epoch: 300, Minibatch Loss= 0.6924, Training Accuracy= 0.515\n",
      "Epoch: 310, Minibatch Loss= 0.6924, Training Accuracy= 0.515\n",
      "Epoch: 320, Minibatch Loss= 0.6924, Training Accuracy= 0.515\n",
      "Epoch: 330, Minibatch Loss= 0.6924, Training Accuracy= 0.514\n",
      "Epoch: 340, Minibatch Loss= 0.6923, Training Accuracy= 0.515\n",
      "Epoch: 350, Minibatch Loss= 0.6923, Training Accuracy= 0.516\n",
      "Epoch: 360, Minibatch Loss= 0.6923, Training Accuracy= 0.517\n",
      "Epoch: 370, Minibatch Loss= 0.6922, Training Accuracy= 0.517\n",
      "Epoch: 380, Minibatch Loss= 0.6922, Training Accuracy= 0.516\n",
      "Epoch: 390, Minibatch Loss= 0.6921, Training Accuracy= 0.517\n",
      "Epoch: 400, Minibatch Loss= 0.6921, Training Accuracy= 0.518\n",
      "Epoch: 410, Minibatch Loss= 0.6920, Training Accuracy= 0.519\n",
      "Epoch: 420, Minibatch Loss= 0.6919, Training Accuracy= 0.520\n",
      "Epoch: 430, Minibatch Loss= 0.6920, Training Accuracy= 0.520\n",
      "Epoch: 440, Minibatch Loss= 0.6918, Training Accuracy= 0.519\n",
      "Epoch: 450, Minibatch Loss= 0.6915, Training Accuracy= 0.523\n",
      "Epoch: 460, Minibatch Loss= 0.6910, Training Accuracy= 0.529\n",
      "Epoch: 470, Minibatch Loss= 0.6902, Training Accuracy= 0.534\n",
      "Epoch: 480, Minibatch Loss= 0.6902, Training Accuracy= 0.536\n",
      "Epoch: 490, Minibatch Loss= 0.6917, Training Accuracy= 0.526\n",
      "Epoch: 500, Minibatch Loss= 0.6909, Training Accuracy= 0.533\n",
      "Epoch: 510, Minibatch Loss= 0.6905, Training Accuracy= 0.533\n",
      "Epoch: 520, Minibatch Loss= 0.6883, Training Accuracy= 0.544\n",
      "Epoch: 530, Minibatch Loss= 0.6886, Training Accuracy= 0.542\n",
      "Epoch: 540, Minibatch Loss= 0.6883, Training Accuracy= 0.544\n",
      "Epoch: 550, Minibatch Loss= 0.6890, Training Accuracy= 0.542\n",
      "Epoch: 560, Minibatch Loss= 0.6932, Training Accuracy= 0.510\n",
      "Epoch: 570, Minibatch Loss= 0.6929, Training Accuracy= 0.511\n",
      "Epoch: 580, Minibatch Loss= 0.6927, Training Accuracy= 0.510\n",
      "Epoch: 590, Minibatch Loss= 0.6925, Training Accuracy= 0.515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 600, Minibatch Loss= 0.6937, Training Accuracy= 0.512\n",
      "Epoch: 610, Minibatch Loss= 0.6913, Training Accuracy= 0.523\n",
      "Epoch: 620, Minibatch Loss= 0.6916, Training Accuracy= 0.531\n",
      "Epoch: 630, Minibatch Loss= 0.6881, Training Accuracy= 0.544\n",
      "Epoch: 640, Minibatch Loss= 0.6860, Training Accuracy= 0.547\n",
      "Epoch: 650, Minibatch Loss= 0.6863, Training Accuracy= 0.548\n",
      "Epoch: 660, Minibatch Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 670, Minibatch Loss= 0.6929, Training Accuracy= 0.512\n",
      "Epoch: 680, Minibatch Loss= 0.6928, Training Accuracy= 0.514\n",
      "Epoch: 690, Minibatch Loss= 0.6927, Training Accuracy= 0.514\n",
      "Epoch: 700, Minibatch Loss= 0.6927, Training Accuracy= 0.515\n",
      "Epoch: 710, Minibatch Loss= 0.6926, Training Accuracy= 0.513\n",
      "Epoch: 720, Minibatch Loss= 0.6925, Training Accuracy= 0.515\n",
      "Epoch: 730, Minibatch Loss= 0.6931, Training Accuracy= 0.510\n",
      "Epoch: 740, Minibatch Loss= 0.6924, Training Accuracy= 0.514\n",
      "Epoch: 750, Minibatch Loss= 0.6927, Training Accuracy= 0.511\n",
      "Epoch: 760, Minibatch Loss= 0.6921, Training Accuracy= 0.518\n",
      "Epoch: 770, Minibatch Loss= 0.6917, Training Accuracy= 0.522\n",
      "Epoch: 780, Minibatch Loss= 0.6915, Training Accuracy= 0.524\n",
      "Epoch: 790, Minibatch Loss= 0.6912, Training Accuracy= 0.525\n",
      "Epoch: 800, Minibatch Loss= 0.6910, Training Accuracy= 0.526\n",
      "Epoch: 810, Minibatch Loss= 0.6907, Training Accuracy= 0.526\n",
      "Epoch: 820, Minibatch Loss= 0.6904, Training Accuracy= 0.528\n",
      "Epoch: 830, Minibatch Loss= 0.6902, Training Accuracy= 0.529\n",
      "Epoch: 840, Minibatch Loss= 0.6901, Training Accuracy= 0.532\n",
      "Epoch: 850, Minibatch Loss= 0.6900, Training Accuracy= 0.531\n",
      "Epoch: 860, Minibatch Loss= 0.6903, Training Accuracy= 0.533\n",
      "Epoch: 870, Minibatch Loss= 0.6916, Training Accuracy= 0.530\n",
      "Epoch: 880, Minibatch Loss= 0.6895, Training Accuracy= 0.536\n",
      "Epoch: 890, Minibatch Loss= 0.6897, Training Accuracy= 0.538\n",
      "Epoch: 900, Minibatch Loss= 0.6891, Training Accuracy= 0.539\n",
      "Epoch: 910, Minibatch Loss= 0.6878, Training Accuracy= 0.539\n",
      "Epoch: 920, Minibatch Loss= 0.6864, Training Accuracy= 0.547\n",
      "Epoch: 930, Minibatch Loss= 0.6861, Training Accuracy= 0.547\n",
      "Epoch: 940, Minibatch Loss= 0.6859, Training Accuracy= 0.549\n",
      "Epoch: 950, Minibatch Loss= 0.6875, Training Accuracy= 0.544\n",
      "Epoch: 960, Minibatch Loss= 0.6850, Training Accuracy= 0.553\n",
      "Epoch: 970, Minibatch Loss= 0.6850, Training Accuracy= 0.551\n",
      "Epoch: 980, Minibatch Loss= 0.6896, Training Accuracy= 0.540\n",
      "Epoch: 990, Minibatch Loss= 0.6839, Training Accuracy= 0.554\n",
      "Epoch: 1000, Minibatch Loss= 0.6867, Training Accuracy= 0.547\n",
      "Epoch: 1010, Minibatch Loss= 0.6836, Training Accuracy= 0.556\n",
      "Epoch: 1020, Minibatch Loss= 0.6826, Training Accuracy= 0.557\n",
      "Epoch: 1030, Minibatch Loss= 0.6831, Training Accuracy= 0.556\n",
      "Epoch: 1040, Minibatch Loss= 0.6850, Training Accuracy= 0.550\n",
      "Epoch: 1050, Minibatch Loss= 0.6857, Training Accuracy= 0.546\n",
      "Epoch: 1060, Minibatch Loss= 0.6936, Training Accuracy= 0.516\n",
      "Epoch: 1070, Minibatch Loss= 0.6887, Training Accuracy= 0.537\n",
      "Epoch: 1080, Minibatch Loss= 0.6809, Training Accuracy= 0.560\n",
      "Epoch: 1090, Minibatch Loss= 0.6791, Training Accuracy= 0.565\n",
      "Epoch: 1100, Minibatch Loss= 0.6787, Training Accuracy= 0.566\n",
      "Epoch: 1110, Minibatch Loss= 0.6862, Training Accuracy= 0.547\n",
      "Epoch: 1120, Minibatch Loss= 0.6798, Training Accuracy= 0.562\n",
      "Epoch: 1130, Minibatch Loss= 0.6836, Training Accuracy= 0.564\n",
      "Epoch: 1140, Minibatch Loss= 0.6782, Training Accuracy= 0.566\n",
      "Epoch: 1150, Minibatch Loss= 0.6783, Training Accuracy= 0.568\n",
      "Epoch: 1160, Minibatch Loss= 0.6792, Training Accuracy= 0.570\n",
      "Epoch: 1170, Minibatch Loss= 0.6754, Training Accuracy= 0.576\n",
      "Epoch: 1180, Minibatch Loss= 0.6755, Training Accuracy= 0.576\n",
      "Epoch: 1190, Minibatch Loss= 0.6760, Training Accuracy= 0.579\n",
      "Epoch: 1200, Minibatch Loss= 0.6708, Training Accuracy= 0.580\n",
      "Epoch: 1210, Minibatch Loss= 0.6776, Training Accuracy= 0.573\n",
      "Epoch: 1220, Minibatch Loss= 0.6675, Training Accuracy= 0.591\n",
      "Epoch: 1230, Minibatch Loss= 0.6677, Training Accuracy= 0.588\n",
      "Epoch: 1240, Minibatch Loss= 0.6655, Training Accuracy= 0.592\n",
      "Epoch: 1250, Minibatch Loss= 0.6647, Training Accuracy= 0.596\n",
      "Epoch: 1260, Minibatch Loss= 0.6896, Training Accuracy= 0.539\n",
      "Epoch: 1270, Minibatch Loss= 0.6712, Training Accuracy= 0.586\n",
      "Epoch: 1280, Minibatch Loss= 0.6872, Training Accuracy= 0.548\n",
      "Epoch: 1290, Minibatch Loss= 0.6742, Training Accuracy= 0.574\n",
      "Epoch: 1300, Minibatch Loss= 0.6779, Training Accuracy= 0.568\n",
      "Epoch: 1310, Minibatch Loss= 0.6738, Training Accuracy= 0.575\n",
      "Epoch: 1320, Minibatch Loss= 0.6682, Training Accuracy= 0.589\n",
      "Epoch: 1330, Minibatch Loss= 0.6651, Training Accuracy= 0.591\n",
      "Epoch: 1340, Minibatch Loss= 0.6610, Training Accuracy= 0.599\n",
      "Epoch: 1350, Minibatch Loss= 0.6674, Training Accuracy= 0.592\n",
      "Epoch: 1360, Minibatch Loss= 0.6529, Training Accuracy= 0.612\n",
      "Epoch: 1370, Minibatch Loss= 0.6514, Training Accuracy= 0.616\n",
      "Epoch: 1380, Minibatch Loss= 0.6464, Training Accuracy= 0.620\n",
      "Epoch: 1390, Minibatch Loss= 0.6872, Training Accuracy= 0.565\n",
      "Epoch: 1400, Minibatch Loss= 0.6935, Training Accuracy= 0.515\n",
      "Epoch: 1410, Minibatch Loss= 0.6890, Training Accuracy= 0.530\n",
      "Epoch: 1420, Minibatch Loss= 0.6876, Training Accuracy= 0.529\n",
      "Epoch: 1430, Minibatch Loss= 0.6876, Training Accuracy= 0.532\n",
      "Epoch: 1440, Minibatch Loss= 0.6859, Training Accuracy= 0.536\n",
      "Epoch: 1450, Minibatch Loss= 0.6833, Training Accuracy= 0.541\n",
      "Epoch: 1460, Minibatch Loss= 0.6840, Training Accuracy= 0.538\n",
      "Epoch: 1470, Minibatch Loss= 0.6824, Training Accuracy= 0.542\n",
      "Epoch: 1480, Minibatch Loss= 0.6866, Training Accuracy= 0.536\n",
      "Epoch: 1490, Minibatch Loss= 0.6826, Training Accuracy= 0.543\n",
      "Epoch: 1500, Minibatch Loss= 0.6947, Training Accuracy= 0.525\n",
      "Epoch: 1510, Minibatch Loss= 0.6939, Training Accuracy= 0.510\n",
      "Epoch: 1520, Minibatch Loss= 0.6937, Training Accuracy= 0.511\n",
      "Epoch: 1530, Minibatch Loss= 0.6935, Training Accuracy= 0.512\n",
      "Epoch: 1540, Minibatch Loss= 0.6933, Training Accuracy= 0.515\n",
      "Epoch: 1550, Minibatch Loss= 0.6930, Training Accuracy= 0.513\n",
      "Epoch: 1560, Minibatch Loss= 0.6928, Training Accuracy= 0.517\n",
      "Epoch: 1570, Minibatch Loss= 0.6926, Training Accuracy= 0.519\n",
      "Epoch: 1580, Minibatch Loss= 0.6924, Training Accuracy= 0.520\n",
      "Epoch: 1590, Minibatch Loss= 0.6922, Training Accuracy= 0.518\n",
      "Epoch: 1600, Minibatch Loss= 0.6920, Training Accuracy= 0.521\n",
      "Epoch: 1610, Minibatch Loss= 0.6918, Training Accuracy= 0.521\n",
      "Epoch: 1620, Minibatch Loss= 0.6916, Training Accuracy= 0.524\n",
      "Epoch: 1630, Minibatch Loss= 0.6915, Training Accuracy= 0.526\n",
      "Epoch: 1640, Minibatch Loss= 0.6913, Training Accuracy= 0.528\n",
      "Epoch: 1650, Minibatch Loss= 0.6910, Training Accuracy= 0.528\n",
      "Epoch: 1660, Minibatch Loss= 0.6908, Training Accuracy= 0.531\n",
      "Epoch: 1670, Minibatch Loss= 0.6905, Training Accuracy= 0.536\n",
      "Epoch: 1680, Minibatch Loss= 0.6901, Training Accuracy= 0.535\n",
      "Epoch: 1690, Minibatch Loss= 0.6896, Training Accuracy= 0.537\n",
      "Epoch: 1700, Minibatch Loss= 0.6892, Training Accuracy= 0.537\n",
      "Epoch: 1710, Minibatch Loss= 0.6888, Training Accuracy= 0.536\n",
      "Epoch: 1720, Minibatch Loss= 0.6883, Training Accuracy= 0.540\n",
      "Epoch: 1730, Minibatch Loss= 0.6876, Training Accuracy= 0.539\n",
      "Epoch: 1740, Minibatch Loss= 0.6866, Training Accuracy= 0.541\n",
      "Epoch: 1750, Minibatch Loss= 0.6855, Training Accuracy= 0.546\n",
      "Epoch: 1760, Minibatch Loss= 0.6855, Training Accuracy= 0.549\n",
      "Epoch: 1770, Minibatch Loss= 0.6872, Training Accuracy= 0.542\n",
      "Epoch: 1780, Minibatch Loss= 0.6838, Training Accuracy= 0.553\n",
      "Epoch: 1790, Minibatch Loss= 0.7153, Training Accuracy= 0.508\n",
      "Epoch: 1800, Minibatch Loss= 0.6867, Training Accuracy= 0.546\n",
      "Epoch: 1810, Minibatch Loss= 0.6799, Training Accuracy= 0.562\n",
      "Epoch: 1820, Minibatch Loss= 0.6802, Training Accuracy= 0.556\n",
      "Epoch: 1830, Minibatch Loss= 0.6795, Training Accuracy= 0.562\n",
      "Epoch: 1840, Minibatch Loss= 0.6872, Training Accuracy= 0.542\n",
      "Epoch: 1850, Minibatch Loss= 0.6842, Training Accuracy= 0.557\n",
      "Epoch: 1860, Minibatch Loss= 0.7038, Training Accuracy= 0.526\n",
      "Epoch: 1870, Minibatch Loss= 0.6778, Training Accuracy= 0.567\n",
      "Epoch: 1880, Minibatch Loss= 0.6956, Training Accuracy= 0.514\n",
      "Epoch: 1890, Minibatch Loss= 0.6930, Training Accuracy= 0.525\n",
      "Epoch: 1900, Minibatch Loss= 0.6915, Training Accuracy= 0.524\n",
      "Epoch: 1910, Minibatch Loss= 0.6901, Training Accuracy= 0.530\n",
      "Epoch: 1920, Minibatch Loss= 0.6883, Training Accuracy= 0.537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1930, Minibatch Loss= 0.6860, Training Accuracy= 0.539\n",
      "Epoch: 1940, Minibatch Loss= 0.6947, Training Accuracy= 0.537\n",
      "Epoch: 1950, Minibatch Loss= 0.6931, Training Accuracy= 0.514\n",
      "Epoch: 1960, Minibatch Loss= 0.6913, Training Accuracy= 0.524\n",
      "Epoch: 1970, Minibatch Loss= 0.6905, Training Accuracy= 0.532\n",
      "Epoch: 1980, Minibatch Loss= 0.6897, Training Accuracy= 0.534\n",
      "Epoch: 1990, Minibatch Loss= 0.6885, Training Accuracy= 0.538\n",
      "Epoch: 2000, Minibatch Loss= 0.6873, Training Accuracy= 0.544\n",
      "Epoch: 2010, Minibatch Loss= 0.6855, Training Accuracy= 0.550\n",
      "Epoch: 2020, Minibatch Loss= 0.6850, Training Accuracy= 0.547\n",
      "Epoch: 2030, Minibatch Loss= 0.6846, Training Accuracy= 0.550\n",
      "Epoch: 2040, Minibatch Loss= 0.6870, Training Accuracy= 0.549\n",
      "Epoch: 2050, Minibatch Loss= 0.6853, Training Accuracy= 0.550\n",
      "Epoch: 2060, Minibatch Loss= 0.6820, Training Accuracy= 0.559\n",
      "Epoch: 2070, Minibatch Loss= 0.6816, Training Accuracy= 0.561\n",
      "Epoch: 2080, Minibatch Loss= 0.6832, Training Accuracy= 0.553\n",
      "Epoch: 2090, Minibatch Loss= 0.6840, Training Accuracy= 0.553\n",
      "Epoch: 2100, Minibatch Loss= 0.6770, Training Accuracy= 0.568\n",
      "Epoch: 2110, Minibatch Loss= 0.6795, Training Accuracy= 0.569\n",
      "Epoch: 2120, Minibatch Loss= 0.6773, Training Accuracy= 0.564\n",
      "Epoch: 2130, Minibatch Loss= 0.6718, Training Accuracy= 0.578\n",
      "Epoch: 2140, Minibatch Loss= 0.6705, Training Accuracy= 0.582\n",
      "Epoch: 2150, Minibatch Loss= 0.6696, Training Accuracy= 0.585\n",
      "Epoch: 2160, Minibatch Loss= 0.6719, Training Accuracy= 0.582\n",
      "Epoch: 2170, Minibatch Loss= 0.6675, Training Accuracy= 0.588\n",
      "Epoch: 2180, Minibatch Loss= 0.6666, Training Accuracy= 0.591\n",
      "Epoch: 2190, Minibatch Loss= 0.6719, Training Accuracy= 0.583\n",
      "Epoch: 2200, Minibatch Loss= 0.6666, Training Accuracy= 0.586\n",
      "Epoch: 2210, Minibatch Loss= 0.6719, Training Accuracy= 0.582\n",
      "Epoch: 2220, Minibatch Loss= 0.6649, Training Accuracy= 0.595\n",
      "Epoch: 2230, Minibatch Loss= 0.6637, Training Accuracy= 0.593\n",
      "Epoch: 2240, Minibatch Loss= 0.6602, Training Accuracy= 0.601\n",
      "Epoch: 2250, Minibatch Loss= 0.6609, Training Accuracy= 0.597\n",
      "Epoch: 2260, Minibatch Loss= 0.6708, Training Accuracy= 0.583\n",
      "Epoch: 2270, Minibatch Loss= 0.6698, Training Accuracy= 0.588\n",
      "Epoch: 2280, Minibatch Loss= 0.6680, Training Accuracy= 0.582\n",
      "Epoch: 2290, Minibatch Loss= 0.6618, Training Accuracy= 0.595\n",
      "Epoch: 2300, Minibatch Loss= 0.6736, Training Accuracy= 0.576\n",
      "Epoch: 2310, Minibatch Loss= 0.6913, Training Accuracy= 0.529\n",
      "Epoch: 2320, Minibatch Loss= 0.6884, Training Accuracy= 0.534\n",
      "Epoch: 2330, Minibatch Loss= 0.6850, Training Accuracy= 0.543\n",
      "Epoch: 2340, Minibatch Loss= 0.6824, Training Accuracy= 0.548\n",
      "Epoch: 2350, Minibatch Loss= 0.6793, Training Accuracy= 0.556\n",
      "Epoch: 2360, Minibatch Loss= 0.6909, Training Accuracy= 0.525\n",
      "Epoch: 2370, Minibatch Loss= 0.6882, Training Accuracy= 0.541\n",
      "Epoch: 2380, Minibatch Loss= 0.6856, Training Accuracy= 0.548\n",
      "Epoch: 2390, Minibatch Loss= 0.6845, Training Accuracy= 0.551\n",
      "Epoch: 2400, Minibatch Loss= 0.6808, Training Accuracy= 0.563\n",
      "Epoch: 2410, Minibatch Loss= 0.6864, Training Accuracy= 0.548\n",
      "Epoch: 2420, Minibatch Loss= 0.6894, Training Accuracy= 0.539\n",
      "Epoch: 2430, Minibatch Loss= 0.6828, Training Accuracy= 0.552\n",
      "Epoch: 2440, Minibatch Loss= 0.6786, Training Accuracy= 0.563\n",
      "Epoch: 2450, Minibatch Loss= 0.6917, Training Accuracy= 0.531\n",
      "Epoch: 2460, Minibatch Loss= 0.6934, Training Accuracy= 0.512\n",
      "Epoch: 2470, Minibatch Loss= 0.6915, Training Accuracy= 0.525\n",
      "Epoch: 2480, Minibatch Loss= 0.6903, Training Accuracy= 0.530\n",
      "Epoch: 2490, Minibatch Loss= 0.6895, Training Accuracy= 0.532\n",
      "Epoch: 2500, Minibatch Loss= 0.6887, Training Accuracy= 0.535\n",
      "Epoch: 2510, Minibatch Loss= 0.6879, Training Accuracy= 0.535\n",
      "Epoch: 2520, Minibatch Loss= 0.6872, Training Accuracy= 0.535\n",
      "Epoch: 2530, Minibatch Loss= 0.6921, Training Accuracy= 0.518\n",
      "Epoch: 2540, Minibatch Loss= 0.6894, Training Accuracy= 0.526\n",
      "Epoch: 2550, Minibatch Loss= 0.6881, Training Accuracy= 0.531\n",
      "Epoch: 2560, Minibatch Loss= 0.6867, Training Accuracy= 0.533\n",
      "Epoch: 2570, Minibatch Loss= 0.6854, Training Accuracy= 0.536\n",
      "Epoch: 2580, Minibatch Loss= 0.6840, Training Accuracy= 0.539\n",
      "Epoch: 2590, Minibatch Loss= 0.6832, Training Accuracy= 0.538\n",
      "Epoch: 2600, Minibatch Loss= 0.6832, Training Accuracy= 0.540\n",
      "Epoch: 2610, Minibatch Loss= 0.6813, Training Accuracy= 0.545\n",
      "Epoch: 2620, Minibatch Loss= 0.6843, Training Accuracy= 0.538\n",
      "Epoch: 2630, Minibatch Loss= 0.6784, Training Accuracy= 0.550\n",
      "Epoch: 2640, Minibatch Loss= 0.6764, Training Accuracy= 0.553\n",
      "Epoch: 2650, Minibatch Loss= 0.6849, Training Accuracy= 0.545\n",
      "Epoch: 2660, Minibatch Loss= 0.6804, Training Accuracy= 0.555\n",
      "Epoch: 2670, Minibatch Loss= 0.6771, Training Accuracy= 0.555\n",
      "Epoch: 2680, Minibatch Loss= 0.6862, Training Accuracy= 0.534\n",
      "Epoch: 2690, Minibatch Loss= 0.6796, Training Accuracy= 0.536\n",
      "Epoch: 2700, Minibatch Loss= 0.6784, Training Accuracy= 0.544\n",
      "Epoch: 2710, Minibatch Loss= 0.6747, Training Accuracy= 0.552\n",
      "Epoch: 2720, Minibatch Loss= 0.6768, Training Accuracy= 0.550\n",
      "Epoch: 2730, Minibatch Loss= 0.6902, Training Accuracy= 0.530\n",
      "Epoch: 2740, Minibatch Loss= 0.6984, Training Accuracy= 0.507\n",
      "Epoch: 2750, Minibatch Loss= 0.6929, Training Accuracy= 0.512\n",
      "Epoch: 2760, Minibatch Loss= 0.6917, Training Accuracy= 0.516\n",
      "Epoch: 2770, Minibatch Loss= 0.6909, Training Accuracy= 0.522\n",
      "Epoch: 2780, Minibatch Loss= 0.6902, Training Accuracy= 0.524\n",
      "Epoch: 2790, Minibatch Loss= 0.6897, Training Accuracy= 0.528\n",
      "Epoch: 2800, Minibatch Loss= 0.6893, Training Accuracy= 0.532\n",
      "Epoch: 2810, Minibatch Loss= 0.6897, Training Accuracy= 0.528\n",
      "Epoch: 2820, Minibatch Loss= 0.6884, Training Accuracy= 0.536\n",
      "Epoch: 2830, Minibatch Loss= 0.6890, Training Accuracy= 0.532\n",
      "Epoch: 2840, Minibatch Loss= 0.6855, Training Accuracy= 0.546\n",
      "Epoch: 2850, Minibatch Loss= 0.6843, Training Accuracy= 0.549\n",
      "Epoch: 2860, Minibatch Loss= 0.6831, Training Accuracy= 0.556\n",
      "Epoch: 2870, Minibatch Loss= 0.6820, Training Accuracy= 0.559\n",
      "Epoch: 2880, Minibatch Loss= 0.6816, Training Accuracy= 0.557\n",
      "Epoch: 2890, Minibatch Loss= 0.6796, Training Accuracy= 0.564\n",
      "Epoch: 2900, Minibatch Loss= 0.6881, Training Accuracy= 0.525\n",
      "Epoch: 2910, Minibatch Loss= 0.6870, Training Accuracy= 0.524\n",
      "Epoch: 2920, Minibatch Loss= 0.6864, Training Accuracy= 0.524\n",
      "Epoch: 2930, Minibatch Loss= 0.6856, Training Accuracy= 0.527\n",
      "Epoch: 2940, Minibatch Loss= 0.6849, Training Accuracy= 0.529\n",
      "Epoch: 2950, Minibatch Loss= 0.6843, Training Accuracy= 0.529\n",
      "Epoch: 2960, Minibatch Loss= 0.6836, Training Accuracy= 0.534\n",
      "Epoch: 2970, Minibatch Loss= 0.6826, Training Accuracy= 0.539\n",
      "Epoch: 2980, Minibatch Loss= 0.6801, Training Accuracy= 0.546\n",
      "Epoch: 2990, Minibatch Loss= 0.6772, Training Accuracy= 0.548\n",
      "Epoch: 3000, Minibatch Loss= 0.6746, Training Accuracy= 0.554\n",
      "Epoch: 3010, Minibatch Loss= 0.6723, Training Accuracy= 0.558\n",
      "Epoch: 3020, Minibatch Loss= 0.6705, Training Accuracy= 0.562\n",
      "Epoch: 3030, Minibatch Loss= 0.6665, Training Accuracy= 0.567\n",
      "Epoch: 3040, Minibatch Loss= 0.6656, Training Accuracy= 0.565\n",
      "Epoch: 3050, Minibatch Loss= 0.6626, Training Accuracy= 0.567\n",
      "Epoch: 3060, Minibatch Loss= 0.6623, Training Accuracy= 0.564\n",
      "Epoch: 3070, Minibatch Loss= 0.5925, Training Accuracy= 0.629\n",
      "Epoch: 3080, Minibatch Loss= 0.6030, Training Accuracy= 0.640\n",
      "Epoch: 3090, Minibatch Loss= 0.7349, Training Accuracy= 0.606\n",
      "Epoch: 3100, Minibatch Loss= 0.4376, Training Accuracy= 0.724\n",
      "Epoch: 3110, Minibatch Loss= 0.4015, Training Accuracy= 0.743\n",
      "Epoch: 3120, Minibatch Loss= 0.4918, Training Accuracy= 0.668\n",
      "Epoch: 3130, Minibatch Loss= 0.4767, Training Accuracy= 0.697\n",
      "Epoch: 3140, Minibatch Loss= 0.7092, Training Accuracy= 0.501\n",
      "Epoch: 3150, Minibatch Loss= 0.7029, Training Accuracy= 0.501\n",
      "Epoch: 3160, Minibatch Loss= 0.7002, Training Accuracy= 0.501\n",
      "Epoch: 3170, Minibatch Loss= 0.6987, Training Accuracy= 0.501\n",
      "Epoch: 3180, Minibatch Loss= 0.6978, Training Accuracy= 0.501\n",
      "Epoch: 3190, Minibatch Loss= 0.6970, Training Accuracy= 0.501\n",
      "Epoch: 3200, Minibatch Loss= 0.6964, Training Accuracy= 0.502\n",
      "Epoch: 3210, Minibatch Loss= 0.6959, Training Accuracy= 0.502\n",
      "Epoch: 3220, Minibatch Loss= 0.6955, Training Accuracy= 0.503\n",
      "Epoch: 3230, Minibatch Loss= 0.6952, Training Accuracy= 0.505\n",
      "Epoch: 3240, Minibatch Loss= 0.6949, Training Accuracy= 0.513\n",
      "Epoch: 3250, Minibatch Loss= 0.6947, Training Accuracy= 0.511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3260, Minibatch Loss= 0.6945, Training Accuracy= 0.511\n",
      "Epoch: 3270, Minibatch Loss= 0.6943, Training Accuracy= 0.513\n",
      "Epoch: 3280, Minibatch Loss= 0.6941, Training Accuracy= 0.511\n",
      "Epoch: 3290, Minibatch Loss= 0.6942, Training Accuracy= 0.512\n",
      "Epoch: 3300, Minibatch Loss= 0.6941, Training Accuracy= 0.513\n",
      "Epoch: 3310, Minibatch Loss= 0.6938, Training Accuracy= 0.512\n",
      "Epoch: 3320, Minibatch Loss= 0.6936, Training Accuracy= 0.515\n",
      "Epoch: 3330, Minibatch Loss= 0.6933, Training Accuracy= 0.517\n",
      "Epoch: 3340, Minibatch Loss= 0.6932, Training Accuracy= 0.515\n",
      "Epoch: 3350, Minibatch Loss= 0.6929, Training Accuracy= 0.517\n",
      "Epoch: 3360, Minibatch Loss= 0.6928, Training Accuracy= 0.518\n",
      "Epoch: 3370, Minibatch Loss= 0.6927, Training Accuracy= 0.516\n",
      "Epoch: 3380, Minibatch Loss= 0.6926, Training Accuracy= 0.519\n",
      "Epoch: 3390, Minibatch Loss= 0.6925, Training Accuracy= 0.519\n",
      "Epoch: 3400, Minibatch Loss= 0.6924, Training Accuracy= 0.520\n",
      "Epoch: 3410, Minibatch Loss= 0.6923, Training Accuracy= 0.520\n",
      "Epoch: 3420, Minibatch Loss= 0.6922, Training Accuracy= 0.520\n",
      "Epoch: 3430, Minibatch Loss= 0.6920, Training Accuracy= 0.522\n",
      "Epoch: 3440, Minibatch Loss= 0.6919, Training Accuracy= 0.523\n",
      "Epoch: 3450, Minibatch Loss= 0.6918, Training Accuracy= 0.523\n",
      "Epoch: 3460, Minibatch Loss= 0.6917, Training Accuracy= 0.525\n",
      "Epoch: 3470, Minibatch Loss= 0.6916, Training Accuracy= 0.526\n",
      "Epoch: 3480, Minibatch Loss= 0.6915, Training Accuracy= 0.525\n",
      "Epoch: 3490, Minibatch Loss= 0.6914, Training Accuracy= 0.525\n",
      "Epoch: 3500, Minibatch Loss= 0.6913, Training Accuracy= 0.526\n",
      "Epoch: 3510, Minibatch Loss= 0.6912, Training Accuracy= 0.526\n",
      "Epoch: 3520, Minibatch Loss= 0.6912, Training Accuracy= 0.525\n",
      "Epoch: 3530, Minibatch Loss= 0.6911, Training Accuracy= 0.527\n",
      "Epoch: 3540, Minibatch Loss= 0.6912, Training Accuracy= 0.525\n",
      "Epoch: 3550, Minibatch Loss= 0.6915, Training Accuracy= 0.526\n",
      "Epoch: 3560, Minibatch Loss= 0.6919, Training Accuracy= 0.527\n",
      "Epoch: 3570, Minibatch Loss= 0.6914, Training Accuracy= 0.527\n",
      "Epoch: 3580, Minibatch Loss= 0.6913, Training Accuracy= 0.527\n",
      "Epoch: 3590, Minibatch Loss= 0.6912, Training Accuracy= 0.527\n",
      "Epoch: 3600, Minibatch Loss= 0.6912, Training Accuracy= 0.526\n",
      "Epoch: 3610, Minibatch Loss= 0.6912, Training Accuracy= 0.526\n",
      "Epoch: 3620, Minibatch Loss= 0.6912, Training Accuracy= 0.527\n",
      "Epoch: 3630, Minibatch Loss= 0.6908, Training Accuracy= 0.525\n",
      "Epoch: 3640, Minibatch Loss= 0.6911, Training Accuracy= 0.528\n",
      "Epoch: 3650, Minibatch Loss= 0.6910, Training Accuracy= 0.525\n",
      "Epoch: 3660, Minibatch Loss= 0.6908, Training Accuracy= 0.528\n",
      "Epoch: 3670, Minibatch Loss= 0.6906, Training Accuracy= 0.527\n",
      "Epoch: 3680, Minibatch Loss= 0.6901, Training Accuracy= 0.527\n",
      "Epoch: 3690, Minibatch Loss= 0.6916, Training Accuracy= 0.526\n",
      "Epoch: 3700, Minibatch Loss= 0.6921, Training Accuracy= 0.529\n",
      "Epoch: 3710, Minibatch Loss= 0.6903, Training Accuracy= 0.529\n",
      "Epoch: 3720, Minibatch Loss= 0.6906, Training Accuracy= 0.528\n",
      "Epoch: 3730, Minibatch Loss= 0.6895, Training Accuracy= 0.530\n",
      "Epoch: 3740, Minibatch Loss= 0.6905, Training Accuracy= 0.531\n",
      "Epoch: 3750, Minibatch Loss= 0.6922, Training Accuracy= 0.530\n",
      "Epoch: 3760, Minibatch Loss= 0.6901, Training Accuracy= 0.531\n",
      "Epoch: 3770, Minibatch Loss= 0.6899, Training Accuracy= 0.537\n",
      "Epoch: 3780, Minibatch Loss= 0.6890, Training Accuracy= 0.536\n",
      "Epoch: 3790, Minibatch Loss= 0.6886, Training Accuracy= 0.536\n",
      "Epoch: 3800, Minibatch Loss= 0.6887, Training Accuracy= 0.537\n",
      "Epoch: 3810, Minibatch Loss= 0.6884, Training Accuracy= 0.535\n",
      "Epoch: 3820, Minibatch Loss= 0.6874, Training Accuracy= 0.539\n",
      "Epoch: 3830, Minibatch Loss= 0.6905, Training Accuracy= 0.538\n",
      "Epoch: 3840, Minibatch Loss= 0.6891, Training Accuracy= 0.539\n",
      "Epoch: 3850, Minibatch Loss= 0.6884, Training Accuracy= 0.540\n",
      "Epoch: 3860, Minibatch Loss= 0.6885, Training Accuracy= 0.541\n",
      "Epoch: 3870, Minibatch Loss= 0.6883, Training Accuracy= 0.543\n",
      "Epoch: 3880, Minibatch Loss= 0.6877, Training Accuracy= 0.540\n",
      "Epoch: 3890, Minibatch Loss= 0.6869, Training Accuracy= 0.541\n",
      "Epoch: 3900, Minibatch Loss= 0.6881, Training Accuracy= 0.534\n",
      "Epoch: 3910, Minibatch Loss= 0.6875, Training Accuracy= 0.536\n",
      "Epoch: 3920, Minibatch Loss= 0.6854, Training Accuracy= 0.541\n",
      "Epoch: 3930, Minibatch Loss= 0.6851, Training Accuracy= 0.542\n",
      "Epoch: 3940, Minibatch Loss= 0.6850, Training Accuracy= 0.541\n",
      "Epoch: 3950, Minibatch Loss= 0.6843, Training Accuracy= 0.543\n",
      "Epoch: 3960, Minibatch Loss= 0.6841, Training Accuracy= 0.544\n",
      "Epoch: 3970, Minibatch Loss= 0.6842, Training Accuracy= 0.546\n",
      "Epoch: 3980, Minibatch Loss= 0.6866, Training Accuracy= 0.546\n",
      "Epoch: 3990, Minibatch Loss= 0.6883, Training Accuracy= 0.544\n",
      "Epoch: 4000, Minibatch Loss= 0.6832, Training Accuracy= 0.550\n",
      "Epoch: 4010, Minibatch Loss= 0.6831, Training Accuracy= 0.552\n",
      "Epoch: 4020, Minibatch Loss= 0.6895, Training Accuracy= 0.531\n",
      "Epoch: 4030, Minibatch Loss= 0.6892, Training Accuracy= 0.531\n",
      "Epoch: 4040, Minibatch Loss= 0.6887, Training Accuracy= 0.532\n",
      "Epoch: 4050, Minibatch Loss= 0.6860, Training Accuracy= 0.540\n",
      "Epoch: 4060, Minibatch Loss= 0.6862, Training Accuracy= 0.543\n",
      "Epoch: 4070, Minibatch Loss= 0.6886, Training Accuracy= 0.545\n",
      "Epoch: 4080, Minibatch Loss= 0.6854, Training Accuracy= 0.546\n",
      "Epoch: 4090, Minibatch Loss= 0.6858, Training Accuracy= 0.548\n",
      "Epoch: 4100, Minibatch Loss= 0.6876, Training Accuracy= 0.549\n",
      "Epoch: 4110, Minibatch Loss= 0.6838, Training Accuracy= 0.549\n",
      "Epoch: 4120, Minibatch Loss= 0.6846, Training Accuracy= 0.546\n",
      "Epoch: 4130, Minibatch Loss= 0.6839, Training Accuracy= 0.544\n",
      "Epoch: 4140, Minibatch Loss= 0.6811, Training Accuracy= 0.546\n",
      "Epoch: 4150, Minibatch Loss= 0.6820, Training Accuracy= 0.543\n",
      "Epoch: 4160, Minibatch Loss= 0.6858, Training Accuracy= 0.546\n",
      "Epoch: 4170, Minibatch Loss= 0.6784, Training Accuracy= 0.553\n",
      "Epoch: 4180, Minibatch Loss= 0.6797, Training Accuracy= 0.550\n",
      "Epoch: 4190, Minibatch Loss= 0.6779, Training Accuracy= 0.560\n",
      "Epoch: 4200, Minibatch Loss= 0.6811, Training Accuracy= 0.550\n",
      "Epoch: 4210, Minibatch Loss= 0.6800, Training Accuracy= 0.554\n",
      "Epoch: 4220, Minibatch Loss= 0.6807, Training Accuracy= 0.555\n",
      "Epoch: 4230, Minibatch Loss= 0.6760, Training Accuracy= 0.558\n",
      "Epoch: 4240, Minibatch Loss= 0.6735, Training Accuracy= 0.566\n",
      "Epoch: 4250, Minibatch Loss= 0.6731, Training Accuracy= 0.565\n",
      "Epoch: 4260, Minibatch Loss= 0.6752, Training Accuracy= 0.558\n",
      "Epoch: 4270, Minibatch Loss= 0.6726, Training Accuracy= 0.563\n",
      "Epoch: 4280, Minibatch Loss= 0.6795, Training Accuracy= 0.559\n",
      "Epoch: 4290, Minibatch Loss= 0.6733, Training Accuracy= 0.567\n",
      "Epoch: 4300, Minibatch Loss= 0.6717, Training Accuracy= 0.565\n",
      "Epoch: 4310, Minibatch Loss= 0.6757, Training Accuracy= 0.563\n",
      "Epoch: 4320, Minibatch Loss= 0.6833, Training Accuracy= 0.557\n",
      "Epoch: 4330, Minibatch Loss= 0.6844, Training Accuracy= 0.549\n",
      "Epoch: 4340, Minibatch Loss= 0.6812, Training Accuracy= 0.549\n",
      "Epoch: 4350, Minibatch Loss= 0.6740, Training Accuracy= 0.570\n",
      "Epoch: 4360, Minibatch Loss= 0.6707, Training Accuracy= 0.569\n",
      "Epoch: 4370, Minibatch Loss= 0.6722, Training Accuracy= 0.566\n",
      "Epoch: 4380, Minibatch Loss= 0.6706, Training Accuracy= 0.567\n",
      "Epoch: 4390, Minibatch Loss= 0.6813, Training Accuracy= 0.557\n",
      "Epoch: 4400, Minibatch Loss= 0.6663, Training Accuracy= 0.574\n",
      "Epoch: 4410, Minibatch Loss= 0.6732, Training Accuracy= 0.573\n",
      "Epoch: 4420, Minibatch Loss= 0.6707, Training Accuracy= 0.574\n",
      "Epoch: 4430, Minibatch Loss= 0.6742, Training Accuracy= 0.565\n",
      "Epoch: 4440, Minibatch Loss= 0.6698, Training Accuracy= 0.571\n",
      "Epoch: 4450, Minibatch Loss= 0.6756, Training Accuracy= 0.570\n",
      "Epoch: 4460, Minibatch Loss= 0.6654, Training Accuracy= 0.580\n",
      "Epoch: 4470, Minibatch Loss= 0.6802, Training Accuracy= 0.557\n",
      "Epoch: 4480, Minibatch Loss= 0.6993, Training Accuracy= 0.510\n",
      "Epoch: 4490, Minibatch Loss= 0.6933, Training Accuracy= 0.516\n",
      "Epoch: 4500, Minibatch Loss= 0.6914, Training Accuracy= 0.528\n",
      "Epoch: 4510, Minibatch Loss= 0.6901, Training Accuracy= 0.532\n",
      "Epoch: 4520, Minibatch Loss= 0.6888, Training Accuracy= 0.535\n",
      "Epoch: 4530, Minibatch Loss= 0.6878, Training Accuracy= 0.536\n",
      "Epoch: 4540, Minibatch Loss= 0.6867, Training Accuracy= 0.545\n",
      "Epoch: 4550, Minibatch Loss= 0.7007, Training Accuracy= 0.498\n",
      "Epoch: 4560, Minibatch Loss= 0.6975, Training Accuracy= 0.502\n",
      "Epoch: 4570, Minibatch Loss= 0.6960, Training Accuracy= 0.502\n",
      "Epoch: 4580, Minibatch Loss= 0.6950, Training Accuracy= 0.499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4590, Minibatch Loss= 0.6944, Training Accuracy= 0.501\n",
      "Epoch: 4600, Minibatch Loss= 0.6940, Training Accuracy= 0.502\n",
      "Epoch: 4610, Minibatch Loss= 0.6937, Training Accuracy= 0.504\n",
      "Epoch: 4620, Minibatch Loss= 0.6936, Training Accuracy= 0.507\n",
      "Epoch: 4630, Minibatch Loss= 0.6935, Training Accuracy= 0.509\n",
      "Epoch: 4640, Minibatch Loss= 0.6934, Training Accuracy= 0.509\n",
      "Epoch: 4650, Minibatch Loss= 0.6934, Training Accuracy= 0.510\n",
      "Epoch: 4660, Minibatch Loss= 0.6934, Training Accuracy= 0.512\n",
      "Epoch: 4670, Minibatch Loss= 0.6934, Training Accuracy= 0.512\n",
      "Epoch: 4680, Minibatch Loss= 0.6934, Training Accuracy= 0.513\n",
      "Epoch: 4690, Minibatch Loss= 0.6934, Training Accuracy= 0.513\n",
      "Epoch: 4700, Minibatch Loss= 0.6934, Training Accuracy= 0.512\n",
      "Epoch: 4710, Minibatch Loss= 0.6933, Training Accuracy= 0.512\n",
      "Epoch: 4720, Minibatch Loss= 0.6933, Training Accuracy= 0.512\n",
      "Epoch: 4730, Minibatch Loss= 0.6933, Training Accuracy= 0.510\n",
      "Epoch: 4740, Minibatch Loss= 0.6933, Training Accuracy= 0.509\n",
      "Epoch: 4750, Minibatch Loss= 0.6933, Training Accuracy= 0.511\n",
      "Epoch: 4760, Minibatch Loss= 0.6933, Training Accuracy= 0.512\n",
      "Epoch: 4770, Minibatch Loss= 0.6932, Training Accuracy= 0.512\n",
      "Epoch: 4780, Minibatch Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 4790, Minibatch Loss= 0.6932, Training Accuracy= 0.511\n",
      "Epoch: 4800, Minibatch Loss= 0.6932, Training Accuracy= 0.512\n",
      "Epoch: 4810, Minibatch Loss= 0.6932, Training Accuracy= 0.512\n",
      "Epoch: 4820, Minibatch Loss= 0.6931, Training Accuracy= 0.512\n",
      "Epoch: 4830, Minibatch Loss= 0.6930, Training Accuracy= 0.512\n",
      "Epoch: 4840, Minibatch Loss= 0.6929, Training Accuracy= 0.513\n",
      "Epoch: 4850, Minibatch Loss= 0.6927, Training Accuracy= 0.512\n",
      "Epoch: 4860, Minibatch Loss= 0.6926, Training Accuracy= 0.513\n",
      "Epoch: 4870, Minibatch Loss= 0.6925, Training Accuracy= 0.513\n",
      "Epoch: 4880, Minibatch Loss= 0.6924, Training Accuracy= 0.513\n",
      "Epoch: 4890, Minibatch Loss= 0.6923, Training Accuracy= 0.515\n",
      "Epoch: 4900, Minibatch Loss= 0.6923, Training Accuracy= 0.518\n",
      "Epoch: 4910, Minibatch Loss= 0.6922, Training Accuracy= 0.519\n",
      "Epoch: 4920, Minibatch Loss= 0.6922, Training Accuracy= 0.518\n",
      "Epoch: 4930, Minibatch Loss= 0.6921, Training Accuracy= 0.519\n",
      "Epoch: 4940, Minibatch Loss= 0.6921, Training Accuracy= 0.518\n",
      "Epoch: 4950, Minibatch Loss= 0.6920, Training Accuracy= 0.520\n",
      "Epoch: 4960, Minibatch Loss= 0.6919, Training Accuracy= 0.522\n",
      "Epoch: 4970, Minibatch Loss= 0.6919, Training Accuracy= 0.522\n",
      "Epoch: 4980, Minibatch Loss= 0.6918, Training Accuracy= 0.523\n",
      "Epoch: 4990, Minibatch Loss= 0.6918, Training Accuracy= 0.522\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.4999\n",
      "Replication: 7: \n",
      "Epoch: 0, Minibatch Loss= 0.7030, Training Accuracy= 0.508\n",
      "Epoch: 10, Minibatch Loss= 0.6933, Training Accuracy= 0.508\n",
      "Epoch: 20, Minibatch Loss= 0.6930, Training Accuracy= 0.508\n",
      "Epoch: 30, Minibatch Loss= 0.6929, Training Accuracy= 0.509\n",
      "Epoch: 40, Minibatch Loss= 0.6929, Training Accuracy= 0.511\n",
      "Epoch: 50, Minibatch Loss= 0.6929, Training Accuracy= 0.511\n",
      "Epoch: 60, Minibatch Loss= 0.6929, Training Accuracy= 0.512\n",
      "Epoch: 70, Minibatch Loss= 0.6929, Training Accuracy= 0.512\n",
      "Epoch: 80, Minibatch Loss= 0.6928, Training Accuracy= 0.512\n",
      "Epoch: 90, Minibatch Loss= 0.6928, Training Accuracy= 0.512\n",
      "Epoch: 100, Minibatch Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 110, Minibatch Loss= 0.6928, Training Accuracy= 0.511\n",
      "Epoch: 120, Minibatch Loss= 0.6927, Training Accuracy= 0.512\n",
      "Epoch: 130, Minibatch Loss= 0.6927, Training Accuracy= 0.511\n",
      "Epoch: 140, Minibatch Loss= 0.6927, Training Accuracy= 0.511\n",
      "Epoch: 150, Minibatch Loss= 0.6926, Training Accuracy= 0.515\n",
      "Epoch: 160, Minibatch Loss= 0.6925, Training Accuracy= 0.516\n",
      "Epoch: 170, Minibatch Loss= 0.6925, Training Accuracy= 0.516\n",
      "Epoch: 180, Minibatch Loss= 0.6924, Training Accuracy= 0.518\n",
      "Epoch: 190, Minibatch Loss= 0.6924, Training Accuracy= 0.518\n",
      "Epoch: 200, Minibatch Loss= 0.6923, Training Accuracy= 0.517\n",
      "Epoch: 210, Minibatch Loss= 0.6923, Training Accuracy= 0.517\n",
      "Epoch: 220, Minibatch Loss= 0.6923, Training Accuracy= 0.519\n",
      "Epoch: 230, Minibatch Loss= 0.6923, Training Accuracy= 0.519\n",
      "Epoch: 240, Minibatch Loss= 0.6922, Training Accuracy= 0.517\n",
      "Epoch: 250, Minibatch Loss= 0.6922, Training Accuracy= 0.518\n",
      "Epoch: 260, Minibatch Loss= 0.6922, Training Accuracy= 0.518\n",
      "Epoch: 270, Minibatch Loss= 0.6921, Training Accuracy= 0.519\n",
      "Epoch: 280, Minibatch Loss= 0.6921, Training Accuracy= 0.519\n",
      "Epoch: 290, Minibatch Loss= 0.6921, Training Accuracy= 0.520\n",
      "Epoch: 300, Minibatch Loss= 0.6920, Training Accuracy= 0.521\n",
      "Epoch: 310, Minibatch Loss= 0.6920, Training Accuracy= 0.521\n",
      "Epoch: 320, Minibatch Loss= 0.6919, Training Accuracy= 0.521\n",
      "Epoch: 330, Minibatch Loss= 0.6919, Training Accuracy= 0.522\n",
      "Epoch: 340, Minibatch Loss= 0.6919, Training Accuracy= 0.522\n",
      "Epoch: 350, Minibatch Loss= 0.6919, Training Accuracy= 0.521\n",
      "Epoch: 360, Minibatch Loss= 0.6919, Training Accuracy= 0.522\n",
      "Epoch: 370, Minibatch Loss= 0.6919, Training Accuracy= 0.521\n",
      "Epoch: 380, Minibatch Loss= 0.6919, Training Accuracy= 0.522\n",
      "Epoch: 390, Minibatch Loss= 0.6919, Training Accuracy= 0.522\n",
      "Epoch: 400, Minibatch Loss= 0.6918, Training Accuracy= 0.522\n",
      "Epoch: 410, Minibatch Loss= 0.6915, Training Accuracy= 0.526\n",
      "Epoch: 420, Minibatch Loss= 0.6914, Training Accuracy= 0.524\n",
      "Epoch: 430, Minibatch Loss= 0.6917, Training Accuracy= 0.524\n",
      "Epoch: 440, Minibatch Loss= 0.6913, Training Accuracy= 0.527\n",
      "Epoch: 450, Minibatch Loss= 0.6919, Training Accuracy= 0.525\n",
      "Epoch: 460, Minibatch Loss= 0.6907, Training Accuracy= 0.528\n",
      "Epoch: 470, Minibatch Loss= 0.6952, Training Accuracy= 0.515\n",
      "Epoch: 480, Minibatch Loss= 0.6899, Training Accuracy= 0.531\n",
      "Epoch: 490, Minibatch Loss= 0.6897, Training Accuracy= 0.529\n",
      "Epoch: 500, Minibatch Loss= 0.6889, Training Accuracy= 0.535\n",
      "Epoch: 510, Minibatch Loss= 0.6878, Training Accuracy= 0.539\n",
      "Epoch: 520, Minibatch Loss= 0.6882, Training Accuracy= 0.541\n",
      "Epoch: 530, Minibatch Loss= 0.6871, Training Accuracy= 0.542\n",
      "Epoch: 540, Minibatch Loss= 0.6917, Training Accuracy= 0.530\n",
      "Epoch: 550, Minibatch Loss= 0.6876, Training Accuracy= 0.543\n",
      "Epoch: 560, Minibatch Loss= 0.6848, Training Accuracy= 0.549\n",
      "Epoch: 570, Minibatch Loss= 0.6863, Training Accuracy= 0.554\n",
      "Epoch: 580, Minibatch Loss= 0.6923, Training Accuracy= 0.532\n",
      "Epoch: 590, Minibatch Loss= 0.6853, Training Accuracy= 0.554\n",
      "Epoch: 600, Minibatch Loss= 0.6832, Training Accuracy= 0.562\n",
      "Epoch: 610, Minibatch Loss= 0.6795, Training Accuracy= 0.572\n",
      "Epoch: 620, Minibatch Loss= 0.6802, Training Accuracy= 0.567\n",
      "Epoch: 630, Minibatch Loss= 0.6822, Training Accuracy= 0.560\n",
      "Epoch: 640, Minibatch Loss= 0.6818, Training Accuracy= 0.565\n",
      "Epoch: 650, Minibatch Loss= 0.6818, Training Accuracy= 0.559\n",
      "Epoch: 660, Minibatch Loss= 0.6833, Training Accuracy= 0.564\n",
      "Epoch: 670, Minibatch Loss= 0.6847, Training Accuracy= 0.559\n",
      "Epoch: 680, Minibatch Loss= 0.6775, Training Accuracy= 0.575\n",
      "Epoch: 690, Minibatch Loss= 0.6949, Training Accuracy= 0.515\n",
      "Epoch: 700, Minibatch Loss= 0.6931, Training Accuracy= 0.519\n",
      "Epoch: 710, Minibatch Loss= 0.6914, Training Accuracy= 0.521\n",
      "Epoch: 720, Minibatch Loss= 0.6902, Training Accuracy= 0.526\n",
      "Epoch: 730, Minibatch Loss= 0.6911, Training Accuracy= 0.524\n",
      "Epoch: 740, Minibatch Loss= 0.6899, Training Accuracy= 0.527\n",
      "Epoch: 750, Minibatch Loss= 0.6892, Training Accuracy= 0.532\n",
      "Epoch: 760, Minibatch Loss= 0.6885, Training Accuracy= 0.532\n",
      "Epoch: 770, Minibatch Loss= 0.6877, Training Accuracy= 0.533\n",
      "Epoch: 780, Minibatch Loss= 0.6872, Training Accuracy= 0.539\n",
      "Epoch: 790, Minibatch Loss= 0.6868, Training Accuracy= 0.539\n",
      "Epoch: 800, Minibatch Loss= 0.6884, Training Accuracy= 0.536\n",
      "Epoch: 810, Minibatch Loss= 0.6872, Training Accuracy= 0.534\n",
      "Epoch: 820, Minibatch Loss= 0.6849, Training Accuracy= 0.546\n",
      "Epoch: 830, Minibatch Loss= 0.6946, Training Accuracy= 0.514\n",
      "Epoch: 840, Minibatch Loss= 0.6909, Training Accuracy= 0.529\n",
      "Epoch: 850, Minibatch Loss= 0.6898, Training Accuracy= 0.529\n",
      "Epoch: 860, Minibatch Loss= 0.6885, Training Accuracy= 0.535\n",
      "Epoch: 870, Minibatch Loss= 0.6876, Training Accuracy= 0.538\n",
      "Epoch: 880, Minibatch Loss= 0.6861, Training Accuracy= 0.542\n",
      "Epoch: 890, Minibatch Loss= 0.6866, Training Accuracy= 0.543\n",
      "Epoch: 900, Minibatch Loss= 0.6851, Training Accuracy= 0.543\n",
      "Epoch: 910, Minibatch Loss= 0.6859, Training Accuracy= 0.543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 920, Minibatch Loss= 0.6843, Training Accuracy= 0.545\n",
      "Epoch: 930, Minibatch Loss= 0.6856, Training Accuracy= 0.543\n",
      "Epoch: 940, Minibatch Loss= 0.6913, Training Accuracy= 0.527\n",
      "Epoch: 950, Minibatch Loss= 0.6894, Training Accuracy= 0.531\n",
      "Epoch: 960, Minibatch Loss= 0.6887, Training Accuracy= 0.534\n",
      "Epoch: 970, Minibatch Loss= 0.6887, Training Accuracy= 0.535\n",
      "Epoch: 980, Minibatch Loss= 0.6875, Training Accuracy= 0.535\n",
      "Epoch: 990, Minibatch Loss= 0.6872, Training Accuracy= 0.537\n",
      "Epoch: 1000, Minibatch Loss= 0.6882, Training Accuracy= 0.536\n",
      "Epoch: 1010, Minibatch Loss= 0.7033, Training Accuracy= 0.513\n",
      "Epoch: 1020, Minibatch Loss= 0.7047, Training Accuracy= 0.508\n",
      "Epoch: 1030, Minibatch Loss= 0.6984, Training Accuracy= 0.508\n",
      "Epoch: 1040, Minibatch Loss= 0.6957, Training Accuracy= 0.508\n",
      "Epoch: 1050, Minibatch Loss= 0.6946, Training Accuracy= 0.508\n",
      "Epoch: 1060, Minibatch Loss= 0.6940, Training Accuracy= 0.509\n",
      "Epoch: 1070, Minibatch Loss= 0.6935, Training Accuracy= 0.511\n",
      "Epoch: 1080, Minibatch Loss= 0.6931, Training Accuracy= 0.512\n",
      "Epoch: 1090, Minibatch Loss= 0.6928, Training Accuracy= 0.516\n",
      "Epoch: 1100, Minibatch Loss= 0.6926, Training Accuracy= 0.519\n",
      "Epoch: 1110, Minibatch Loss= 0.6925, Training Accuracy= 0.521\n",
      "Epoch: 1120, Minibatch Loss= 0.6924, Training Accuracy= 0.521\n",
      "Epoch: 1130, Minibatch Loss= 0.6924, Training Accuracy= 0.522\n",
      "Epoch: 1140, Minibatch Loss= 0.6924, Training Accuracy= 0.521\n",
      "Epoch: 1150, Minibatch Loss= 0.6923, Training Accuracy= 0.524\n",
      "Epoch: 1160, Minibatch Loss= 0.6923, Training Accuracy= 0.522\n",
      "Epoch: 1170, Minibatch Loss= 0.6921, Training Accuracy= 0.522\n",
      "Epoch: 1180, Minibatch Loss= 0.6918, Training Accuracy= 0.523\n",
      "Epoch: 1190, Minibatch Loss= 0.6917, Training Accuracy= 0.523\n",
      "Epoch: 1200, Minibatch Loss= 0.6912, Training Accuracy= 0.528\n",
      "Epoch: 1210, Minibatch Loss= 0.6910, Training Accuracy= 0.525\n",
      "Epoch: 1220, Minibatch Loss= 0.6919, Training Accuracy= 0.525\n",
      "Epoch: 1230, Minibatch Loss= 0.6932, Training Accuracy= 0.522\n",
      "Epoch: 1240, Minibatch Loss= 0.6921, Training Accuracy= 0.522\n",
      "Epoch: 1250, Minibatch Loss= 0.6909, Training Accuracy= 0.533\n",
      "Epoch: 1260, Minibatch Loss= 0.6911, Training Accuracy= 0.527\n",
      "Epoch: 1270, Minibatch Loss= 0.6898, Training Accuracy= 0.533\n",
      "Epoch: 1280, Minibatch Loss= 0.6911, Training Accuracy= 0.533\n",
      "Epoch: 1290, Minibatch Loss= 0.6919, Training Accuracy= 0.529\n",
      "Epoch: 1300, Minibatch Loss= 0.6914, Training Accuracy= 0.531\n",
      "Epoch: 1310, Minibatch Loss= 0.6911, Training Accuracy= 0.532\n",
      "Epoch: 1320, Minibatch Loss= 0.6899, Training Accuracy= 0.534\n",
      "Epoch: 1330, Minibatch Loss= 0.6886, Training Accuracy= 0.537\n",
      "Epoch: 1340, Minibatch Loss= 0.6959, Training Accuracy= 0.520\n",
      "Epoch: 1350, Minibatch Loss= 0.6929, Training Accuracy= 0.532\n",
      "Epoch: 1360, Minibatch Loss= 0.6914, Training Accuracy= 0.531\n",
      "Epoch: 1370, Minibatch Loss= 0.6899, Training Accuracy= 0.530\n",
      "Epoch: 1380, Minibatch Loss= 0.6894, Training Accuracy= 0.534\n",
      "Epoch: 1390, Minibatch Loss= 0.6915, Training Accuracy= 0.518\n",
      "Epoch: 1400, Minibatch Loss= 0.6889, Training Accuracy= 0.539\n",
      "Epoch: 1410, Minibatch Loss= 0.6904, Training Accuracy= 0.533\n",
      "Epoch: 1420, Minibatch Loss= 0.6888, Training Accuracy= 0.535\n",
      "Epoch: 1430, Minibatch Loss= 0.6938, Training Accuracy= 0.519\n",
      "Epoch: 1440, Minibatch Loss= 0.6913, Training Accuracy= 0.525\n",
      "Epoch: 1450, Minibatch Loss= 0.6911, Training Accuracy= 0.523\n",
      "Epoch: 1460, Minibatch Loss= 0.6901, Training Accuracy= 0.526\n",
      "Epoch: 1470, Minibatch Loss= 0.6907, Training Accuracy= 0.526\n",
      "Epoch: 1480, Minibatch Loss= 0.6929, Training Accuracy= 0.520\n",
      "Epoch: 1490, Minibatch Loss= 0.6905, Training Accuracy= 0.531\n",
      "Epoch: 1500, Minibatch Loss= 0.6895, Training Accuracy= 0.537\n",
      "Epoch: 1510, Minibatch Loss= 0.6895, Training Accuracy= 0.533\n",
      "Epoch: 1520, Minibatch Loss= 0.6889, Training Accuracy= 0.533\n",
      "Epoch: 1530, Minibatch Loss= 0.6890, Training Accuracy= 0.532\n",
      "Epoch: 1540, Minibatch Loss= 0.6872, Training Accuracy= 0.539\n",
      "Epoch: 1550, Minibatch Loss= 0.6886, Training Accuracy= 0.533\n",
      "Epoch: 1560, Minibatch Loss= 0.6883, Training Accuracy= 0.541\n",
      "Epoch: 1570, Minibatch Loss= 0.6879, Training Accuracy= 0.534\n",
      "Epoch: 1580, Minibatch Loss= 0.6872, Training Accuracy= 0.535\n",
      "Epoch: 1590, Minibatch Loss= 0.6949, Training Accuracy= 0.509\n",
      "Epoch: 1600, Minibatch Loss= 0.6927, Training Accuracy= 0.518\n",
      "Epoch: 1610, Minibatch Loss= 0.6916, Training Accuracy= 0.526\n",
      "Epoch: 1620, Minibatch Loss= 0.6908, Training Accuracy= 0.527\n",
      "Epoch: 1630, Minibatch Loss= 0.6918, Training Accuracy= 0.523\n",
      "Epoch: 1640, Minibatch Loss= 0.6901, Training Accuracy= 0.529\n",
      "Epoch: 1650, Minibatch Loss= 0.6899, Training Accuracy= 0.532\n",
      "Epoch: 1660, Minibatch Loss= 0.6899, Training Accuracy= 0.530\n",
      "Epoch: 1670, Minibatch Loss= 0.6896, Training Accuracy= 0.527\n",
      "Epoch: 1680, Minibatch Loss= 0.6912, Training Accuracy= 0.528\n",
      "Epoch: 1690, Minibatch Loss= 0.6888, Training Accuracy= 0.534\n",
      "Epoch: 1700, Minibatch Loss= 0.6897, Training Accuracy= 0.532\n",
      "Epoch: 1710, Minibatch Loss= 0.6928, Training Accuracy= 0.515\n",
      "Epoch: 1720, Minibatch Loss= 0.6908, Training Accuracy= 0.527\n",
      "Epoch: 1730, Minibatch Loss= 0.6944, Training Accuracy= 0.518\n",
      "Epoch: 1740, Minibatch Loss= 0.6929, Training Accuracy= 0.518\n",
      "Epoch: 1750, Minibatch Loss= 0.6924, Training Accuracy= 0.523\n",
      "Epoch: 1760, Minibatch Loss= 0.6918, Training Accuracy= 0.525\n",
      "Epoch: 1770, Minibatch Loss= 0.6919, Training Accuracy= 0.524\n",
      "Epoch: 1780, Minibatch Loss= 0.6912, Training Accuracy= 0.528\n",
      "Epoch: 1790, Minibatch Loss= 0.6910, Training Accuracy= 0.530\n",
      "Epoch: 1800, Minibatch Loss= 0.6913, Training Accuracy= 0.528\n",
      "Epoch: 1810, Minibatch Loss= 0.6902, Training Accuracy= 0.529\n",
      "Epoch: 1820, Minibatch Loss= 0.6908, Training Accuracy= 0.528\n",
      "Epoch: 1830, Minibatch Loss= 0.6905, Training Accuracy= 0.530\n",
      "Epoch: 1840, Minibatch Loss= 0.6897, Training Accuracy= 0.537\n",
      "Epoch: 1850, Minibatch Loss= 0.6894, Training Accuracy= 0.537\n",
      "Epoch: 1860, Minibatch Loss= 0.6891, Training Accuracy= 0.537\n",
      "Epoch: 1870, Minibatch Loss= 0.6898, Training Accuracy= 0.528\n",
      "Epoch: 1880, Minibatch Loss= 0.6886, Training Accuracy= 0.541\n",
      "Epoch: 1890, Minibatch Loss= 0.6889, Training Accuracy= 0.534\n",
      "Epoch: 1900, Minibatch Loss= 0.6878, Training Accuracy= 0.537\n",
      "Epoch: 1910, Minibatch Loss= 0.6879, Training Accuracy= 0.537\n",
      "Epoch: 1920, Minibatch Loss= 0.6885, Training Accuracy= 0.538\n",
      "Epoch: 1930, Minibatch Loss= 0.6925, Training Accuracy= 0.528\n",
      "Epoch: 1940, Minibatch Loss= 0.6874, Training Accuracy= 0.542\n",
      "Epoch: 1950, Minibatch Loss= 0.6874, Training Accuracy= 0.542\n",
      "Epoch: 1960, Minibatch Loss= 0.6862, Training Accuracy= 0.541\n",
      "Epoch: 1970, Minibatch Loss= 0.6852, Training Accuracy= 0.543\n",
      "Epoch: 1980, Minibatch Loss= 0.6848, Training Accuracy= 0.549\n",
      "Epoch: 1990, Minibatch Loss= 0.6844, Training Accuracy= 0.550\n",
      "Epoch: 2000, Minibatch Loss= 0.6843, Training Accuracy= 0.546\n",
      "Epoch: 2010, Minibatch Loss= 0.6849, Training Accuracy= 0.545\n",
      "Epoch: 2020, Minibatch Loss= 0.6857, Training Accuracy= 0.547\n",
      "Epoch: 2030, Minibatch Loss= 0.6861, Training Accuracy= 0.545\n",
      "Epoch: 2040, Minibatch Loss= 0.6848, Training Accuracy= 0.549\n",
      "Epoch: 2050, Minibatch Loss= 0.6867, Training Accuracy= 0.546\n",
      "Epoch: 2060, Minibatch Loss= 0.6880, Training Accuracy= 0.540\n",
      "Epoch: 2070, Minibatch Loss= 0.6849, Training Accuracy= 0.549\n",
      "Epoch: 2080, Minibatch Loss= 0.6914, Training Accuracy= 0.531\n",
      "Epoch: 2090, Minibatch Loss= 0.6867, Training Accuracy= 0.544\n",
      "Epoch: 2100, Minibatch Loss= 0.6842, Training Accuracy= 0.556\n",
      "Epoch: 2110, Minibatch Loss= 0.6863, Training Accuracy= 0.546\n",
      "Epoch: 2120, Minibatch Loss= 0.6837, Training Accuracy= 0.549\n",
      "Epoch: 2130, Minibatch Loss= 0.6840, Training Accuracy= 0.553\n",
      "Epoch: 2140, Minibatch Loss= 0.6932, Training Accuracy= 0.533\n",
      "Epoch: 2150, Minibatch Loss= 0.6877, Training Accuracy= 0.548\n",
      "Epoch: 2160, Minibatch Loss= 0.6798, Training Accuracy= 0.563\n",
      "Epoch: 2170, Minibatch Loss= 0.6841, Training Accuracy= 0.560\n",
      "Epoch: 2180, Minibatch Loss= 0.6801, Training Accuracy= 0.561\n",
      "Epoch: 2190, Minibatch Loss= 0.6820, Training Accuracy= 0.560\n",
      "Epoch: 2200, Minibatch Loss= 0.6815, Training Accuracy= 0.560\n",
      "Epoch: 2210, Minibatch Loss= 0.6838, Training Accuracy= 0.562\n",
      "Epoch: 2220, Minibatch Loss= 0.6772, Training Accuracy= 0.569\n",
      "Epoch: 2230, Minibatch Loss= 0.6740, Training Accuracy= 0.577\n",
      "Epoch: 2240, Minibatch Loss= 0.6733, Training Accuracy= 0.576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2250, Minibatch Loss= 0.6697, Training Accuracy= 0.582\n",
      "Epoch: 2260, Minibatch Loss= 0.6834, Training Accuracy= 0.562\n",
      "Epoch: 2270, Minibatch Loss= 0.6666, Training Accuracy= 0.589\n",
      "Epoch: 2280, Minibatch Loss= 0.6857, Training Accuracy= 0.554\n",
      "Epoch: 2290, Minibatch Loss= 0.6651, Training Accuracy= 0.594\n",
      "Epoch: 2300, Minibatch Loss= 0.6664, Training Accuracy= 0.591\n",
      "Epoch: 2310, Minibatch Loss= 0.6927, Training Accuracy= 0.557\n",
      "Epoch: 2320, Minibatch Loss= 0.6677, Training Accuracy= 0.590\n",
      "Epoch: 2330, Minibatch Loss= 0.6891, Training Accuracy= 0.557\n",
      "Epoch: 2340, Minibatch Loss= 0.6885, Training Accuracy= 0.562\n",
      "Epoch: 2350, Minibatch Loss= 0.6647, Training Accuracy= 0.589\n",
      "Epoch: 2360, Minibatch Loss= 0.6637, Training Accuracy= 0.599\n",
      "Epoch: 2370, Minibatch Loss= 0.6643, Training Accuracy= 0.596\n",
      "Epoch: 2380, Minibatch Loss= 0.6993, Training Accuracy= 0.516\n",
      "Epoch: 2390, Minibatch Loss= 0.6928, Training Accuracy= 0.521\n",
      "Epoch: 2400, Minibatch Loss= 0.6904, Training Accuracy= 0.527\n",
      "Epoch: 2410, Minibatch Loss= 0.6898, Training Accuracy= 0.534\n",
      "Epoch: 2420, Minibatch Loss= 0.6887, Training Accuracy= 0.536\n",
      "Epoch: 2430, Minibatch Loss= 0.6894, Training Accuracy= 0.535\n",
      "Epoch: 2440, Minibatch Loss= 0.6888, Training Accuracy= 0.544\n",
      "Epoch: 2450, Minibatch Loss= 0.6853, Training Accuracy= 0.549\n",
      "Epoch: 2460, Minibatch Loss= 0.6849, Training Accuracy= 0.549\n",
      "Epoch: 2470, Minibatch Loss= 0.6825, Training Accuracy= 0.554\n",
      "Epoch: 2480, Minibatch Loss= 0.6834, Training Accuracy= 0.554\n",
      "Epoch: 2490, Minibatch Loss= 0.6847, Training Accuracy= 0.553\n",
      "Epoch: 2500, Minibatch Loss= 0.6884, Training Accuracy= 0.537\n",
      "Epoch: 2510, Minibatch Loss= 0.6890, Training Accuracy= 0.544\n",
      "Epoch: 2520, Minibatch Loss= 0.6849, Training Accuracy= 0.549\n",
      "Epoch: 2530, Minibatch Loss= 0.6881, Training Accuracy= 0.541\n",
      "Epoch: 2540, Minibatch Loss= 0.6808, Training Accuracy= 0.560\n",
      "Epoch: 2550, Minibatch Loss= 0.6805, Training Accuracy= 0.561\n",
      "Epoch: 2560, Minibatch Loss= 0.6764, Training Accuracy= 0.570\n",
      "Epoch: 2570, Minibatch Loss= 0.6888, Training Accuracy= 0.547\n",
      "Epoch: 2580, Minibatch Loss= 0.6780, Training Accuracy= 0.568\n",
      "Epoch: 2590, Minibatch Loss= 0.6769, Training Accuracy= 0.566\n",
      "Epoch: 2600, Minibatch Loss= 0.6712, Training Accuracy= 0.582\n",
      "Epoch: 2610, Minibatch Loss= 0.6824, Training Accuracy= 0.556\n",
      "Epoch: 2620, Minibatch Loss= 0.6829, Training Accuracy= 0.562\n",
      "Epoch: 2630, Minibatch Loss= 0.6749, Training Accuracy= 0.574\n",
      "Epoch: 2640, Minibatch Loss= 0.6722, Training Accuracy= 0.575\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.25\n",
    "batch_size = 128\n",
    "display_step = batch_size * 100\n",
    "\n",
    "#batch_steps = 10000 / batch_size\n",
    "epochs = 5000\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 1 # \n",
    "timesteps = N # timesteps\n",
    "num_hidden = H # hidden layer num of features\n",
    "num_classes = 2 # 0 or 1\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "\n",
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "logits = RNN(X, weights, biases)\n",
    "#prediction = tf.nn.softmax(logits)\n",
    "prediction = tf.tanh(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "test_accuracies_10replications = []\n",
    "minibatch_losses_1st_replication = [] #epoch as unit\n",
    "test_accuracies_1st_replication = [] #epoch as unit\n",
    "train_accuracies_1st_replication = [] #epoch as unit\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Run 10 replications\n",
    "    for replication in range(10):\n",
    "        \n",
    "        print(\"Replication: %d: \" % replication)\n",
    "        \n",
    "        # Initialize random weights\n",
    "        train_data = generate_parity_sequences(N, 10000)\n",
    "        train_data_x = train_data[0]\n",
    "        train_data_y = train_data[1]\n",
    "        test_data = generate_parity_sequences(N, 10000)\n",
    "        test_data_x = test_data[0]\n",
    "        test_data_y = test_data[1]\n",
    "        \n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            batch_index = 0\n",
    "            while batch_index < 10000:\n",
    "\n",
    "                train_data_batch_x = []\n",
    "                train_data_batch_y = []\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_x[batch_index : batch_index + batch_size]\n",
    "                    train_data_batch_y = train_data_y[batch_index : batch_index + batch_size]\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_x[batch_index : ]\n",
    "                    train_data_batch_y = train_data_y[batch_index : ]\n",
    "\n",
    "                #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "                # Reshape data to get 28 seq of 28 elements\n",
    "                #batch_x = batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                #train_data_x = train_data_x.reshape((10000, timesteps, num_input))\n",
    "                #print(\"train_data_batch_x.shape:  \" , train_data_batch_x.shape)\n",
    "                if batch_index + batch_size < 10000: \n",
    "                    train_data_batch_x = train_data_batch_x.reshape((batch_size, timesteps, num_input))\n",
    "                else:\n",
    "                    train_data_batch_x = train_data_batch_x.reshape((10000 % batch_size, timesteps, num_input))\n",
    "                # Run optimization op (backprop)\n",
    "                #sess.run(train_op, feed_dict={X: train_data_x, \n",
    "                 #                             Y: train_data_y})\n",
    "                sess.run(train_op, feed_dict={X: train_data_batch_x, \n",
    "                                              Y: train_data_batch_y})\n",
    "\n",
    "                batch_index += batch_size\n",
    "\n",
    "            if replication == 0:\n",
    "                loss, train_accuracy = sess.run([loss_op, accuracy], feed_dict={X: train_data_x, Y: train_data_y})\n",
    "                test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "                minibatch_losses_1st_replication.append(loss)\n",
    "                train_accuracies_1st_replication.append(train_accuracy)\n",
    "                test_accuracies_1st_replication.append(test_accuracy)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: train_data_x,\n",
    "                                                                         Y: train_data_y})\n",
    "                print(\"Epoch: \" + str(epoch) + \\\n",
    "                          \", Minibatch Loss= \" + \\\n",
    "                          \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.3f}\".format(acc))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        test_data_x = test_data_x.reshape((-1, timesteps, num_input))\n",
    "        test_data_y = test_data_y\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={X: test_data_x, Y: test_data_y})\n",
    "        test_accuracies_10replications.append(test_accuracy)\n",
    "        print(\"Testing Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print results\n",
    "test_accuracies_10replications_std = np.std(test_accuracies_10replications, axis=0)\n",
    "test_accuracies_10replications_std_mean = test_accuracies_10replications_std / np.square(10)\n",
    "print(\"test_accuracies_10replications: \", test_accuracies_10replications)\n",
    "print(\"mean of test_accuracies_10replications: \", np.mean(test_accuracies_10replications))\n",
    "print(\"standard deviation of test_accuracies_10replications_std_mean: \", test_accuracies_10replications_std_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minibatch_losses_1st_replication\n",
    "plt.plot(minibatch_losses_1st_replication, color='green', linewidth=5)\n",
    "plt.plot(train_accuracies_1st_replication, color='blue', linewidth=7)\n",
    "plt.plot(test_accuracies_1st_replication, color='red', linewidth=3)\n",
    "plt.xlim(0, epochs)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.ylabel(\"train acc in blue, test acc in red, minibacth loss in green\")\n",
    "plt.title(\"1st replication\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
