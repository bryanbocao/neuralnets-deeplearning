{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Author: Bryan Bo Cao\n",
    "Email: boca7588@colorado.edu or bo.cao-1@colorado.edu\n",
    "Github Repo: https://github.com/BryanBo-Cao/neuralnets-deeplearning\n",
    "Reference: \"3_mnist_from_scratch from\", \"docker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow\"\n",
    "https://github.com/michael-iuzzolino/CIFAR_reader\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module\n",
    "from CIFAR_reader import CIFAR_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for CIFAR data...\n",
      "Extracting Data...\n",
      "Unpacking data...\n",
      "Loading training batch 1 of 5...\n",
      "Loading training batch 2 of 5...\n",
      "Loading training batch 3 of 5...\n",
      "Loading training batch 4 of 5...\n",
      "Loading training batch 5 of 5...\n",
      "Loading testing batch 1 of 1...\n"
     ]
    }
   ],
   "source": [
    "cifar = CIFAR_reader(one_hot=True, verbose=True, img_size=32, num_classes=10, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 32\n",
    "PIXEL_DEPTH = 255\n",
    "BATCH_SIZE = 128\n",
    "N_CHANNELS = 3\n",
    "N_LABELS = 10\n",
    "SEED = 32\n",
    "\n",
    "training_data = cifar.train\n",
    "training_labels = cifar.labels\n",
    "train_data = training_data['data']\n",
    "train_labels = training_data['labels']\n",
    "\n",
    "testing_data = cifar.test\n",
    "test_data = testing_data['data']\n",
    "test_data = np.float32(test_data)\n",
    "test_labels = testing_data['labels']\n",
    "test_labels = np.float32(test_labels)\n",
    "\n",
    "# convert train and test data values from [0, 255] to [-0.5, 0.5]\n",
    "N_TRAIN_IMAGE = len(train_data)\n",
    "train_data = (train_data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
    "train_data = train_data.reshape(N_TRAIN_IMAGE, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "\n",
    "N_TEST_IMAGE = len(test_data)\n",
    "test_data = (test_data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
    "test_data = test_data.reshape(N_TEST_IMAGE, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "\n",
    "#print(\"train_data[0]:\", train_data[0])\n",
    "#print(\"test_data[0]:\", test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11984fb10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cifar.preview_data(data_set=\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 10)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print (train_data.shape)\n",
    "print (train_labels.shape)\n",
    "print (test_data.shape)\n",
    "print (test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape (40000, 32, 32, 3)\n",
      "validation_data.shape (10000, 32, 32, 3)\n",
      "train_data size: 40000\n",
      "validation_data size: 10000\n",
      "N_TRAIN_IMAGE:  40000\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_SIZE = 10000\n",
    "\n",
    "train_data = train_data[VALIDATION_SIZE:, :, :, :]\n",
    "train_data = np.float32(train_data)\n",
    "train_labels = train_labels[VALIDATION_SIZE:]\n",
    "train_size = len(train_data)\n",
    "validation_data = train_data[:VALIDATION_SIZE, :, :, :]\n",
    "validation_data = np.float32(validation_data)\n",
    "validation_labels = train_labels[:VALIDATION_SIZE]\n",
    "validation_size = len(validation_data)\n",
    "\n",
    "print('train_data.shape', train_data.shape)\n",
    "print('validation_data.shape', validation_data.shape)\n",
    "print('train_data size:', train_size)\n",
    "print('validation_data size:', validation_size)\n",
    "#print('validation_data:', validation_data)\n",
    "#print('validation_labels: ', validation_labels)\n",
    "\n",
    "N_TRAIN_IMAGE = train_size\n",
    "print(\"N_TRAIN_IMAGE: \", N_TRAIN_IMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables Initialized\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_data_node = tf.placeholder(\n",
    "  tf.float32,\n",
    "  shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, N_CHANNELS))\n",
    "train_labels_node = tf.placeholder(tf.float32,\n",
    "                                   shape=(BATCH_SIZE, N_LABELS))\n",
    "\n",
    "train_all_data_node = tf.constant(train_data)\n",
    "validation_data_node = tf.constant(validation_data)\n",
    "test_data_node = tf.constant(test_data)\n",
    "\n",
    "conv1_weights = tf.Variable(\n",
    "  tf.truncated_normal([10, 10, N_CHANNELS, 32],  # 5x5 kernel, depth 32.\n",
    "                      stddev=0.1,\n",
    "                      seed=SEED))\n",
    "conv1_biases = tf.Variable(tf.zeros([32]))\n",
    "conv2_weights = tf.Variable(\n",
    "  tf.truncated_normal([10, 10, 32, 64],\n",
    "                      stddev=0.1,\n",
    "                      seed=SEED))\n",
    "conv2_biases = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "fc1_weights = tf.Variable(  # fully connected, depth 512.\n",
    "  tf.truncated_normal([IMAGE_SIZE // 4 * IMAGE_SIZE // 4 * 64, 512],\n",
    "                      stddev=0.1,\n",
    "                      seed=SEED))\n",
    "fc1_biases = tf.Variable(tf.constant(0.1, shape=[512]))\n",
    "fc2_weights = tf.Variable(\n",
    "  tf.truncated_normal([512, N_LABELS],\n",
    "                      stddev=0.1,\n",
    "                      seed=SEED))\n",
    "fc2_biases = tf.Variable(tf.constant(0.1, shape=[N_LABELS]))\n",
    "\n",
    "print('Variables Initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model defined\n"
     ]
    }
   ],
   "source": [
    "def model(data, train=False):\n",
    "\n",
    "    conv = tf.nn.conv2d(data,\n",
    "                        conv1_weights,\n",
    "                        strides=[1, 1, 1, 1], #[image index, y, x, depth]\n",
    "                        padding='SAME')\n",
    "\n",
    "    relu = tf.nn.relu(tf.nn.bias_add(conv, conv1_biases))\n",
    "\n",
    "    pool = tf.nn.max_pool(relu,\n",
    "                          ksize=[1, 4, 4, 1],\n",
    "                          strides=[1, 2, 2, 1],\n",
    "                          padding='SAME')\n",
    "    conv = tf.nn.conv2d(pool,\n",
    "                        conv2_weights,\n",
    "                        strides=[1, 1, 1, 1],\n",
    "                        padding='SAME')\n",
    "    relu = tf.nn.relu(tf.nn.bias_add(conv, conv2_biases))\n",
    "    pool = tf.nn.max_pool(relu,\n",
    "                          ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "    # Fully connected layers\n",
    "    pool_shape = pool.get_shape().as_list()\n",
    "    reshape = tf.reshape(\n",
    "        pool,\n",
    "        [pool_shape[0], pool_shape[1] * pool_shape[2] * pool_shape[3]])\n",
    "  \n",
    "    # Fully connected layer. Note that the \n",
    "    # '+' operation automatically broadcasts the biases.\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)\n",
    "\n",
    "    if train:\n",
    "        hidden = tf.nn.dropout(hidden, 0.5, seed=SEED) # drop out rate 50%\n",
    "    return tf.matmul(hidden, fc2_weights) + fc2_biases\n",
    "\n",
    "print('Model defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training computation: logits + cross-entropy loss done\n"
     ]
    }
   ],
   "source": [
    "# Training computation: logits + cross-entropy loss.\n",
    "logits = model(train_data_node, True)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "  labels=train_labels_node, logits=logits))\n",
    "\n",
    "# L2 regularization for the fully connected parameters.\n",
    "regularizers = (tf.nn.l2_loss(fc1_weights) + tf.nn.l2_loss(fc1_biases) +\n",
    "                tf.nn.l2_loss(fc2_weights) + tf.nn.l2_loss(fc2_biases))\n",
    "loss += 5e-4 * regularizers\n",
    "\n",
    "batch = tf.Variable(0)\n",
    "# Decay once per epoch, using an exponential schedule starting at 0.01.\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "  0.01,                # Base learning rate.\n",
    "  batch * BATCH_SIZE,  # Current index into the dataset.\n",
    "  train_size,          # Decay step.\n",
    "  0.95,                # Decay rate.\n",
    "  staircase=True)\n",
    "\n",
    "# Use simple momentum for the optimization.\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate,\n",
    "                                       0.9).minimize(loss,\n",
    "                                                     global_step=batch)\n",
    "\n",
    "# Predictions for the minibatch, validation set and test set.\n",
    "train_prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# compute only by {eval()} method.\n",
    "train_all_data_prediction = tf.nn.softmax(model(train_all_data_node))\n",
    "validation_prediction = tf.nn.softmax(model(validation_data_node))\n",
    "test_prediction = tf.nn.softmax(model(test_data_node))\n",
    "\n",
    "print('Training computation: logits + cross-entropy loss done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.as_default()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 32, 32, 3)\n",
      "(128, 10)\n",
      "Run graph done.\n"
     ]
    }
   ],
   "source": [
    "batch_data = train_data[:BATCH_SIZE, :, :, :]\n",
    "batch_labels = train_labels[:BATCH_SIZE]\n",
    "\n",
    "# batch data\n",
    "feed_dict = {train_data_node: batch_data,\n",
    "             train_labels_node: batch_labels}\n",
    "\n",
    "# Run the graph and fetch some of the nodes.\n",
    "_, l, lr, predictions = sess.run(\n",
    "  [optimizer, loss, learning_rate, train_prediction],\n",
    "  feed_dict=feed_dict)\n",
    "\n",
    "print(batch_data.shape)\n",
    "print(batch_labels.shape)\n",
    "print('Run graph done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.30611849e-10   1.11723393e-05   3.11259276e-18   7.73865182e-16\n",
      "   8.28149438e-10   5.81399604e-07   4.76680258e-11   9.83323157e-01\n",
      "   4.96903578e-14   1.66650619e-02]\n"
     ]
    }
   ],
   "source": [
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First prediction 7\n",
      "(128, 10)\n",
      "All predictions [7 4 5 1 7 5 6 1 0 7 5 0 5 5 5 4 5 4 7 7 7 2 5 1 5 5 1 0 5 7 7 9 5 9 7 9 5\n",
      " 5 7 7 5 5 0 0 5 7 7 5 5 2 5 5 5 5 5 7 1 1 5 5 7 4 5 7 7 7 5 5 5 2 0 7 7 5\n",
      " 7 0 9 5 5 7 5 7 4 0 9 9 4 5 5 5 5 5 5 5 6 5 6 9 5 4 5 7 4 7 9 8 5 0 7 7 7\n",
      " 7 5 7 5 6 1 2 0 5 8 0 7 4 7 9 5 9]\n"
     ]
    }
   ],
   "source": [
    "# The highest probability in the first entry.\n",
    "print('First prediction', np.argmax(predictions[0]))\n",
    "print(predictions.shape)\n",
    "print('All predictions', np.argmax(predictions, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch labels [1 6 6 8 8 3 4 6 0 6 0 3 6 6 5 4 8 3 2 6 0 3 1 4 0 6 6 2 7 6 9 0 4 5 7 1 6\n",
      " 7 9 1 7 7 8 0 3 7 4 7 3 1 0 4 6 6 1 4 9 2 6 4 5 0 4 6 0 8 3 4 8 8 3 9 5 7\n",
      " 1 9 4 7 9 1 9 7 5 2 7 3 4 8 8 2 1 5 9 2 7 8 8 6 8 8 1 3 8 8 5 4 7 1 6 6 1\n",
      " 6 1 6 7 0 4 6 9 5 8 7 1 9 0 3 3 7]\n"
     ]
    }
   ],
   "source": [
    "print('Batch labels', np.argmax(batch_labels, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_accuracy defined\n"
     ]
    }
   ],
   "source": [
    "def get_accuracy(predictions, labels):\n",
    "    correct = np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "    total = predictions.shape[0]\n",
    "\n",
    "    accuracy = float(correct) / float(total)\n",
    "    accuracy_fig = \"\"\n",
    "    accuracy_fig = str(correct)\n",
    "    accuracy_fig += (\" of \")\n",
    "    accuracy_fig += str(total)\n",
    "    return accuracy, accuracy_fig\n",
    "\n",
    "print('get_accuracy defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_prediction.shape (10000, 10)\n",
      "Validation accuracy: 12.9800% (1298 of 10000)\n"
     ]
    }
   ],
   "source": [
    "validation_accuracy, validation_accuracy_fig = get_accuracy(validation_prediction.eval(), validation_labels)\n",
    "print('validation_prediction.shape', validation_prediction.shape)\n",
    "print('Validation accuracy: %.4f%% (%s)' %  (validation_accuracy * 100, validation_accuracy_fig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_prediction (10000, 10)\n",
      "Test accuracy: 0.1292% (1292 of 10000)\n"
     ]
    }
   ],
   "source": [
    "test_accuracy, test_accuracy_fig = get_accuracy(test_prediction.eval(), test_labels)\n",
    "print('test_prediction.shap', test_prediction.shape)\n",
    "print('Test accuracy: %.4f%% (%s)' % (test_accuracy * 100, test_accuracy_fig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_accuracy, train_accuracy_fig = get_accuracy(train_all_data_prediction.eval(), train_labels)\n",
    "print('train_all_data_prediction.shape', train_all_data_prediction.shape)\n",
    "print('Train accuracy: %.4f%% (%s)' % (train_accuracy * 100, train_accuracy_fig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 of 2000\n"
     ]
    }
   ],
   "source": [
    "#steps = train_size\n",
    "steps = 2000\n",
    "for step in range(steps):\n",
    "    offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)\n",
    "    batch_data = train_data[offset:(offset + BATCH_SIZE), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n",
    "    feed_dict = {train_data_node: batch_data, train_labels_node: batch_labels}\n",
    "    _, l, lr, predictions = sess.run([optimizer, loss, learning_rate, train_prediction], feed_dict=feed_dict)\n",
    "    \n",
    "    if step % 5 == 0:\n",
    "        print('Step %d of %d' % (step, steps))\n",
    "        validation_accuracy, validation_accuracy_fig = get_accuracy(\n",
    "              validation_prediction.eval(), validation_labels)\n",
    "        print(validation_prediction.shape)\n",
    "        print('Validation accuracy: %.6f%% (%s), Mini-batch loss: %.5f, Learning rate: %.5f' % \n",
    "              (validation_accuracy * 100, validation_accuracy_fig, l, lr))\n",
    "        \n",
    "        print(train_all_data_prediction.shape)\n",
    "        train_accuracy, train_accuracy_fig = get_accuracy(train_all_data_prediction.eval(), train_labels)\n",
    "        print('Train accuracy: %.8f (%s)' % (train_accuracy, train_accuracy_fig))\n",
    "        #feed_train_all_data_dict = {train_all_data_node: train_data}\n",
    "        #train_accuracy, train_accuracy_fig = get_accuracy(\n",
    "         #     train_all_data_prediction.eval(feed_dict=feed_train_all_data_dict), \n",
    "         #   train_labels)\n",
    "        \n",
    "        #train_accuracy, train_accuracy_fig = get_accuracy(\n",
    "        #      train_all_data_prediction.eval(), train_labels)\n",
    "        \n",
    "        #print('Train accuracy: %.6f%% (%s), Mini-batch loss: %.5f, Learning rate: %.5f' % \n",
    "         #     (train_accuracy * 100, train_accuracy_fig, l, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_accuracy, test_accuracy_fig = get_accuracy(test_prediction.eval(), test_labels)\n",
    "print('Test accuracy: %.4f%% (%s)' % (test_accuracy * 100, test_accuracy_fig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_accuracy, train_accuracy_fig = get_accuracy(train_all_data_prediction.eval(), train_labels)\n",
    "print('Train accuracy: %.4f%% (%s)' % (train_accuracy * 100, train_accuracy_fig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
